{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zbxhyl_zFlWL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import re\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yH5cg5pSIHaZ"
      },
      "source": [
        "### Loading Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_AjGkWXITKA"
      },
      "source": [
        "news = pd.read_csv(r\"telugu_dataset.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oXtxc-toIc94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 199
        },
        "outputId": "492282a3-c2a4-4bc1-a756-7b8c67c5e8ab"
      },
      "source": [
        "news.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>summary</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ప్రమాదకర కరోనా వైరస్‌ భారత ఆర్మీకి సైతం పాకింద...</td>\n",
              "      <td>ఆర్మీ జవాన్‌కు కరోనా పాజిటివ్‌</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>సంక్షోభంలో పడిన  ప్రైవేటు బ్యాంకు యస్‌ బ్యాంకు...</td>\n",
              "      <td>యస్‌’ పునర్నిర్మాణ పథకం, త్వరలోనే ఆంక్షలు ఎత్త...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ఏపీలో స్థానిక సంస్థల ఎన్నికలు వాయిదా వేయడాన్ని...</td>\n",
              "      <td>చంద్రబాబు క్షమాపణ చెప్పాలి</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>పాకిస్తాన్‌ మాజీ క్రికెటర్‌ షోయబ్‌ అక్తర్‌ చైన...</td>\n",
              "      <td>‘ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు’</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>రాష్ట వ్యాప్తంగా సంచలన సృష్టించిన మిర్యాలగూడ ప...</td>\n",
              "      <td>తల్లి గిరిజను కలిసిన అమృతా ప్రణయ్‌</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text                                            summary\n",
              "0  ప్రమాదకర కరోనా వైరస్‌ భారత ఆర్మీకి సైతం పాకింద...                     ఆర్మీ జవాన్‌కు కరోనా పాజిటివ్‌\n",
              "1  సంక్షోభంలో పడిన  ప్రైవేటు బ్యాంకు యస్‌ బ్యాంకు...  యస్‌’ పునర్నిర్మాణ పథకం, త్వరలోనే ఆంక్షలు ఎత్త...\n",
              "2  ఏపీలో స్థానిక సంస్థల ఎన్నికలు వాయిదా వేయడాన్ని...                         చంద్రబాబు క్షమాపణ చెప్పాలి\n",
              "3  పాకిస్తాన్‌ మాజీ క్రికెటర్‌ షోయబ్‌ అక్తర్‌ చైన...         ‘ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు’\n",
              "4  రాష్ట వ్యాప్తంగా సంచలన సృష్టించిన మిర్యాలగూడ ప...                 తల్లి గిరిజను కలిసిన అమృతా ప్రణయ్‌"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04oeUTvbQ4qY"
      },
      "source": [
        "document = news['text']\n",
        "summary = news['summary']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z55AhpKIdK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "44537ef6-e220-42c8-821a-7f49549532f9"
      },
      "source": [
        "document[30], summary[30]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('ప్రపంచమార్కెట్లలో కరోనా ప్రళయం కొనసాగుతూనే ఉంది. మహా పతనాల బాటలో స్టాక్\\u200cమార్కెట్లు శుక్రవారం కూడా మరింత అధఃపాతాళానికి పడిపోయాయి. భారత్\\u200cలో తొలి కరోనా మరణం నమోదు కావడంతో మార్కెట్\\u200c మరోమారు అత్యంత ఘోరంగా కుప్పకూలింది. అయితే, అంతేవేగంతో నేలక్కొట్టిన బంతిలా మార్కెట్\\u200c దూసుకెళ్లి ఇన్వెస్టర్లకు అసలుసిసలు రోలర్\\u200c కోస్టర్\\u200c రైడ్\\u200cను చూపించింది. గడిచిన 12 ఏళ్లలో ఎన్నడూ జరగని రీతిలో తొలిసారి మన స్టాక్\\u200c మార్కెట్లో మళ్లీ ట్రేడింగ్\\u200c నిలిపేయాల్సిన పరిస్థితి తలెత్తింది.ఒకానొక దశలో సెన్సెక్స్\\u200c 3,389 పాయింట్లు నష్టపోయి... ఆ కనిష్ట స్థాయి నుంచి 5,380 పాయింట్లు దూసుకెళ్లడం తీవ్రమైన ఒడిదుడుకులకు నిదర్శనం. చివరకు 1,325 పాయింట్లు లాభపడి 34,103 వద్ద ముగిసింది. ఒకేరోజు ఇంత ఘోరంగా పడిపోవడం, మళ్లీ ఈస్థాయిలో రికవరీ.. ఈ రెండూ కూడా కొత్త రికార్డులే కావడం గమనార్హం. కాగా, శుక్రవారం ఆరంభంలో 15 నిమిషాల్లోనే రూ.12.9 లక్షల కోట్ల ఇన్వెస్టర్ల సంపద తుడిచిపెట్టుకుపోగా... చివరికి ఈ నష్టాలన్నింటినీ పూడ్చుకోవడంతోపాటు రూ.3.5 లక్షల కోట్ల మార్కెట్\\u200c విలువ పెరగడం విశేషం!! ',\n",
              " '‘కోవిడ్\\u200c’ కోస్టర్\\u200c..!45 నిమిషాల పాటు ట్రేడింగ్\\u200c నిలిపివేత,సెన్సెక్స్, నిఫ్టీలు ఆరంభంలోనే 10 శాతం డౌన్\\u200c,ఇంట్రాడేలో 3,389 పాయింట్లు పతనమైన సెన్సెక్స్\\u200c,1,325 పాయింట్ల లాభంతో 34,103 వద్ద ముగింపు ')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f8gKyq1gIq4r"
      },
      "source": [
        "### Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJ6LE4MrJjC_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "8d2c6b39-6b30-4123-b434-34a3adf00e1a"
      },
      "source": [
        "# for decoder sequence\n",
        "summary = summary.apply(lambda x: '<go> ' + str(x) + ' <stop>')\n",
        "summary.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0           <go> ఆర్మీ జవాన్‌కు కరోనా పాజిటివ్‌ <stop>\n",
              "1    <go> యస్‌’ పునర్నిర్మాణ పథకం, త్వరలోనే ఆంక్షలు...\n",
              "2               <go> చంద్రబాబు క్షమాపణ చెప్పాలి <stop>\n",
              "3    <go> ‘ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు...\n",
              "4       <go> తల్లి గిరిజను కలిసిన అమృతా ప్రణయ్‌ <stop>\n",
              "Name: summary, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "95Zv7FIvKbTi"
      },
      "source": [
        "#### Tokenizing the texts into integer tokens"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7TqbpEyPMRqa"
      },
      "source": [
        "# since < and > from default tokens cannot be removed\n",
        "filters = '!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n'\n",
        "oov_token = '<unk>'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHw2csoYImsa"
      },
      "source": [
        "document_tokenizer = tf.keras.preprocessing.text.Tokenizer(oov_token=oov_token)\n",
        "summary_tokenizer = tf.keras.preprocessing.text.Tokenizer(filters=filters, oov_token=oov_token)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DWU9Xu7OKVab"
      },
      "source": [
        "document_tokenizer.fit_on_texts(document)\n",
        "summary_tokenizer.fit_on_texts(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ESm-aYR-tvx"
      },
      "source": [
        "inputs = document_tokenizer.texts_to_sequences(document)\n",
        "targets = summary_tokenizer.texts_to_sequences(summary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVyErXAei5_b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 966
        },
        "outputId": "f416ea2a-55b9-4a1e-9fb1-7f286482a9b4"
      },
      "source": [
        "summary_tokenizer.texts_to_sequences([\"దేశంలో జరిగే అన్ని ఫుట్‌బాల్‌ మ్యాచ్‌లను ఈ నెల 31 వరకు రద్దు చేస్తూ అఖిల భారత ఫుట్‌బాల్‌ సమాఖ్య (ఏఐఎఫ్‌ఎఫ్‌) శనివారం నిర్ణయం తీసుకుంది. దాంతో ఐ–లీగ్, డివిజన్‌–2, యూత్‌ లీగ్, గోల్డెన్‌ లీగ్, జాతీయ టోర్నీలు రద్దయ్యాయి. ఐ–లీగ్‌లోని 28 మ్యాచ్‌లను ప్రేక్షకులు లేకుండానే నిర్వహించాలని ఏఐఎఫ్‌ఎఫ్‌ తొలుత అనుకున్నా... కేంద్ర ఆరోగ్య మంత్రిత్వ శాఖ సలహా మేరకు ఈ నెల చివరి వరకు దేశంలో ఎటువంటి ఫుట్‌బాల్‌ మ్యాచ్‌లను నిర్వహించరాదని  నిర్ణయించింది.\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[656,\n",
              "  1,\n",
              "  2158,\n",
              "  76,\n",
              "  1,\n",
              "  12,\n",
              "  204,\n",
              "  75,\n",
              "  48,\n",
              "  283,\n",
              "  1,\n",
              "  1,\n",
              "  105,\n",
              "  76,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1573,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  387,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  467,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  1,\n",
              "  286,\n",
              "  1,\n",
              "  1,\n",
              "  954,\n",
              "  1,\n",
              "  1,\n",
              "  12,\n",
              "  204,\n",
              "  968,\n",
              "  48,\n",
              "  656,\n",
              "  1,\n",
              "  76,\n",
              "  1,\n",
              "  1,\n",
              "  1]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ryx9qx90jwXu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c61bd6e5-dc44-4a79-8613-0594e3261482"
      },
      "source": [
        "summary_tokenizer.sequences_to_texts([[184, 22, 12, 71]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ఘోర చంద్రబాబు ఈ రియల్టీ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoizyBvLKv8h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "371799a2-9a57-4317-a747-d8c56b35b380"
      },
      "source": [
        "encoder_vocab_size = len(document_tokenizer.word_index) + 1\n",
        "decoder_vocab_size = len(summary_tokenizer.word_index) + 1\n",
        "\n",
        "# vocab_size\n",
        "encoder_vocab_size, decoder_vocab_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(25646, 2938)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZden_q9_eZr"
      },
      "source": [
        "#### Obtaining insights on lengths for defining maxlen"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma4o2nGdK5Xb"
      },
      "source": [
        "document_lengths = pd.Series([len(x) for x in document])\n",
        "summary_lengths = pd.Series([len(x) for x in summary])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXZlO99C-UXK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "9bf14182-6d37-44e7-aa9e-c94c3d495d2a"
      },
      "source": [
        "document_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1007.000000\n",
              "mean      634.841112\n",
              "std       206.310924\n",
              "min       208.000000\n",
              "25%       478.500000\n",
              "50%       618.000000\n",
              "75%       747.000000\n",
              "max      1805.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALMwKMx--ZF7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "outputId": "6fd7d265-a056-4eb5-bd98-de6f32c94c1a"
      },
      "source": [
        "summary_lengths.describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1007.000000\n",
              "mean       44.391261\n",
              "std        13.294636\n",
              "min        20.000000\n",
              "25%        37.000000\n",
              "50%        43.000000\n",
              "75%        50.000000\n",
              "max       203.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVeMilXr-bpC"
      },
      "source": [
        "# maxlen\n",
        "# taking values > and round figured to 75th percentile\n",
        "# at the same time not leaving high variance\n",
        "encoder_maxlen = 400\n",
        "decoder_maxlen = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SWap3YJBk-D"
      },
      "source": [
        "#### Padding/Truncating sequences for identical sequence lengths"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEyUBeu7ACRt"
      },
      "source": [
        "inputs = tf.keras.preprocessing.sequence.pad_sequences(inputs, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "targets = tf.keras.preprocessing.sequence.pad_sequences(targets, maxlen=decoder_maxlen, padding='post', truncating='post')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wIP0kIIcB8Rm"
      },
      "source": [
        "### Creating dataset pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LzO6l3-AB7hJ"
      },
      "source": [
        "inputs = tf.cast(inputs, dtype=tf.int32)\n",
        "targets = tf.cast(targets, dtype=tf.int32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "slZ5f4P4DurS"
      },
      "source": [
        "BUFFER_SIZE = 2000\n",
        "BATCH_SIZE = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI-fV7eABWN6"
      },
      "source": [
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, targets)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isN1CpAXLfsl"
      },
      "source": [
        "### Positional Encoding for adding notion of position among words as unlike RNN this is non-directional"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Purv7oyhETDZ"
      },
      "source": [
        "def get_angles(position, i, d_model):\n",
        "    angle_rates = 1 / np.power(10000, (2 * (i // 2)) / np.float32(d_model))\n",
        "    return position * angle_rates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40J2pc2NEXp5"
      },
      "source": [
        "def positional_encoding(position, d_model):\n",
        "    angle_rads = get_angles(\n",
        "        np.arange(position)[:, np.newaxis],\n",
        "        np.arange(d_model)[np.newaxis, :],\n",
        "        d_model\n",
        "    )\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...]\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "24Pe01DMMWHc"
      },
      "source": [
        "### Masking\n",
        "\n",
        "- Padding mask for masking \"pad\" sequences\n",
        "- Lookahead mask for masking future words from contributing in prediction of current words in self attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hN1wVQAdMVYy"
      },
      "source": [
        "def create_padding_mask(seq):\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmjAPLWuMREE"
      },
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
        "    return mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8DqUBc4NFOy"
      },
      "source": [
        "### Building the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfknVF7hNKf7"
      },
      "source": [
        "#### Scaled Dot Product"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w_B6M9OBNBKB"
      },
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True)\n",
        "\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)  \n",
        "\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)\n",
        "\n",
        "    output = tf.matmul(attention_weights, v)\n",
        "    return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf7_a5uQOfJk"
      },
      "source": [
        "#### Multi-Headed Attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIuFrdXnNZEC"
      },
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads):\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "        \n",
        "    def split_heads(self, x, batch_size):\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
        "    \n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)\n",
        "        k = self.wk(k)\n",
        "        v = self.wv(v)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)\n",
        "        k = self.split_heads(k, batch_size)\n",
        "        v = self.split_heads(v, batch_size)\n",
        "\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention, (batch_size, -1, self.d_model))\n",
        "        output = self.dense(concat_attention)\n",
        "            \n",
        "        return output, attention_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A49tXMVvOkOZ"
      },
      "source": [
        "### Feed Forward Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9-qoKuTNwKq"
      },
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'),\n",
        "        tf.keras.layers.Dense(d_model)\n",
        "    ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2RRmn2bOpW9"
      },
      "source": [
        "#### Fundamental Unit of Transformer encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HNuoJoFWO335"
      },
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads)\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, training, mask):\n",
        "        attn_output, _ = self.mha(x, x, x, mask)\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        out1 = self.layernorm1(x + attn_output)\n",
        "\n",
        "        ffn_output = self.ffn(out1)\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        out2 = self.layernorm2(out1 + ffn_output)\n",
        "\n",
        "        return out2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i6Zh8gnPqdW"
      },
      "source": [
        "#### Fundamental Unit of Transformer decoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7CVmvs6dPMRC"
      },
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)\n",
        "\n",
        "        ffn_output = self.ffn(out2)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6zt5MUc_QNid"
      },
      "source": [
        "#### Encoder consisting of multiple EncoderLayer(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrbnTwijQJ-h"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "        \n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "    \n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "    \n",
        "        return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N5LrNrvRexg"
      },
      "source": [
        "#### Decoder consisting of multiple DecoderLayer(s)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmeqkZrIRbSB"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size, maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "    \n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        seq_len = tf.shape(x)[1]\n",
        "        attention_weights = {}\n",
        "\n",
        "        x = self.embedding(x)\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
        "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
        "    \n",
        "        return x, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbMNK_bzSHnh"
      },
      "source": [
        "#### Finally, the Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXHRG-o4R9Mc"
      },
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size, target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "        super(Transformer, self).__init__()\n",
        "\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "    \n",
        "    def call(self, inp, tar, training, enc_padding_mask, look_ahead_mask, dec_padding_mask):\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
        "\n",
        "        dec_output, attention_weights = self.decoder(tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output)\n",
        "\n",
        "        return final_output, attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UndsMPZXTdSr"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GQPBv8FWTg1D"
      },
      "source": [
        "# hyper-params\n",
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 4\n",
        "EPOCHS = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uOGvkYDNTjIj"
      },
      "source": [
        "#### Adam optimizer with custom learning rate scheduling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tfiynCLlTL8C"
      },
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "    \n",
        "    def __call__(self, step):\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsVdrENTUERY"
      },
      "source": [
        "#### Defining losses and other metrics "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ip1-943kTXXK"
      },
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktKwyvKtTvF6"
      },
      "source": [
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uW4LA_45T4Aa"
      },
      "source": [
        "def loss_function(real, pred):\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "    loss_ *= mask\n",
        "\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ze0u6xxXT7dI"
      },
      "source": [
        "train_loss = tf.keras.metrics.Mean(name='train_loss')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XvKy3v6ULnO"
      },
      "source": [
        "#### Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5-RcxqFUCuk"
      },
      "source": [
        "transformer = Transformer(\n",
        "    num_layers, \n",
        "    d_model, \n",
        "    num_heads, \n",
        "    dff,\n",
        "    encoder_vocab_size, \n",
        "    decoder_vocab_size, \n",
        "    pe_input=encoder_vocab_size, \n",
        "    pe_target=decoder_vocab_size,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f56BGiVXU_Dk"
      },
      "source": [
        "#### Masks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZxHuyZxU5Pa"
      },
      "source": [
        "def create_masks(inp, tar):\n",
        "    enc_padding_mask = create_padding_mask(inp)\n",
        "    dec_padding_mask = create_padding_mask(inp)\n",
        "\n",
        "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
        "    dec_target_padding_mask = create_padding_mask(tar)\n",
        "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
        "  \n",
        "    return enc_padding_mask, combined_mask, dec_padding_mask\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYIotvaBVI0d"
      },
      "source": [
        "#### Checkpoints"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tOc1_3c-VGaL"
      },
      "source": [
        "checkpoint_path = \"/content/sample_data/checkpoints\"\n",
        "\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer, optimizer=optimizer)\n",
        "\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print ('Latest checkpoint restored!!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfpI0gS4c06c"
      },
      "source": [
        "#### Training steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmVOMzkrczgl"
      },
      "source": [
        "@tf.function\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    enc_padding_mask, combined_mask, dec_padding_mask = create_masks(inp, tar_inp)\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions, _ = transformer(\n",
        "            inp, tar_inp, \n",
        "            True, \n",
        "            enc_padding_mask, \n",
        "            combined_mask, \n",
        "            dec_padding_mask\n",
        "        )\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)    \n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    train_loss(loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5Ms2P6NWxok"
      },
      "source": [
        "los = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhZqo4bNW4Zh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "17fbccb7-8241-492f-aa95-099354850e2f"
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    train_loss.reset_states()\n",
        "  \n",
        "    for (batch, (inp, tar)) in enumerate(dataset):\n",
        "        train_step(inp, tar)\n",
        "    \n",
        "        # 55k samples\n",
        "        # we display 3 batch results -- 0th, middle and last one (approx)\n",
        "        # 55k / 64 ~ 858; 858 / 2 = 429\n",
        "        #if batch % 429 == 0:\n",
        "        print ('Epoch {} Batch {} Loss {:.4f}'.format(epoch + 1, batch, train_loss.result()))\n",
        "      \n",
        "    if (epoch + 1) % 1:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print ('Saving checkpoint for epoch {} at {}'.format(epoch+1, ckpt_save_path))\n",
        "    \n",
        "    print ('Epoch {} Loss {:.4f}'.format(epoch + 1, train_loss.result()))\n",
        "    los.append(train_loss.result())\n",
        "\n",
        "    print ('Time taken for 1 epoch: {} secs\\n'.format(time.time() - start))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1 Batch 0 Loss 7.9021\n",
            "Epoch 1 Batch 1 Loss 7.9152\n",
            "Epoch 1 Batch 2 Loss 7.9181\n",
            "Epoch 1 Batch 3 Loss 7.9282\n",
            "Epoch 1 Batch 4 Loss 7.9248\n",
            "Epoch 1 Batch 5 Loss 7.9218\n",
            "Epoch 1 Batch 6 Loss 7.9210\n",
            "Epoch 1 Batch 7 Loss 7.9231\n",
            "Epoch 1 Batch 8 Loss 7.9221\n",
            "Epoch 1 Batch 9 Loss 7.9203\n",
            "Epoch 1 Batch 10 Loss 7.9196\n",
            "Epoch 1 Batch 11 Loss 7.9170\n",
            "Epoch 1 Batch 12 Loss 7.9160\n",
            "Epoch 1 Batch 13 Loss 7.9158\n",
            "Epoch 1 Batch 14 Loss 7.9134\n",
            "Epoch 1 Batch 15 Loss 7.9132\n",
            "Epoch 1 Loss 7.9132\n",
            "Time taken for 1 epoch: 17.8436758518219 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 7.8831\n",
            "Epoch 2 Batch 1 Loss 7.8828\n",
            "Epoch 2 Batch 2 Loss 7.8741\n",
            "Epoch 2 Batch 3 Loss 7.8729\n",
            "Epoch 2 Batch 4 Loss 7.8664\n",
            "Epoch 2 Batch 5 Loss 7.8627\n",
            "Epoch 2 Batch 6 Loss 7.8624\n",
            "Epoch 2 Batch 7 Loss 7.8574\n",
            "Epoch 2 Batch 8 Loss 7.8542\n",
            "Epoch 2 Batch 9 Loss 7.8516\n",
            "Epoch 2 Batch 10 Loss 7.8513\n",
            "Epoch 2 Batch 11 Loss 7.8468\n",
            "Epoch 2 Batch 12 Loss 7.8453\n",
            "Epoch 2 Batch 13 Loss 7.8405\n",
            "Epoch 2 Batch 14 Loss 7.8372\n",
            "Epoch 2 Batch 15 Loss 7.8322\n",
            "Epoch 2 Loss 7.8322\n",
            "Time taken for 1 epoch: 3.4629874229431152 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 7.7635\n",
            "Epoch 3 Batch 1 Loss 7.7509\n",
            "Epoch 3 Batch 2 Loss 7.7625\n",
            "Epoch 3 Batch 3 Loss 7.7575\n",
            "Epoch 3 Batch 4 Loss 7.7548\n",
            "Epoch 3 Batch 5 Loss 7.7557\n",
            "Epoch 3 Batch 6 Loss 7.7507\n",
            "Epoch 3 Batch 7 Loss 7.7437\n",
            "Epoch 3 Batch 8 Loss 7.7385\n",
            "Epoch 3 Batch 9 Loss 7.7320\n",
            "Epoch 3 Batch 10 Loss 7.7270\n",
            "Epoch 3 Batch 11 Loss 7.7222\n",
            "Epoch 3 Batch 12 Loss 7.7224\n",
            "Epoch 3 Batch 13 Loss 7.7188\n",
            "Epoch 3 Batch 14 Loss 7.7152\n",
            "Epoch 3 Batch 15 Loss 7.7110\n",
            "Epoch 3 Loss 7.7110\n",
            "Time taken for 1 epoch: 3.4708030223846436 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 7.6635\n",
            "Epoch 4 Batch 1 Loss 7.6455\n",
            "Epoch 4 Batch 2 Loss 7.6347\n",
            "Epoch 4 Batch 3 Loss 7.6269\n",
            "Epoch 4 Batch 4 Loss 7.6259\n",
            "Epoch 4 Batch 5 Loss 7.6227\n",
            "Epoch 4 Batch 6 Loss 7.6153\n",
            "Epoch 4 Batch 7 Loss 7.6119\n",
            "Epoch 4 Batch 8 Loss 7.6108\n",
            "Epoch 4 Batch 9 Loss 7.6077\n",
            "Epoch 4 Batch 10 Loss 7.6069\n",
            "Epoch 4 Batch 11 Loss 7.6043\n",
            "Epoch 4 Batch 12 Loss 7.6013\n",
            "Epoch 4 Batch 13 Loss 7.6000\n",
            "Epoch 4 Batch 14 Loss 7.5950\n",
            "Epoch 4 Batch 15 Loss 7.5917\n",
            "Epoch 4 Loss 7.5917\n",
            "Time taken for 1 epoch: 3.516270160675049 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 7.5555\n",
            "Epoch 5 Batch 1 Loss 7.5434\n",
            "Epoch 5 Batch 2 Loss 7.5405\n",
            "Epoch 5 Batch 3 Loss 7.5219\n",
            "Epoch 5 Batch 4 Loss 7.5171\n",
            "Epoch 5 Batch 5 Loss 7.5200\n",
            "Epoch 5 Batch 6 Loss 7.5098\n",
            "Epoch 5 Batch 7 Loss 7.5118\n",
            "Epoch 5 Batch 8 Loss 7.5120\n",
            "Epoch 5 Batch 9 Loss 7.5097\n",
            "Epoch 5 Batch 10 Loss 7.5055\n",
            "Epoch 5 Batch 11 Loss 7.5052\n",
            "Epoch 5 Batch 12 Loss 7.4987\n",
            "Epoch 5 Batch 13 Loss 7.4986\n",
            "Epoch 5 Batch 14 Loss 7.4977\n",
            "Epoch 5 Batch 15 Loss 7.4968\n",
            "Epoch 5 Loss 7.4968\n",
            "Time taken for 1 epoch: 3.4874069690704346 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 7.4656\n",
            "Epoch 6 Batch 1 Loss 7.4605\n",
            "Epoch 6 Batch 2 Loss 7.4372\n",
            "Epoch 6 Batch 3 Loss 7.4571\n",
            "Epoch 6 Batch 4 Loss 7.4509\n",
            "Epoch 6 Batch 5 Loss 7.4460\n",
            "Epoch 6 Batch 6 Loss 7.4371\n",
            "Epoch 6 Batch 7 Loss 7.4421\n",
            "Epoch 6 Batch 8 Loss 7.4375\n",
            "Epoch 6 Batch 9 Loss 7.4405\n",
            "Epoch 6 Batch 10 Loss 7.4410\n",
            "Epoch 6 Batch 11 Loss 7.4413\n",
            "Epoch 6 Batch 12 Loss 7.4394\n",
            "Epoch 6 Batch 13 Loss 7.4383\n",
            "Epoch 6 Batch 14 Loss 7.4390\n",
            "Epoch 6 Batch 15 Loss 7.4351\n",
            "Epoch 6 Loss 7.4351\n",
            "Time taken for 1 epoch: 3.4773313999176025 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 7.4252\n",
            "Epoch 7 Batch 1 Loss 7.3860\n",
            "Epoch 7 Batch 2 Loss 7.3769\n",
            "Epoch 7 Batch 3 Loss 7.3952\n",
            "Epoch 7 Batch 4 Loss 7.3883\n",
            "Epoch 7 Batch 5 Loss 7.3847\n",
            "Epoch 7 Batch 6 Loss 7.4009\n",
            "Epoch 7 Batch 7 Loss 7.4014\n",
            "Epoch 7 Batch 8 Loss 7.4061\n",
            "Epoch 7 Batch 9 Loss 7.4041\n",
            "Epoch 7 Batch 10 Loss 7.4012\n",
            "Epoch 7 Batch 11 Loss 7.3979\n",
            "Epoch 7 Batch 12 Loss 7.3926\n",
            "Epoch 7 Batch 13 Loss 7.3901\n",
            "Epoch 7 Batch 14 Loss 7.3911\n",
            "Epoch 7 Batch 15 Loss 7.3924\n",
            "Epoch 7 Loss 7.3924\n",
            "Time taken for 1 epoch: 3.461178779602051 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 7.3298\n",
            "Epoch 8 Batch 1 Loss 7.3568\n",
            "Epoch 8 Batch 2 Loss 7.3689\n",
            "Epoch 8 Batch 3 Loss 7.3610\n",
            "Epoch 8 Batch 4 Loss 7.3626\n",
            "Epoch 8 Batch 5 Loss 7.3630\n",
            "Epoch 8 Batch 6 Loss 7.3674\n",
            "Epoch 8 Batch 7 Loss 7.3721\n",
            "Epoch 8 Batch 8 Loss 7.3685\n",
            "Epoch 8 Batch 9 Loss 7.3635\n",
            "Epoch 8 Batch 10 Loss 7.3657\n",
            "Epoch 8 Batch 11 Loss 7.3653\n",
            "Epoch 8 Batch 12 Loss 7.3643\n",
            "Epoch 8 Batch 13 Loss 7.3614\n",
            "Epoch 8 Batch 14 Loss 7.3607\n",
            "Epoch 8 Batch 15 Loss 7.3565\n",
            "Epoch 8 Loss 7.3565\n",
            "Time taken for 1 epoch: 3.497619152069092 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 7.3226\n",
            "Epoch 9 Batch 1 Loss 7.3045\n",
            "Epoch 9 Batch 2 Loss 7.3175\n",
            "Epoch 9 Batch 3 Loss 7.3131\n",
            "Epoch 9 Batch 4 Loss 7.3167\n",
            "Epoch 9 Batch 5 Loss 7.3175\n",
            "Epoch 9 Batch 6 Loss 7.3174\n",
            "Epoch 9 Batch 7 Loss 7.3240\n",
            "Epoch 9 Batch 8 Loss 7.3284\n",
            "Epoch 9 Batch 9 Loss 7.3256\n",
            "Epoch 9 Batch 10 Loss 7.3240\n",
            "Epoch 9 Batch 11 Loss 7.3274\n",
            "Epoch 9 Batch 12 Loss 7.3266\n",
            "Epoch 9 Batch 13 Loss 7.3254\n",
            "Epoch 9 Batch 14 Loss 7.3290\n",
            "Epoch 9 Batch 15 Loss 7.3235\n",
            "Epoch 9 Loss 7.3235\n",
            "Time taken for 1 epoch: 3.4995310306549072 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 7.3414\n",
            "Epoch 10 Batch 1 Loss 7.3427\n",
            "Epoch 10 Batch 2 Loss 7.3267\n",
            "Epoch 10 Batch 3 Loss 7.3144\n",
            "Epoch 10 Batch 4 Loss 7.3062\n",
            "Epoch 10 Batch 5 Loss 7.3050\n",
            "Epoch 10 Batch 6 Loss 7.3022\n",
            "Epoch 10 Batch 7 Loss 7.3038\n",
            "Epoch 10 Batch 8 Loss 7.2999\n",
            "Epoch 10 Batch 9 Loss 7.2969\n",
            "Epoch 10 Batch 10 Loss 7.2963\n",
            "Epoch 10 Batch 11 Loss 7.2954\n",
            "Epoch 10 Batch 12 Loss 7.2908\n",
            "Epoch 10 Batch 13 Loss 7.2943\n",
            "Epoch 10 Batch 14 Loss 7.2925\n",
            "Epoch 10 Batch 15 Loss 7.2905\n",
            "Epoch 10 Loss 7.2905\n",
            "Time taken for 1 epoch: 3.487856864929199 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 7.2712\n",
            "Epoch 11 Batch 1 Loss 7.2502\n",
            "Epoch 11 Batch 2 Loss 7.2516\n",
            "Epoch 11 Batch 3 Loss 7.2533\n",
            "Epoch 11 Batch 4 Loss 7.2567\n",
            "Epoch 11 Batch 5 Loss 7.2526\n",
            "Epoch 11 Batch 6 Loss 7.2589\n",
            "Epoch 11 Batch 7 Loss 7.2615\n",
            "Epoch 11 Batch 8 Loss 7.2639\n",
            "Epoch 11 Batch 9 Loss 7.2612\n",
            "Epoch 11 Batch 10 Loss 7.2595\n",
            "Epoch 11 Batch 11 Loss 7.2546\n",
            "Epoch 11 Batch 12 Loss 7.2504\n",
            "Epoch 11 Batch 13 Loss 7.2514\n",
            "Epoch 11 Batch 14 Loss 7.2550\n",
            "Epoch 11 Batch 15 Loss 7.2575\n",
            "Epoch 11 Loss 7.2575\n",
            "Time taken for 1 epoch: 3.512042999267578 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 7.2061\n",
            "Epoch 12 Batch 1 Loss 7.2160\n",
            "Epoch 12 Batch 2 Loss 7.2005\n",
            "Epoch 12 Batch 3 Loss 7.2137\n",
            "Epoch 12 Batch 4 Loss 7.2262\n",
            "Epoch 12 Batch 5 Loss 7.2187\n",
            "Epoch 12 Batch 6 Loss 7.2179\n",
            "Epoch 12 Batch 7 Loss 7.2248\n",
            "Epoch 12 Batch 8 Loss 7.2246\n",
            "Epoch 12 Batch 9 Loss 7.2235\n",
            "Epoch 12 Batch 10 Loss 7.2226\n",
            "Epoch 12 Batch 11 Loss 7.2232\n",
            "Epoch 12 Batch 12 Loss 7.2196\n",
            "Epoch 12 Batch 13 Loss 7.2185\n",
            "Epoch 12 Batch 14 Loss 7.2174\n",
            "Epoch 12 Batch 15 Loss 7.2211\n",
            "Epoch 12 Loss 7.2211\n",
            "Time taken for 1 epoch: 3.5084569454193115 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 7.1514\n",
            "Epoch 13 Batch 1 Loss 7.1574\n",
            "Epoch 13 Batch 2 Loss 7.1495\n",
            "Epoch 13 Batch 3 Loss 7.1674\n",
            "Epoch 13 Batch 4 Loss 7.1868\n",
            "Epoch 13 Batch 5 Loss 7.1925\n",
            "Epoch 13 Batch 6 Loss 7.1934\n",
            "Epoch 13 Batch 7 Loss 7.1952\n",
            "Epoch 13 Batch 8 Loss 7.1896\n",
            "Epoch 13 Batch 9 Loss 7.1958\n",
            "Epoch 13 Batch 10 Loss 7.1959\n",
            "Epoch 13 Batch 11 Loss 7.1948\n",
            "Epoch 13 Batch 12 Loss 7.1914\n",
            "Epoch 13 Batch 13 Loss 7.1880\n",
            "Epoch 13 Batch 14 Loss 7.1852\n",
            "Epoch 13 Batch 15 Loss 7.1822\n",
            "Epoch 13 Loss 7.1822\n",
            "Time taken for 1 epoch: 3.502741813659668 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 7.1360\n",
            "Epoch 14 Batch 1 Loss 7.1533\n",
            "Epoch 14 Batch 2 Loss 7.1586\n",
            "Epoch 14 Batch 3 Loss 7.1556\n",
            "Epoch 14 Batch 4 Loss 7.1547\n",
            "Epoch 14 Batch 5 Loss 7.1622\n",
            "Epoch 14 Batch 6 Loss 7.1536\n",
            "Epoch 14 Batch 7 Loss 7.1541\n",
            "Epoch 14 Batch 8 Loss 7.1461\n",
            "Epoch 14 Batch 9 Loss 7.1457\n",
            "Epoch 14 Batch 10 Loss 7.1474\n",
            "Epoch 14 Batch 11 Loss 7.1442\n",
            "Epoch 14 Batch 12 Loss 7.1457\n",
            "Epoch 14 Batch 13 Loss 7.1467\n",
            "Epoch 14 Batch 14 Loss 7.1427\n",
            "Epoch 14 Batch 15 Loss 7.1437\n",
            "Epoch 14 Loss 7.1437\n",
            "Time taken for 1 epoch: 3.5287039279937744 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 7.0735\n",
            "Epoch 15 Batch 1 Loss 7.1044\n",
            "Epoch 15 Batch 2 Loss 7.1121\n",
            "Epoch 15 Batch 3 Loss 7.1095\n",
            "Epoch 15 Batch 4 Loss 7.1020\n",
            "Epoch 15 Batch 5 Loss 7.1078\n",
            "Epoch 15 Batch 6 Loss 7.1090\n",
            "Epoch 15 Batch 7 Loss 7.1063\n",
            "Epoch 15 Batch 8 Loss 7.1020\n",
            "Epoch 15 Batch 9 Loss 7.1076\n",
            "Epoch 15 Batch 10 Loss 7.1074\n",
            "Epoch 15 Batch 11 Loss 7.1067\n",
            "Epoch 15 Batch 12 Loss 7.1020\n",
            "Epoch 15 Batch 13 Loss 7.1037\n",
            "Epoch 15 Batch 14 Loss 7.0981\n",
            "Epoch 15 Batch 15 Loss 7.0998\n",
            "Epoch 15 Loss 7.0998\n",
            "Time taken for 1 epoch: 3.502302408218384 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 7.1318\n",
            "Epoch 16 Batch 1 Loss 7.0891\n",
            "Epoch 16 Batch 2 Loss 7.0813\n",
            "Epoch 16 Batch 3 Loss 7.0661\n",
            "Epoch 16 Batch 4 Loss 7.0600\n",
            "Epoch 16 Batch 5 Loss 7.0595\n",
            "Epoch 16 Batch 6 Loss 7.0682\n",
            "Epoch 16 Batch 7 Loss 7.0629\n",
            "Epoch 16 Batch 8 Loss 7.0589\n",
            "Epoch 16 Batch 9 Loss 7.0592\n",
            "Epoch 16 Batch 10 Loss 7.0574\n",
            "Epoch 16 Batch 11 Loss 7.0535\n",
            "Epoch 16 Batch 12 Loss 7.0538\n",
            "Epoch 16 Batch 13 Loss 7.0528\n",
            "Epoch 16 Batch 14 Loss 7.0523\n",
            "Epoch 16 Batch 15 Loss 7.0524\n",
            "Epoch 16 Loss 7.0524\n",
            "Time taken for 1 epoch: 3.52998685836792 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 7.0687\n",
            "Epoch 17 Batch 1 Loss 7.0420\n",
            "Epoch 17 Batch 2 Loss 7.0177\n",
            "Epoch 17 Batch 3 Loss 7.0203\n",
            "Epoch 17 Batch 4 Loss 7.0254\n",
            "Epoch 17 Batch 5 Loss 7.0191\n",
            "Epoch 17 Batch 6 Loss 7.0185\n",
            "Epoch 17 Batch 7 Loss 7.0192\n",
            "Epoch 17 Batch 8 Loss 7.0200\n",
            "Epoch 17 Batch 9 Loss 7.0192\n",
            "Epoch 17 Batch 10 Loss 7.0147\n",
            "Epoch 17 Batch 11 Loss 7.0106\n",
            "Epoch 17 Batch 12 Loss 7.0108\n",
            "Epoch 17 Batch 13 Loss 7.0077\n",
            "Epoch 17 Batch 14 Loss 7.0063\n",
            "Epoch 17 Batch 15 Loss 7.0058\n",
            "Epoch 17 Loss 7.0058\n",
            "Time taken for 1 epoch: 3.5065371990203857 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 7.0026\n",
            "Epoch 18 Batch 1 Loss 7.0220\n",
            "Epoch 18 Batch 2 Loss 6.9930\n",
            "Epoch 18 Batch 3 Loss 6.9680\n",
            "Epoch 18 Batch 4 Loss 6.9684\n",
            "Epoch 18 Batch 5 Loss 6.9716\n",
            "Epoch 18 Batch 6 Loss 6.9747\n",
            "Epoch 18 Batch 7 Loss 6.9759\n",
            "Epoch 18 Batch 8 Loss 6.9763\n",
            "Epoch 18 Batch 9 Loss 6.9712\n",
            "Epoch 18 Batch 10 Loss 6.9673\n",
            "Epoch 18 Batch 11 Loss 6.9678\n",
            "Epoch 18 Batch 12 Loss 6.9603\n",
            "Epoch 18 Batch 13 Loss 6.9583\n",
            "Epoch 18 Batch 14 Loss 6.9546\n",
            "Epoch 18 Batch 15 Loss 6.9522\n",
            "Epoch 18 Loss 6.9522\n",
            "Time taken for 1 epoch: 3.508239984512329 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 6.9569\n",
            "Epoch 19 Batch 1 Loss 6.9419\n",
            "Epoch 19 Batch 2 Loss 6.9526\n",
            "Epoch 19 Batch 3 Loss 6.9342\n",
            "Epoch 19 Batch 4 Loss 6.9111\n",
            "Epoch 19 Batch 5 Loss 6.9188\n",
            "Epoch 19 Batch 6 Loss 6.9132\n",
            "Epoch 19 Batch 7 Loss 6.9097\n",
            "Epoch 19 Batch 8 Loss 6.9089\n",
            "Epoch 19 Batch 9 Loss 6.9102\n",
            "Epoch 19 Batch 10 Loss 6.9099\n",
            "Epoch 19 Batch 11 Loss 6.9062\n",
            "Epoch 19 Batch 12 Loss 6.9033\n",
            "Epoch 19 Batch 13 Loss 6.9006\n",
            "Epoch 19 Batch 14 Loss 6.8961\n",
            "Epoch 19 Batch 15 Loss 6.8993\n",
            "Epoch 19 Loss 6.8993\n",
            "Time taken for 1 epoch: 3.57181453704834 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 6.8621\n",
            "Epoch 20 Batch 1 Loss 6.8495\n",
            "Epoch 20 Batch 2 Loss 6.8389\n",
            "Epoch 20 Batch 3 Loss 6.8453\n",
            "Epoch 20 Batch 4 Loss 6.8600\n",
            "Epoch 20 Batch 5 Loss 6.8496\n",
            "Epoch 20 Batch 6 Loss 6.8364\n",
            "Epoch 20 Batch 7 Loss 6.8446\n",
            "Epoch 20 Batch 8 Loss 6.8445\n",
            "Epoch 20 Batch 9 Loss 6.8407\n",
            "Epoch 20 Batch 10 Loss 6.8385\n",
            "Epoch 20 Batch 11 Loss 6.8353\n",
            "Epoch 20 Batch 12 Loss 6.8396\n",
            "Epoch 20 Batch 13 Loss 6.8366\n",
            "Epoch 20 Batch 14 Loss 6.8359\n",
            "Epoch 20 Batch 15 Loss 6.8351\n",
            "Epoch 20 Loss 6.8351\n",
            "Time taken for 1 epoch: 3.538377046585083 secs\n",
            "\n",
            "Epoch 21 Batch 0 Loss 6.8259\n",
            "Epoch 21 Batch 1 Loss 6.8431\n",
            "Epoch 21 Batch 2 Loss 6.8268\n",
            "Epoch 21 Batch 3 Loss 6.8236\n",
            "Epoch 21 Batch 4 Loss 6.7998\n",
            "Epoch 21 Batch 5 Loss 6.7808\n",
            "Epoch 21 Batch 6 Loss 6.7708\n",
            "Epoch 21 Batch 7 Loss 6.7750\n",
            "Epoch 21 Batch 8 Loss 6.7722\n",
            "Epoch 21 Batch 9 Loss 6.7645\n",
            "Epoch 21 Batch 10 Loss 6.7659\n",
            "Epoch 21 Batch 11 Loss 6.7599\n",
            "Epoch 21 Batch 12 Loss 6.7506\n",
            "Epoch 21 Batch 13 Loss 6.7482\n",
            "Epoch 21 Batch 14 Loss 6.7503\n",
            "Epoch 21 Batch 15 Loss 6.7485\n",
            "Epoch 21 Loss 6.7485\n",
            "Time taken for 1 epoch: 3.5469255447387695 secs\n",
            "\n",
            "Epoch 22 Batch 0 Loss 6.6538\n",
            "Epoch 22 Batch 1 Loss 6.6510\n",
            "Epoch 22 Batch 2 Loss 6.6477\n",
            "Epoch 22 Batch 3 Loss 6.6688\n",
            "Epoch 22 Batch 4 Loss 6.6743\n",
            "Epoch 22 Batch 5 Loss 6.6676\n",
            "Epoch 22 Batch 6 Loss 6.6756\n",
            "Epoch 22 Batch 7 Loss 6.6669\n",
            "Epoch 22 Batch 8 Loss 6.6699\n",
            "Epoch 22 Batch 9 Loss 6.6669\n",
            "Epoch 22 Batch 10 Loss 6.6631\n",
            "Epoch 22 Batch 11 Loss 6.6574\n",
            "Epoch 22 Batch 12 Loss 6.6543\n",
            "Epoch 22 Batch 13 Loss 6.6517\n",
            "Epoch 22 Batch 14 Loss 6.6522\n",
            "Epoch 22 Batch 15 Loss 6.6566\n",
            "Epoch 22 Loss 6.6566\n",
            "Time taken for 1 epoch: 3.539292335510254 secs\n",
            "\n",
            "Epoch 23 Batch 0 Loss 6.6372\n",
            "Epoch 23 Batch 1 Loss 6.5927\n",
            "Epoch 23 Batch 2 Loss 6.5799\n",
            "Epoch 23 Batch 3 Loss 6.5663\n",
            "Epoch 23 Batch 4 Loss 6.5741\n",
            "Epoch 23 Batch 5 Loss 6.5706\n",
            "Epoch 23 Batch 6 Loss 6.5657\n",
            "Epoch 23 Batch 7 Loss 6.5636\n",
            "Epoch 23 Batch 8 Loss 6.5684\n",
            "Epoch 23 Batch 9 Loss 6.5638\n",
            "Epoch 23 Batch 10 Loss 6.5629\n",
            "Epoch 23 Batch 11 Loss 6.5534\n",
            "Epoch 23 Batch 12 Loss 6.5564\n",
            "Epoch 23 Batch 13 Loss 6.5581\n",
            "Epoch 23 Batch 14 Loss 6.5585\n",
            "Epoch 23 Batch 15 Loss 6.5576\n",
            "Epoch 23 Loss 6.5576\n",
            "Time taken for 1 epoch: 3.537489175796509 secs\n",
            "\n",
            "Epoch 24 Batch 0 Loss 6.5009\n",
            "Epoch 24 Batch 1 Loss 6.5105\n",
            "Epoch 24 Batch 2 Loss 6.5040\n",
            "Epoch 24 Batch 3 Loss 6.4935\n",
            "Epoch 24 Batch 4 Loss 6.4842\n",
            "Epoch 24 Batch 5 Loss 6.4909\n",
            "Epoch 24 Batch 6 Loss 6.4883\n",
            "Epoch 24 Batch 7 Loss 6.4734\n",
            "Epoch 24 Batch 8 Loss 6.4723\n",
            "Epoch 24 Batch 9 Loss 6.4768\n",
            "Epoch 24 Batch 10 Loss 6.4728\n",
            "Epoch 24 Batch 11 Loss 6.4743\n",
            "Epoch 24 Batch 12 Loss 6.4687\n",
            "Epoch 24 Batch 13 Loss 6.4574\n",
            "Epoch 24 Batch 14 Loss 6.4620\n",
            "Epoch 24 Batch 15 Loss 6.4615\n",
            "Epoch 24 Loss 6.4615\n",
            "Time taken for 1 epoch: 3.5780110359191895 secs\n",
            "\n",
            "Epoch 25 Batch 0 Loss 6.4792\n",
            "Epoch 25 Batch 1 Loss 6.4219\n",
            "Epoch 25 Batch 2 Loss 6.3936\n",
            "Epoch 25 Batch 3 Loss 6.3837\n",
            "Epoch 25 Batch 4 Loss 6.3722\n",
            "Epoch 25 Batch 5 Loss 6.3816\n",
            "Epoch 25 Batch 6 Loss 6.3906\n",
            "Epoch 25 Batch 7 Loss 6.3976\n",
            "Epoch 25 Batch 8 Loss 6.3963\n",
            "Epoch 25 Batch 9 Loss 6.3959\n",
            "Epoch 25 Batch 10 Loss 6.3849\n",
            "Epoch 25 Batch 11 Loss 6.3869\n",
            "Epoch 25 Batch 12 Loss 6.3790\n",
            "Epoch 25 Batch 13 Loss 6.3752\n",
            "Epoch 25 Batch 14 Loss 6.3717\n",
            "Epoch 25 Batch 15 Loss 6.3755\n",
            "Epoch 25 Loss 6.3755\n",
            "Time taken for 1 epoch: 3.559281349182129 secs\n",
            "\n",
            "Epoch 26 Batch 0 Loss 6.2501\n",
            "Epoch 26 Batch 1 Loss 6.2127\n",
            "Epoch 26 Batch 2 Loss 6.2152\n",
            "Epoch 26 Batch 3 Loss 6.2260\n",
            "Epoch 26 Batch 4 Loss 6.2333\n",
            "Epoch 26 Batch 5 Loss 6.2393\n",
            "Epoch 26 Batch 6 Loss 6.2433\n",
            "Epoch 26 Batch 7 Loss 6.2304\n",
            "Epoch 26 Batch 8 Loss 6.2457\n",
            "Epoch 26 Batch 9 Loss 6.2518\n",
            "Epoch 26 Batch 10 Loss 6.2556\n",
            "Epoch 26 Batch 11 Loss 6.2643\n",
            "Epoch 26 Batch 12 Loss 6.2625\n",
            "Epoch 26 Batch 13 Loss 6.2614\n",
            "Epoch 26 Batch 14 Loss 6.2637\n",
            "Epoch 26 Batch 15 Loss 6.2702\n",
            "Epoch 26 Loss 6.2702\n",
            "Time taken for 1 epoch: 3.5769526958465576 secs\n",
            "\n",
            "Epoch 27 Batch 0 Loss 6.2339\n",
            "Epoch 27 Batch 1 Loss 6.2191\n",
            "Epoch 27 Batch 2 Loss 6.2190\n",
            "Epoch 27 Batch 3 Loss 6.2180\n",
            "Epoch 27 Batch 4 Loss 6.1976\n",
            "Epoch 27 Batch 5 Loss 6.1853\n",
            "Epoch 27 Batch 6 Loss 6.1910\n",
            "Epoch 27 Batch 7 Loss 6.1979\n",
            "Epoch 27 Batch 8 Loss 6.1995\n",
            "Epoch 27 Batch 9 Loss 6.1938\n",
            "Epoch 27 Batch 10 Loss 6.1889\n",
            "Epoch 27 Batch 11 Loss 6.1902\n",
            "Epoch 27 Batch 12 Loss 6.1919\n",
            "Epoch 27 Batch 13 Loss 6.1895\n",
            "Epoch 27 Batch 14 Loss 6.1862\n",
            "Epoch 27 Batch 15 Loss 6.1877\n",
            "Epoch 27 Loss 6.1877\n",
            "Time taken for 1 epoch: 3.572538137435913 secs\n",
            "\n",
            "Epoch 28 Batch 0 Loss 6.1331\n",
            "Epoch 28 Batch 1 Loss 6.1517\n",
            "Epoch 28 Batch 2 Loss 6.1491\n",
            "Epoch 28 Batch 3 Loss 6.1294\n",
            "Epoch 28 Batch 4 Loss 6.1189\n",
            "Epoch 28 Batch 5 Loss 6.1232\n",
            "Epoch 28 Batch 6 Loss 6.1222\n",
            "Epoch 28 Batch 7 Loss 6.1218\n",
            "Epoch 28 Batch 8 Loss 6.1177\n",
            "Epoch 28 Batch 9 Loss 6.1218\n",
            "Epoch 28 Batch 10 Loss 6.1136\n",
            "Epoch 28 Batch 11 Loss 6.1011\n",
            "Epoch 28 Batch 12 Loss 6.0992\n",
            "Epoch 28 Batch 13 Loss 6.0996\n",
            "Epoch 28 Batch 14 Loss 6.0871\n",
            "Epoch 28 Batch 15 Loss 6.0915\n",
            "Epoch 28 Loss 6.0915\n",
            "Time taken for 1 epoch: 3.584338426589966 secs\n",
            "\n",
            "Epoch 29 Batch 0 Loss 5.9078\n",
            "Epoch 29 Batch 1 Loss 6.0092\n",
            "Epoch 29 Batch 2 Loss 6.0023\n",
            "Epoch 29 Batch 3 Loss 5.9992\n",
            "Epoch 29 Batch 4 Loss 5.9794\n",
            "Epoch 29 Batch 5 Loss 5.9820\n",
            "Epoch 29 Batch 6 Loss 5.9803\n",
            "Epoch 29 Batch 7 Loss 5.9805\n",
            "Epoch 29 Batch 8 Loss 5.9914\n",
            "Epoch 29 Batch 9 Loss 5.9929\n",
            "Epoch 29 Batch 10 Loss 5.9901\n",
            "Epoch 29 Batch 11 Loss 5.9948\n",
            "Epoch 29 Batch 12 Loss 5.9998\n",
            "Epoch 29 Batch 13 Loss 6.0038\n",
            "Epoch 29 Batch 14 Loss 6.0069\n",
            "Epoch 29 Batch 15 Loss 6.0004\n",
            "Epoch 29 Loss 6.0004\n",
            "Time taken for 1 epoch: 3.5998501777648926 secs\n",
            "\n",
            "Epoch 30 Batch 0 Loss 5.9450\n",
            "Epoch 30 Batch 1 Loss 5.9776\n",
            "Epoch 30 Batch 2 Loss 6.0011\n",
            "Epoch 30 Batch 3 Loss 5.9688\n",
            "Epoch 30 Batch 4 Loss 5.9676\n",
            "Epoch 30 Batch 5 Loss 5.9482\n",
            "Epoch 30 Batch 6 Loss 5.9330\n",
            "Epoch 30 Batch 7 Loss 5.9419\n",
            "Epoch 30 Batch 8 Loss 5.9355\n",
            "Epoch 30 Batch 9 Loss 5.9368\n",
            "Epoch 30 Batch 10 Loss 5.9294\n",
            "Epoch 30 Batch 11 Loss 5.9140\n",
            "Epoch 30 Batch 12 Loss 5.9076\n",
            "Epoch 30 Batch 13 Loss 5.9074\n",
            "Epoch 30 Batch 14 Loss 5.9208\n",
            "Epoch 30 Batch 15 Loss 5.9195\n",
            "Epoch 30 Loss 5.9195\n",
            "Time taken for 1 epoch: 3.6358277797698975 secs\n",
            "\n",
            "Epoch 31 Batch 0 Loss 5.8804\n",
            "Epoch 31 Batch 1 Loss 5.9217\n",
            "Epoch 31 Batch 2 Loss 5.8923\n",
            "Epoch 31 Batch 3 Loss 5.8755\n",
            "Epoch 31 Batch 4 Loss 5.8561\n",
            "Epoch 31 Batch 5 Loss 5.8533\n",
            "Epoch 31 Batch 6 Loss 5.8539\n",
            "Epoch 31 Batch 7 Loss 5.8515\n",
            "Epoch 31 Batch 8 Loss 5.8516\n",
            "Epoch 31 Batch 9 Loss 5.8572\n",
            "Epoch 31 Batch 10 Loss 5.8427\n",
            "Epoch 31 Batch 11 Loss 5.8345\n",
            "Epoch 31 Batch 12 Loss 5.8358\n",
            "Epoch 31 Batch 13 Loss 5.8319\n",
            "Epoch 31 Batch 14 Loss 5.8247\n",
            "Epoch 31 Batch 15 Loss 5.8188\n",
            "Epoch 31 Loss 5.8188\n",
            "Time taken for 1 epoch: 3.613375425338745 secs\n",
            "\n",
            "Epoch 32 Batch 0 Loss 5.7075\n",
            "Epoch 32 Batch 1 Loss 5.7483\n",
            "Epoch 32 Batch 2 Loss 5.7558\n",
            "Epoch 32 Batch 3 Loss 5.7394\n",
            "Epoch 32 Batch 4 Loss 5.7324\n",
            "Epoch 32 Batch 5 Loss 5.7417\n",
            "Epoch 32 Batch 6 Loss 5.7396\n",
            "Epoch 32 Batch 7 Loss 5.7407\n",
            "Epoch 32 Batch 8 Loss 5.7387\n",
            "Epoch 32 Batch 9 Loss 5.7383\n",
            "Epoch 32 Batch 10 Loss 5.7462\n",
            "Epoch 32 Batch 11 Loss 5.7383\n",
            "Epoch 32 Batch 12 Loss 5.7385\n",
            "Epoch 32 Batch 13 Loss 5.7440\n",
            "Epoch 32 Batch 14 Loss 5.7425\n",
            "Epoch 32 Batch 15 Loss 5.7453\n",
            "Epoch 32 Loss 5.7453\n",
            "Time taken for 1 epoch: 3.640772581100464 secs\n",
            "\n",
            "Epoch 33 Batch 0 Loss 5.7321\n",
            "Epoch 33 Batch 1 Loss 5.7021\n",
            "Epoch 33 Batch 2 Loss 5.7040\n",
            "Epoch 33 Batch 3 Loss 5.6834\n",
            "Epoch 33 Batch 4 Loss 5.6761\n",
            "Epoch 33 Batch 5 Loss 5.6772\n",
            "Epoch 33 Batch 6 Loss 5.6647\n",
            "Epoch 33 Batch 7 Loss 5.6500\n",
            "Epoch 33 Batch 8 Loss 5.6556\n",
            "Epoch 33 Batch 9 Loss 5.6584\n",
            "Epoch 33 Batch 10 Loss 5.6647\n",
            "Epoch 33 Batch 11 Loss 5.6684\n",
            "Epoch 33 Batch 12 Loss 5.6666\n",
            "Epoch 33 Batch 13 Loss 5.6687\n",
            "Epoch 33 Batch 14 Loss 5.6614\n",
            "Epoch 33 Batch 15 Loss 5.6541\n",
            "Epoch 33 Loss 5.6541\n",
            "Time taken for 1 epoch: 3.6586766242980957 secs\n",
            "\n",
            "Epoch 34 Batch 0 Loss 5.5560\n",
            "Epoch 34 Batch 1 Loss 5.5793\n",
            "Epoch 34 Batch 2 Loss 5.5517\n",
            "Epoch 34 Batch 3 Loss 5.5514\n",
            "Epoch 34 Batch 4 Loss 5.5654\n",
            "Epoch 34 Batch 5 Loss 5.5678\n",
            "Epoch 34 Batch 6 Loss 5.5652\n",
            "Epoch 34 Batch 7 Loss 5.5743\n",
            "Epoch 34 Batch 8 Loss 5.5886\n",
            "Epoch 34 Batch 9 Loss 5.5868\n",
            "Epoch 34 Batch 10 Loss 5.5840\n",
            "Epoch 34 Batch 11 Loss 5.5836\n",
            "Epoch 34 Batch 12 Loss 5.5877\n",
            "Epoch 34 Batch 13 Loss 5.5798\n",
            "Epoch 34 Batch 14 Loss 5.5778\n",
            "Epoch 34 Batch 15 Loss 5.5788\n",
            "Epoch 34 Loss 5.5788\n",
            "Time taken for 1 epoch: 3.6537692546844482 secs\n",
            "\n",
            "Epoch 35 Batch 0 Loss 5.4649\n",
            "Epoch 35 Batch 1 Loss 5.4877\n",
            "Epoch 35 Batch 2 Loss 5.4619\n",
            "Epoch 35 Batch 3 Loss 5.4862\n",
            "Epoch 35 Batch 4 Loss 5.5014\n",
            "Epoch 35 Batch 5 Loss 5.4998\n",
            "Epoch 35 Batch 6 Loss 5.5064\n",
            "Epoch 35 Batch 7 Loss 5.5142\n",
            "Epoch 35 Batch 8 Loss 5.5068\n",
            "Epoch 35 Batch 9 Loss 5.5087\n",
            "Epoch 35 Batch 10 Loss 5.4987\n",
            "Epoch 35 Batch 11 Loss 5.4997\n",
            "Epoch 35 Batch 12 Loss 5.5023\n",
            "Epoch 35 Batch 13 Loss 5.5013\n",
            "Epoch 35 Batch 14 Loss 5.5011\n",
            "Epoch 35 Batch 15 Loss 5.4926\n",
            "Epoch 35 Loss 5.4926\n",
            "Time taken for 1 epoch: 3.6868982315063477 secs\n",
            "\n",
            "Epoch 36 Batch 0 Loss 5.4768\n",
            "Epoch 36 Batch 1 Loss 5.4561\n",
            "Epoch 36 Batch 2 Loss 5.4414\n",
            "Epoch 36 Batch 3 Loss 5.4377\n",
            "Epoch 36 Batch 4 Loss 5.4208\n",
            "Epoch 36 Batch 5 Loss 5.4171\n",
            "Epoch 36 Batch 6 Loss 5.4116\n",
            "Epoch 36 Batch 7 Loss 5.4230\n",
            "Epoch 36 Batch 8 Loss 5.4239\n",
            "Epoch 36 Batch 9 Loss 5.4235\n",
            "Epoch 36 Batch 10 Loss 5.4282\n",
            "Epoch 36 Batch 11 Loss 5.4217\n",
            "Epoch 36 Batch 12 Loss 5.4164\n",
            "Epoch 36 Batch 13 Loss 5.4231\n",
            "Epoch 36 Batch 14 Loss 5.4224\n",
            "Epoch 36 Batch 15 Loss 5.4245\n",
            "Epoch 36 Loss 5.4245\n",
            "Time taken for 1 epoch: 3.676469564437866 secs\n",
            "\n",
            "Epoch 37 Batch 0 Loss 5.4132\n",
            "Epoch 37 Batch 1 Loss 5.4109\n",
            "Epoch 37 Batch 2 Loss 5.3761\n",
            "Epoch 37 Batch 3 Loss 5.3430\n",
            "Epoch 37 Batch 4 Loss 5.3291\n",
            "Epoch 37 Batch 5 Loss 5.3298\n",
            "Epoch 37 Batch 6 Loss 5.3354\n",
            "Epoch 37 Batch 7 Loss 5.3262\n",
            "Epoch 37 Batch 8 Loss 5.3346\n",
            "Epoch 37 Batch 9 Loss 5.3398\n",
            "Epoch 37 Batch 10 Loss 5.3341\n",
            "Epoch 37 Batch 11 Loss 5.3367\n",
            "Epoch 37 Batch 12 Loss 5.3351\n",
            "Epoch 37 Batch 13 Loss 5.3335\n",
            "Epoch 37 Batch 14 Loss 5.3310\n",
            "Epoch 37 Batch 15 Loss 5.3360\n",
            "Epoch 37 Loss 5.3360\n",
            "Time taken for 1 epoch: 3.6579360961914062 secs\n",
            "\n",
            "Epoch 38 Batch 0 Loss 5.3311\n",
            "Epoch 38 Batch 1 Loss 5.3036\n",
            "Epoch 38 Batch 2 Loss 5.2657\n",
            "Epoch 38 Batch 3 Loss 5.2561\n",
            "Epoch 38 Batch 4 Loss 5.2495\n",
            "Epoch 38 Batch 5 Loss 5.2532\n",
            "Epoch 38 Batch 6 Loss 5.2381\n",
            "Epoch 38 Batch 7 Loss 5.2517\n",
            "Epoch 38 Batch 8 Loss 5.2622\n",
            "Epoch 38 Batch 9 Loss 5.2675\n",
            "Epoch 38 Batch 10 Loss 5.2683\n",
            "Epoch 38 Batch 11 Loss 5.2594\n",
            "Epoch 38 Batch 12 Loss 5.2545\n",
            "Epoch 38 Batch 13 Loss 5.2538\n",
            "Epoch 38 Batch 14 Loss 5.2600\n",
            "Epoch 38 Batch 15 Loss 5.2534\n",
            "Epoch 38 Loss 5.2534\n",
            "Time taken for 1 epoch: 3.665785551071167 secs\n",
            "\n",
            "Epoch 39 Batch 0 Loss 5.1643\n",
            "Epoch 39 Batch 1 Loss 5.2311\n",
            "Epoch 39 Batch 2 Loss 5.2319\n",
            "Epoch 39 Batch 3 Loss 5.1993\n",
            "Epoch 39 Batch 4 Loss 5.2185\n",
            "Epoch 39 Batch 5 Loss 5.1964\n",
            "Epoch 39 Batch 6 Loss 5.1822\n",
            "Epoch 39 Batch 7 Loss 5.1856\n",
            "Epoch 39 Batch 8 Loss 5.1806\n",
            "Epoch 39 Batch 9 Loss 5.1898\n",
            "Epoch 39 Batch 10 Loss 5.1837\n",
            "Epoch 39 Batch 11 Loss 5.1858\n",
            "Epoch 39 Batch 12 Loss 5.1795\n",
            "Epoch 39 Batch 13 Loss 5.1824\n",
            "Epoch 39 Batch 14 Loss 5.1813\n",
            "Epoch 39 Batch 15 Loss 5.1783\n",
            "Epoch 39 Loss 5.1783\n",
            "Time taken for 1 epoch: 3.6313695907592773 secs\n",
            "\n",
            "Epoch 40 Batch 0 Loss 5.2670\n",
            "Epoch 40 Batch 1 Loss 5.2053\n",
            "Epoch 40 Batch 2 Loss 5.1597\n",
            "Epoch 40 Batch 3 Loss 5.1532\n",
            "Epoch 40 Batch 4 Loss 5.1391\n",
            "Epoch 40 Batch 5 Loss 5.1326\n",
            "Epoch 40 Batch 6 Loss 5.1119\n",
            "Epoch 40 Batch 7 Loss 5.1074\n",
            "Epoch 40 Batch 8 Loss 5.0968\n",
            "Epoch 40 Batch 9 Loss 5.0972\n",
            "Epoch 40 Batch 10 Loss 5.0858\n",
            "Epoch 40 Batch 11 Loss 5.0845\n",
            "Epoch 40 Batch 12 Loss 5.0915\n",
            "Epoch 40 Batch 13 Loss 5.0884\n",
            "Epoch 40 Batch 14 Loss 5.0946\n",
            "Epoch 40 Batch 15 Loss 5.0987\n",
            "Epoch 40 Loss 5.0987\n",
            "Time taken for 1 epoch: 3.613588571548462 secs\n",
            "\n",
            "Epoch 41 Batch 0 Loss 5.0164\n",
            "Epoch 41 Batch 1 Loss 5.0630\n",
            "Epoch 41 Batch 2 Loss 5.0534\n",
            "Epoch 41 Batch 3 Loss 5.0621\n",
            "Epoch 41 Batch 4 Loss 5.0380\n",
            "Epoch 41 Batch 5 Loss 5.0279\n",
            "Epoch 41 Batch 6 Loss 5.0343\n",
            "Epoch 41 Batch 7 Loss 5.0349\n",
            "Epoch 41 Batch 8 Loss 5.0243\n",
            "Epoch 41 Batch 9 Loss 5.0280\n",
            "Epoch 41 Batch 10 Loss 5.0304\n",
            "Epoch 41 Batch 11 Loss 5.0299\n",
            "Epoch 41 Batch 12 Loss 5.0294\n",
            "Epoch 41 Batch 13 Loss 5.0238\n",
            "Epoch 41 Batch 14 Loss 5.0206\n",
            "Epoch 41 Batch 15 Loss 5.0216\n",
            "Epoch 41 Loss 5.0216\n",
            "Time taken for 1 epoch: 3.6254031658172607 secs\n",
            "\n",
            "Epoch 42 Batch 0 Loss 4.8678\n",
            "Epoch 42 Batch 1 Loss 4.9188\n",
            "Epoch 42 Batch 2 Loss 4.9055\n",
            "Epoch 42 Batch 3 Loss 4.9278\n",
            "Epoch 42 Batch 4 Loss 4.9531\n",
            "Epoch 42 Batch 5 Loss 4.9337\n",
            "Epoch 42 Batch 6 Loss 4.9333\n",
            "Epoch 42 Batch 7 Loss 4.9356\n",
            "Epoch 42 Batch 8 Loss 4.9550\n",
            "Epoch 42 Batch 9 Loss 4.9547\n",
            "Epoch 42 Batch 10 Loss 4.9413\n",
            "Epoch 42 Batch 11 Loss 4.9354\n",
            "Epoch 42 Batch 12 Loss 4.9396\n",
            "Epoch 42 Batch 13 Loss 4.9326\n",
            "Epoch 42 Batch 14 Loss 4.9331\n",
            "Epoch 42 Batch 15 Loss 4.9340\n",
            "Epoch 42 Loss 4.9340\n",
            "Time taken for 1 epoch: 3.6195435523986816 secs\n",
            "\n",
            "Epoch 43 Batch 0 Loss 4.8931\n",
            "Epoch 43 Batch 1 Loss 4.8679\n",
            "Epoch 43 Batch 2 Loss 4.9063\n",
            "Epoch 43 Batch 3 Loss 4.9140\n",
            "Epoch 43 Batch 4 Loss 4.9006\n",
            "Epoch 43 Batch 5 Loss 4.8771\n",
            "Epoch 43 Batch 6 Loss 4.8803\n",
            "Epoch 43 Batch 7 Loss 4.8680\n",
            "Epoch 43 Batch 8 Loss 4.8529\n",
            "Epoch 43 Batch 9 Loss 4.8552\n",
            "Epoch 43 Batch 10 Loss 4.8448\n",
            "Epoch 43 Batch 11 Loss 4.8527\n",
            "Epoch 43 Batch 12 Loss 4.8434\n",
            "Epoch 43 Batch 13 Loss 4.8499\n",
            "Epoch 43 Batch 14 Loss 4.8489\n",
            "Epoch 43 Batch 15 Loss 4.8479\n",
            "Epoch 43 Loss 4.8479\n",
            "Time taken for 1 epoch: 3.6265039443969727 secs\n",
            "\n",
            "Epoch 44 Batch 0 Loss 4.8279\n",
            "Epoch 44 Batch 1 Loss 4.8577\n",
            "Epoch 44 Batch 2 Loss 4.8136\n",
            "Epoch 44 Batch 3 Loss 4.8209\n",
            "Epoch 44 Batch 4 Loss 4.8128\n",
            "Epoch 44 Batch 5 Loss 4.8058\n",
            "Epoch 44 Batch 6 Loss 4.8046\n",
            "Epoch 44 Batch 7 Loss 4.7932\n",
            "Epoch 44 Batch 8 Loss 4.7886\n",
            "Epoch 44 Batch 9 Loss 4.7805\n",
            "Epoch 44 Batch 10 Loss 4.7717\n",
            "Epoch 44 Batch 11 Loss 4.7656\n",
            "Epoch 44 Batch 12 Loss 4.7679\n",
            "Epoch 44 Batch 13 Loss 4.7645\n",
            "Epoch 44 Batch 14 Loss 4.7697\n",
            "Epoch 44 Batch 15 Loss 4.7707\n",
            "Epoch 44 Loss 4.7707\n",
            "Time taken for 1 epoch: 3.6008896827697754 secs\n",
            "\n",
            "Epoch 45 Batch 0 Loss 4.5854\n",
            "Epoch 45 Batch 1 Loss 4.6975\n",
            "Epoch 45 Batch 2 Loss 4.6996\n",
            "Epoch 45 Batch 3 Loss 4.7334\n",
            "Epoch 45 Batch 4 Loss 4.7167\n",
            "Epoch 45 Batch 5 Loss 4.7076\n",
            "Epoch 45 Batch 6 Loss 4.6816\n",
            "Epoch 45 Batch 7 Loss 4.6953\n",
            "Epoch 45 Batch 8 Loss 4.7021\n",
            "Epoch 45 Batch 9 Loss 4.6977\n",
            "Epoch 45 Batch 10 Loss 4.6897\n",
            "Epoch 45 Batch 11 Loss 4.6832\n",
            "Epoch 45 Batch 12 Loss 4.6865\n",
            "Epoch 45 Batch 13 Loss 4.6767\n",
            "Epoch 45 Batch 14 Loss 4.6730\n",
            "Epoch 45 Batch 15 Loss 4.6829\n",
            "Epoch 45 Loss 4.6829\n",
            "Time taken for 1 epoch: 3.6010475158691406 secs\n",
            "\n",
            "Epoch 46 Batch 0 Loss 4.6336\n",
            "Epoch 46 Batch 1 Loss 4.6667\n",
            "Epoch 46 Batch 2 Loss 4.6309\n",
            "Epoch 46 Batch 3 Loss 4.6255\n",
            "Epoch 46 Batch 4 Loss 4.6252\n",
            "Epoch 46 Batch 5 Loss 4.6245\n",
            "Epoch 46 Batch 6 Loss 4.6129\n",
            "Epoch 46 Batch 7 Loss 4.6107\n",
            "Epoch 46 Batch 8 Loss 4.5938\n",
            "Epoch 46 Batch 9 Loss 4.5885\n",
            "Epoch 46 Batch 10 Loss 4.6071\n",
            "Epoch 46 Batch 11 Loss 4.6119\n",
            "Epoch 46 Batch 12 Loss 4.5990\n",
            "Epoch 46 Batch 13 Loss 4.6031\n",
            "Epoch 46 Batch 14 Loss 4.6026\n",
            "Epoch 46 Batch 15 Loss 4.5933\n",
            "Epoch 46 Loss 4.5933\n",
            "Time taken for 1 epoch: 3.6153037548065186 secs\n",
            "\n",
            "Epoch 47 Batch 0 Loss 4.5140\n",
            "Epoch 47 Batch 1 Loss 4.4815\n",
            "Epoch 47 Batch 2 Loss 4.4960\n",
            "Epoch 47 Batch 3 Loss 4.4958\n",
            "Epoch 47 Batch 4 Loss 4.4853\n",
            "Epoch 47 Batch 5 Loss 4.4802\n",
            "Epoch 47 Batch 6 Loss 4.4946\n",
            "Epoch 47 Batch 7 Loss 4.5115\n",
            "Epoch 47 Batch 8 Loss 4.5042\n",
            "Epoch 47 Batch 9 Loss 4.5101\n",
            "Epoch 47 Batch 10 Loss 4.5147\n",
            "Epoch 47 Batch 11 Loss 4.5135\n",
            "Epoch 47 Batch 12 Loss 4.5095\n",
            "Epoch 47 Batch 13 Loss 4.5073\n",
            "Epoch 47 Batch 14 Loss 4.5104\n",
            "Epoch 47 Batch 15 Loss 4.5084\n",
            "Epoch 47 Loss 4.5084\n",
            "Time taken for 1 epoch: 3.6133835315704346 secs\n",
            "\n",
            "Epoch 48 Batch 0 Loss 4.4127\n",
            "Epoch 48 Batch 1 Loss 4.3631\n",
            "Epoch 48 Batch 2 Loss 4.3645\n",
            "Epoch 48 Batch 3 Loss 4.3885\n",
            "Epoch 48 Batch 4 Loss 4.3980\n",
            "Epoch 48 Batch 5 Loss 4.4082\n",
            "Epoch 48 Batch 6 Loss 4.4134\n",
            "Epoch 48 Batch 7 Loss 4.4160\n",
            "Epoch 48 Batch 8 Loss 4.4219\n",
            "Epoch 48 Batch 9 Loss 4.4161\n",
            "Epoch 48 Batch 10 Loss 4.4175\n",
            "Epoch 48 Batch 11 Loss 4.4143\n",
            "Epoch 48 Batch 12 Loss 4.4088\n",
            "Epoch 48 Batch 13 Loss 4.4134\n",
            "Epoch 48 Batch 14 Loss 4.4143\n",
            "Epoch 48 Batch 15 Loss 4.4139\n",
            "Epoch 48 Loss 4.4139\n",
            "Time taken for 1 epoch: 3.6224308013916016 secs\n",
            "\n",
            "Epoch 49 Batch 0 Loss 4.3187\n",
            "Epoch 49 Batch 1 Loss 4.3110\n",
            "Epoch 49 Batch 2 Loss 4.3048\n",
            "Epoch 49 Batch 3 Loss 4.3486\n",
            "Epoch 49 Batch 4 Loss 4.3128\n",
            "Epoch 49 Batch 5 Loss 4.3146\n",
            "Epoch 49 Batch 6 Loss 4.3345\n",
            "Epoch 49 Batch 7 Loss 4.3286\n",
            "Epoch 49 Batch 8 Loss 4.3277\n",
            "Epoch 49 Batch 9 Loss 4.3426\n",
            "Epoch 49 Batch 10 Loss 4.3346\n",
            "Epoch 49 Batch 11 Loss 4.3321\n",
            "Epoch 49 Batch 12 Loss 4.3332\n",
            "Epoch 49 Batch 13 Loss 4.3313\n",
            "Epoch 49 Batch 14 Loss 4.3292\n",
            "Epoch 49 Batch 15 Loss 4.3265\n",
            "Epoch 49 Loss 4.3265\n",
            "Time taken for 1 epoch: 3.6219277381896973 secs\n",
            "\n",
            "Epoch 50 Batch 0 Loss 4.2982\n",
            "Epoch 50 Batch 1 Loss 4.2335\n",
            "Epoch 50 Batch 2 Loss 4.2244\n",
            "Epoch 50 Batch 3 Loss 4.2434\n",
            "Epoch 50 Batch 4 Loss 4.2482\n",
            "Epoch 50 Batch 5 Loss 4.2418\n",
            "Epoch 50 Batch 6 Loss 4.2509\n",
            "Epoch 50 Batch 7 Loss 4.2503\n",
            "Epoch 50 Batch 8 Loss 4.2431\n",
            "Epoch 50 Batch 9 Loss 4.2348\n",
            "Epoch 50 Batch 10 Loss 4.2340\n",
            "Epoch 50 Batch 11 Loss 4.2413\n",
            "Epoch 50 Batch 12 Loss 4.2326\n",
            "Epoch 50 Batch 13 Loss 4.2387\n",
            "Epoch 50 Batch 14 Loss 4.2389\n",
            "Epoch 50 Batch 15 Loss 4.2371\n",
            "Epoch 50 Loss 4.2371\n",
            "Time taken for 1 epoch: 3.606837272644043 secs\n",
            "\n",
            "Epoch 51 Batch 0 Loss 4.1704\n",
            "Epoch 51 Batch 1 Loss 4.1442\n",
            "Epoch 51 Batch 2 Loss 4.1483\n",
            "Epoch 51 Batch 3 Loss 4.1324\n",
            "Epoch 51 Batch 4 Loss 4.1580\n",
            "Epoch 51 Batch 5 Loss 4.1570\n",
            "Epoch 51 Batch 6 Loss 4.1615\n",
            "Epoch 51 Batch 7 Loss 4.1630\n",
            "Epoch 51 Batch 8 Loss 4.1653\n",
            "Epoch 51 Batch 9 Loss 4.1602\n",
            "Epoch 51 Batch 10 Loss 4.1426\n",
            "Epoch 51 Batch 11 Loss 4.1346\n",
            "Epoch 51 Batch 12 Loss 4.1385\n",
            "Epoch 51 Batch 13 Loss 4.1405\n",
            "Epoch 51 Batch 14 Loss 4.1344\n",
            "Epoch 51 Batch 15 Loss 4.1445\n",
            "Epoch 51 Loss 4.1445\n",
            "Time taken for 1 epoch: 3.5858962535858154 secs\n",
            "\n",
            "Epoch 52 Batch 0 Loss 4.0556\n",
            "Epoch 52 Batch 1 Loss 4.0937\n",
            "Epoch 52 Batch 2 Loss 4.0889\n",
            "Epoch 52 Batch 3 Loss 4.0645\n",
            "Epoch 52 Batch 4 Loss 4.0425\n",
            "Epoch 52 Batch 5 Loss 4.0340\n",
            "Epoch 52 Batch 6 Loss 4.0527\n",
            "Epoch 52 Batch 7 Loss 4.0497\n",
            "Epoch 52 Batch 8 Loss 4.0509\n",
            "Epoch 52 Batch 9 Loss 4.0499\n",
            "Epoch 52 Batch 10 Loss 4.0448\n",
            "Epoch 52 Batch 11 Loss 4.0420\n",
            "Epoch 52 Batch 12 Loss 4.0495\n",
            "Epoch 52 Batch 13 Loss 4.0461\n",
            "Epoch 52 Batch 14 Loss 4.0438\n",
            "Epoch 52 Batch 15 Loss 4.0546\n",
            "Epoch 52 Loss 4.0546\n",
            "Time taken for 1 epoch: 3.6031668186187744 secs\n",
            "\n",
            "Epoch 53 Batch 0 Loss 4.0066\n",
            "Epoch 53 Batch 1 Loss 3.9149\n",
            "Epoch 53 Batch 2 Loss 3.9295\n",
            "Epoch 53 Batch 3 Loss 3.9242\n",
            "Epoch 53 Batch 4 Loss 3.9388\n",
            "Epoch 53 Batch 5 Loss 3.9452\n",
            "Epoch 53 Batch 6 Loss 3.9559\n",
            "Epoch 53 Batch 7 Loss 3.9523\n",
            "Epoch 53 Batch 8 Loss 3.9475\n",
            "Epoch 53 Batch 9 Loss 3.9459\n",
            "Epoch 53 Batch 10 Loss 3.9351\n",
            "Epoch 53 Batch 11 Loss 3.9379\n",
            "Epoch 53 Batch 12 Loss 3.9460\n",
            "Epoch 53 Batch 13 Loss 3.9445\n",
            "Epoch 53 Batch 14 Loss 3.9471\n",
            "Epoch 53 Batch 15 Loss 3.9521\n",
            "Epoch 53 Loss 3.9521\n",
            "Time taken for 1 epoch: 3.613253116607666 secs\n",
            "\n",
            "Epoch 54 Batch 0 Loss 3.6563\n",
            "Epoch 54 Batch 1 Loss 3.7502\n",
            "Epoch 54 Batch 2 Loss 3.8331\n",
            "Epoch 54 Batch 3 Loss 3.8462\n",
            "Epoch 54 Batch 4 Loss 3.8507\n",
            "Epoch 54 Batch 5 Loss 3.8496\n",
            "Epoch 54 Batch 6 Loss 3.8535\n",
            "Epoch 54 Batch 7 Loss 3.8502\n",
            "Epoch 54 Batch 8 Loss 3.8534\n",
            "Epoch 54 Batch 9 Loss 3.8614\n",
            "Epoch 54 Batch 10 Loss 3.8514\n",
            "Epoch 54 Batch 11 Loss 3.8556\n",
            "Epoch 54 Batch 12 Loss 3.8521\n",
            "Epoch 54 Batch 13 Loss 3.8456\n",
            "Epoch 54 Batch 14 Loss 3.8461\n",
            "Epoch 54 Batch 15 Loss 3.8522\n",
            "Epoch 54 Loss 3.8522\n",
            "Time taken for 1 epoch: 3.6441662311553955 secs\n",
            "\n",
            "Epoch 55 Batch 0 Loss 3.8031\n",
            "Epoch 55 Batch 1 Loss 3.8276\n",
            "Epoch 55 Batch 2 Loss 3.7701\n",
            "Epoch 55 Batch 3 Loss 3.7597\n",
            "Epoch 55 Batch 4 Loss 3.7732\n",
            "Epoch 55 Batch 5 Loss 3.7813\n",
            "Epoch 55 Batch 6 Loss 3.7696\n",
            "Epoch 55 Batch 7 Loss 3.7599\n",
            "Epoch 55 Batch 8 Loss 3.7524\n",
            "Epoch 55 Batch 9 Loss 3.7381\n",
            "Epoch 55 Batch 10 Loss 3.7473\n",
            "Epoch 55 Batch 11 Loss 3.7438\n",
            "Epoch 55 Batch 12 Loss 3.7444\n",
            "Epoch 55 Batch 13 Loss 3.7493\n",
            "Epoch 55 Batch 14 Loss 3.7501\n",
            "Epoch 55 Batch 15 Loss 3.7492\n",
            "Epoch 55 Loss 3.7492\n",
            "Time taken for 1 epoch: 3.6090636253356934 secs\n",
            "\n",
            "Epoch 56 Batch 0 Loss 3.7126\n",
            "Epoch 56 Batch 1 Loss 3.7070\n",
            "Epoch 56 Batch 2 Loss 3.6778\n",
            "Epoch 56 Batch 3 Loss 3.6466\n",
            "Epoch 56 Batch 4 Loss 3.6235\n",
            "Epoch 56 Batch 5 Loss 3.6127\n",
            "Epoch 56 Batch 6 Loss 3.6223\n",
            "Epoch 56 Batch 7 Loss 3.6076\n",
            "Epoch 56 Batch 8 Loss 3.6195\n",
            "Epoch 56 Batch 9 Loss 3.6154\n",
            "Epoch 56 Batch 10 Loss 3.6290\n",
            "Epoch 56 Batch 11 Loss 3.6269\n",
            "Epoch 56 Batch 12 Loss 3.6345\n",
            "Epoch 56 Batch 13 Loss 3.6383\n",
            "Epoch 56 Batch 14 Loss 3.6528\n",
            "Epoch 56 Batch 15 Loss 3.6589\n",
            "Epoch 56 Loss 3.6589\n",
            "Time taken for 1 epoch: 3.6290273666381836 secs\n",
            "\n",
            "Epoch 57 Batch 0 Loss 3.5756\n",
            "Epoch 57 Batch 1 Loss 3.5923\n",
            "Epoch 57 Batch 2 Loss 3.6226\n",
            "Epoch 57 Batch 3 Loss 3.6199\n",
            "Epoch 57 Batch 4 Loss 3.6348\n",
            "Epoch 57 Batch 5 Loss 3.6096\n",
            "Epoch 57 Batch 6 Loss 3.5957\n",
            "Epoch 57 Batch 7 Loss 3.5816\n",
            "Epoch 57 Batch 8 Loss 3.5850\n",
            "Epoch 57 Batch 9 Loss 3.5790\n",
            "Epoch 57 Batch 10 Loss 3.5757\n",
            "Epoch 57 Batch 11 Loss 3.5793\n",
            "Epoch 57 Batch 12 Loss 3.5713\n",
            "Epoch 57 Batch 13 Loss 3.5572\n",
            "Epoch 57 Batch 14 Loss 3.5610\n",
            "Epoch 57 Batch 15 Loss 3.5597\n",
            "Epoch 57 Loss 3.5597\n",
            "Time taken for 1 epoch: 3.6018474102020264 secs\n",
            "\n",
            "Epoch 58 Batch 0 Loss 3.5121\n",
            "Epoch 58 Batch 1 Loss 3.4955\n",
            "Epoch 58 Batch 2 Loss 3.5376\n",
            "Epoch 58 Batch 3 Loss 3.5219\n",
            "Epoch 58 Batch 4 Loss 3.5053\n",
            "Epoch 58 Batch 5 Loss 3.4912\n",
            "Epoch 58 Batch 6 Loss 3.4888\n",
            "Epoch 58 Batch 7 Loss 3.4822\n",
            "Epoch 58 Batch 8 Loss 3.4800\n",
            "Epoch 58 Batch 9 Loss 3.4750\n",
            "Epoch 58 Batch 10 Loss 3.4721\n",
            "Epoch 58 Batch 11 Loss 3.4679\n",
            "Epoch 58 Batch 12 Loss 3.4539\n",
            "Epoch 58 Batch 13 Loss 3.4608\n",
            "Epoch 58 Batch 14 Loss 3.4682\n",
            "Epoch 58 Batch 15 Loss 3.4587\n",
            "Epoch 58 Loss 3.4587\n",
            "Time taken for 1 epoch: 3.6318373680114746 secs\n",
            "\n",
            "Epoch 59 Batch 0 Loss 3.2641\n",
            "Epoch 59 Batch 1 Loss 3.3749\n",
            "Epoch 59 Batch 2 Loss 3.3782\n",
            "Epoch 59 Batch 3 Loss 3.3917\n",
            "Epoch 59 Batch 4 Loss 3.3874\n",
            "Epoch 59 Batch 5 Loss 3.4032\n",
            "Epoch 59 Batch 6 Loss 3.3974\n",
            "Epoch 59 Batch 7 Loss 3.3992\n",
            "Epoch 59 Batch 8 Loss 3.3921\n",
            "Epoch 59 Batch 9 Loss 3.3838\n",
            "Epoch 59 Batch 10 Loss 3.3721\n",
            "Epoch 59 Batch 11 Loss 3.3646\n",
            "Epoch 59 Batch 12 Loss 3.3590\n",
            "Epoch 59 Batch 13 Loss 3.3609\n",
            "Epoch 59 Batch 14 Loss 3.3544\n",
            "Epoch 59 Batch 15 Loss 3.3515\n",
            "Epoch 59 Loss 3.3515\n",
            "Time taken for 1 epoch: 3.639169692993164 secs\n",
            "\n",
            "Epoch 60 Batch 0 Loss 3.2091\n",
            "Epoch 60 Batch 1 Loss 3.1855\n",
            "Epoch 60 Batch 2 Loss 3.2220\n",
            "Epoch 60 Batch 3 Loss 3.2784\n",
            "Epoch 60 Batch 4 Loss 3.2633\n",
            "Epoch 60 Batch 5 Loss 3.2635\n",
            "Epoch 60 Batch 6 Loss 3.2657\n",
            "Epoch 60 Batch 7 Loss 3.2686\n",
            "Epoch 60 Batch 8 Loss 3.2709\n",
            "Epoch 60 Batch 9 Loss 3.2688\n",
            "Epoch 60 Batch 10 Loss 3.2550\n",
            "Epoch 60 Batch 11 Loss 3.2535\n",
            "Epoch 60 Batch 12 Loss 3.2435\n",
            "Epoch 60 Batch 13 Loss 3.2438\n",
            "Epoch 60 Batch 14 Loss 3.2430\n",
            "Epoch 60 Batch 15 Loss 3.2439\n",
            "Epoch 60 Loss 3.2439\n",
            "Time taken for 1 epoch: 3.62607741355896 secs\n",
            "\n",
            "Epoch 61 Batch 0 Loss 3.1073\n",
            "Epoch 61 Batch 1 Loss 3.1524\n",
            "Epoch 61 Batch 2 Loss 3.1719\n",
            "Epoch 61 Batch 3 Loss 3.1652\n",
            "Epoch 61 Batch 4 Loss 3.1719\n",
            "Epoch 61 Batch 5 Loss 3.1750\n",
            "Epoch 61 Batch 6 Loss 3.1750\n",
            "Epoch 61 Batch 7 Loss 3.1661\n",
            "Epoch 61 Batch 8 Loss 3.1642\n",
            "Epoch 61 Batch 9 Loss 3.1516\n",
            "Epoch 61 Batch 10 Loss 3.1428\n",
            "Epoch 61 Batch 11 Loss 3.1457\n",
            "Epoch 61 Batch 12 Loss 3.1345\n",
            "Epoch 61 Batch 13 Loss 3.1453\n",
            "Epoch 61 Batch 14 Loss 3.1420\n",
            "Epoch 61 Batch 15 Loss 3.1382\n",
            "Epoch 61 Loss 3.1382\n",
            "Time taken for 1 epoch: 3.6106815338134766 secs\n",
            "\n",
            "Epoch 62 Batch 0 Loss 3.0459\n",
            "Epoch 62 Batch 1 Loss 3.0593\n",
            "Epoch 62 Batch 2 Loss 3.0298\n",
            "Epoch 62 Batch 3 Loss 3.0375\n",
            "Epoch 62 Batch 4 Loss 3.0474\n",
            "Epoch 62 Batch 5 Loss 3.0326\n",
            "Epoch 62 Batch 6 Loss 3.0179\n",
            "Epoch 62 Batch 7 Loss 3.0312\n",
            "Epoch 62 Batch 8 Loss 3.0282\n",
            "Epoch 62 Batch 9 Loss 3.0215\n",
            "Epoch 62 Batch 10 Loss 3.0180\n",
            "Epoch 62 Batch 11 Loss 3.0212\n",
            "Epoch 62 Batch 12 Loss 3.0260\n",
            "Epoch 62 Batch 13 Loss 3.0348\n",
            "Epoch 62 Batch 14 Loss 3.0345\n",
            "Epoch 62 Batch 15 Loss 3.0392\n",
            "Epoch 62 Loss 3.0392\n",
            "Time taken for 1 epoch: 3.633970260620117 secs\n",
            "\n",
            "Epoch 63 Batch 0 Loss 2.8740\n",
            "Epoch 63 Batch 1 Loss 2.9588\n",
            "Epoch 63 Batch 2 Loss 2.9503\n",
            "Epoch 63 Batch 3 Loss 2.9796\n",
            "Epoch 63 Batch 4 Loss 2.9732\n",
            "Epoch 63 Batch 5 Loss 2.9630\n",
            "Epoch 63 Batch 6 Loss 2.9460\n",
            "Epoch 63 Batch 7 Loss 2.9379\n",
            "Epoch 63 Batch 8 Loss 2.9438\n",
            "Epoch 63 Batch 9 Loss 2.9389\n",
            "Epoch 63 Batch 10 Loss 2.9378\n",
            "Epoch 63 Batch 11 Loss 2.9436\n",
            "Epoch 63 Batch 12 Loss 2.9372\n",
            "Epoch 63 Batch 13 Loss 2.9359\n",
            "Epoch 63 Batch 14 Loss 2.9356\n",
            "Epoch 63 Batch 15 Loss 2.9320\n",
            "Epoch 63 Loss 2.9320\n",
            "Time taken for 1 epoch: 3.6706531047821045 secs\n",
            "\n",
            "Epoch 64 Batch 0 Loss 2.8826\n",
            "Epoch 64 Batch 1 Loss 2.9088\n",
            "Epoch 64 Batch 2 Loss 2.8544\n",
            "Epoch 64 Batch 3 Loss 2.8525\n",
            "Epoch 64 Batch 4 Loss 2.8419\n",
            "Epoch 64 Batch 5 Loss 2.8312\n",
            "Epoch 64 Batch 6 Loss 2.8399\n",
            "Epoch 64 Batch 7 Loss 2.8512\n",
            "Epoch 64 Batch 8 Loss 2.8480\n",
            "Epoch 64 Batch 9 Loss 2.8527\n",
            "Epoch 64 Batch 10 Loss 2.8420\n",
            "Epoch 64 Batch 11 Loss 2.8403\n",
            "Epoch 64 Batch 12 Loss 2.8365\n",
            "Epoch 64 Batch 13 Loss 2.8314\n",
            "Epoch 64 Batch 14 Loss 2.8346\n",
            "Epoch 64 Batch 15 Loss 2.8329\n",
            "Epoch 64 Loss 2.8329\n",
            "Time taken for 1 epoch: 3.606837749481201 secs\n",
            "\n",
            "Epoch 65 Batch 0 Loss 2.8973\n",
            "Epoch 65 Batch 1 Loss 2.8444\n",
            "Epoch 65 Batch 2 Loss 2.8551\n",
            "Epoch 65 Batch 3 Loss 2.8429\n",
            "Epoch 65 Batch 4 Loss 2.8092\n",
            "Epoch 65 Batch 5 Loss 2.7887\n",
            "Epoch 65 Batch 6 Loss 2.7720\n",
            "Epoch 65 Batch 7 Loss 2.7681\n",
            "Epoch 65 Batch 8 Loss 2.7490\n",
            "Epoch 65 Batch 9 Loss 2.7399\n",
            "Epoch 65 Batch 10 Loss 2.7314\n",
            "Epoch 65 Batch 11 Loss 2.7305\n",
            "Epoch 65 Batch 12 Loss 2.7371\n",
            "Epoch 65 Batch 13 Loss 2.7345\n",
            "Epoch 65 Batch 14 Loss 2.7271\n",
            "Epoch 65 Batch 15 Loss 2.7297\n",
            "Epoch 65 Loss 2.7297\n",
            "Time taken for 1 epoch: 3.6313915252685547 secs\n",
            "\n",
            "Epoch 66 Batch 0 Loss 2.6327\n",
            "Epoch 66 Batch 1 Loss 2.7018\n",
            "Epoch 66 Batch 2 Loss 2.6756\n",
            "Epoch 66 Batch 3 Loss 2.6844\n",
            "Epoch 66 Batch 4 Loss 2.6539\n",
            "Epoch 66 Batch 5 Loss 2.6678\n",
            "Epoch 66 Batch 6 Loss 2.6690\n",
            "Epoch 66 Batch 7 Loss 2.6668\n",
            "Epoch 66 Batch 8 Loss 2.6607\n",
            "Epoch 66 Batch 9 Loss 2.6423\n",
            "Epoch 66 Batch 10 Loss 2.6360\n",
            "Epoch 66 Batch 11 Loss 2.6386\n",
            "Epoch 66 Batch 12 Loss 2.6383\n",
            "Epoch 66 Batch 13 Loss 2.6417\n",
            "Epoch 66 Batch 14 Loss 2.6254\n",
            "Epoch 66 Batch 15 Loss 2.6212\n",
            "Epoch 66 Loss 2.6212\n",
            "Time taken for 1 epoch: 3.6557302474975586 secs\n",
            "\n",
            "Epoch 67 Batch 0 Loss 2.6509\n",
            "Epoch 67 Batch 1 Loss 2.6158\n",
            "Epoch 67 Batch 2 Loss 2.6053\n",
            "Epoch 67 Batch 3 Loss 2.6032\n",
            "Epoch 67 Batch 4 Loss 2.5978\n",
            "Epoch 67 Batch 5 Loss 2.5729\n",
            "Epoch 67 Batch 6 Loss 2.5629\n",
            "Epoch 67 Batch 7 Loss 2.5501\n",
            "Epoch 67 Batch 8 Loss 2.5555\n",
            "Epoch 67 Batch 9 Loss 2.5408\n",
            "Epoch 67 Batch 10 Loss 2.5342\n",
            "Epoch 67 Batch 11 Loss 2.5381\n",
            "Epoch 67 Batch 12 Loss 2.5422\n",
            "Epoch 67 Batch 13 Loss 2.5345\n",
            "Epoch 67 Batch 14 Loss 2.5282\n",
            "Epoch 67 Batch 15 Loss 2.5163\n",
            "Epoch 67 Loss 2.5163\n",
            "Time taken for 1 epoch: 3.616319179534912 secs\n",
            "\n",
            "Epoch 68 Batch 0 Loss 2.5014\n",
            "Epoch 68 Batch 1 Loss 2.5297\n",
            "Epoch 68 Batch 2 Loss 2.4774\n",
            "Epoch 68 Batch 3 Loss 2.4348\n",
            "Epoch 68 Batch 4 Loss 2.4260\n",
            "Epoch 68 Batch 5 Loss 2.4429\n",
            "Epoch 68 Batch 6 Loss 2.4435\n",
            "Epoch 68 Batch 7 Loss 2.4459\n",
            "Epoch 68 Batch 8 Loss 2.4342\n",
            "Epoch 68 Batch 9 Loss 2.4289\n",
            "Epoch 68 Batch 10 Loss 2.4238\n",
            "Epoch 68 Batch 11 Loss 2.4222\n",
            "Epoch 68 Batch 12 Loss 2.4244\n",
            "Epoch 68 Batch 13 Loss 2.4181\n",
            "Epoch 68 Batch 14 Loss 2.4179\n",
            "Epoch 68 Batch 15 Loss 2.4160\n",
            "Epoch 68 Loss 2.4160\n",
            "Time taken for 1 epoch: 3.6336183547973633 secs\n",
            "\n",
            "Epoch 69 Batch 0 Loss 2.3688\n",
            "Epoch 69 Batch 1 Loss 2.3811\n",
            "Epoch 69 Batch 2 Loss 2.3831\n",
            "Epoch 69 Batch 3 Loss 2.3972\n",
            "Epoch 69 Batch 4 Loss 2.3812\n",
            "Epoch 69 Batch 5 Loss 2.3795\n",
            "Epoch 69 Batch 6 Loss 2.3695\n",
            "Epoch 69 Batch 7 Loss 2.3771\n",
            "Epoch 69 Batch 8 Loss 2.3618\n",
            "Epoch 69 Batch 9 Loss 2.3479\n",
            "Epoch 69 Batch 10 Loss 2.3434\n",
            "Epoch 69 Batch 11 Loss 2.3281\n",
            "Epoch 69 Batch 12 Loss 2.3162\n",
            "Epoch 69 Batch 13 Loss 2.3072\n",
            "Epoch 69 Batch 14 Loss 2.3059\n",
            "Epoch 69 Batch 15 Loss 2.3079\n",
            "Epoch 69 Loss 2.3079\n",
            "Time taken for 1 epoch: 3.6663875579833984 secs\n",
            "\n",
            "Epoch 70 Batch 0 Loss 2.1692\n",
            "Epoch 70 Batch 1 Loss 2.1465\n",
            "Epoch 70 Batch 2 Loss 2.1766\n",
            "Epoch 70 Batch 3 Loss 2.2010\n",
            "Epoch 70 Batch 4 Loss 2.2058\n",
            "Epoch 70 Batch 5 Loss 2.2031\n",
            "Epoch 70 Batch 6 Loss 2.2011\n",
            "Epoch 70 Batch 7 Loss 2.2036\n",
            "Epoch 70 Batch 8 Loss 2.2075\n",
            "Epoch 70 Batch 9 Loss 2.2070\n",
            "Epoch 70 Batch 10 Loss 2.2035\n",
            "Epoch 70 Batch 11 Loss 2.2086\n",
            "Epoch 70 Batch 12 Loss 2.2118\n",
            "Epoch 70 Batch 13 Loss 2.2092\n",
            "Epoch 70 Batch 14 Loss 2.2050\n",
            "Epoch 70 Batch 15 Loss 2.2017\n",
            "Epoch 70 Loss 2.2017\n",
            "Time taken for 1 epoch: 3.6277692317962646 secs\n",
            "\n",
            "Epoch 71 Batch 0 Loss 2.0492\n",
            "Epoch 71 Batch 1 Loss 2.0840\n",
            "Epoch 71 Batch 2 Loss 2.0814\n",
            "Epoch 71 Batch 3 Loss 2.1025\n",
            "Epoch 71 Batch 4 Loss 2.0990\n",
            "Epoch 71 Batch 5 Loss 2.0765\n",
            "Epoch 71 Batch 6 Loss 2.0801\n",
            "Epoch 71 Batch 7 Loss 2.0776\n",
            "Epoch 71 Batch 8 Loss 2.0863\n",
            "Epoch 71 Batch 9 Loss 2.0821\n",
            "Epoch 71 Batch 10 Loss 2.0804\n",
            "Epoch 71 Batch 11 Loss 2.0923\n",
            "Epoch 71 Batch 12 Loss 2.0963\n",
            "Epoch 71 Batch 13 Loss 2.0933\n",
            "Epoch 71 Batch 14 Loss 2.0921\n",
            "Epoch 71 Batch 15 Loss 2.0990\n",
            "Epoch 71 Loss 2.0990\n",
            "Time taken for 1 epoch: 3.6327178478240967 secs\n",
            "\n",
            "Epoch 72 Batch 0 Loss 2.0637\n",
            "Epoch 72 Batch 1 Loss 2.0063\n",
            "Epoch 72 Batch 2 Loss 2.0029\n",
            "Epoch 72 Batch 3 Loss 2.0346\n",
            "Epoch 72 Batch 4 Loss 2.0143\n",
            "Epoch 72 Batch 5 Loss 2.0141\n",
            "Epoch 72 Batch 6 Loss 2.0027\n",
            "Epoch 72 Batch 7 Loss 2.0042\n",
            "Epoch 72 Batch 8 Loss 2.0047\n",
            "Epoch 72 Batch 9 Loss 2.0028\n",
            "Epoch 72 Batch 10 Loss 1.9976\n",
            "Epoch 72 Batch 11 Loss 2.0005\n",
            "Epoch 72 Batch 12 Loss 1.9962\n",
            "Epoch 72 Batch 13 Loss 1.9974\n",
            "Epoch 72 Batch 14 Loss 2.0024\n",
            "Epoch 72 Batch 15 Loss 1.9937\n",
            "Epoch 72 Loss 1.9937\n",
            "Time taken for 1 epoch: 3.6439599990844727 secs\n",
            "\n",
            "Epoch 73 Batch 0 Loss 1.9645\n",
            "Epoch 73 Batch 1 Loss 1.9120\n",
            "Epoch 73 Batch 2 Loss 1.9254\n",
            "Epoch 73 Batch 3 Loss 1.9354\n",
            "Epoch 73 Batch 4 Loss 1.9167\n",
            "Epoch 73 Batch 5 Loss 1.9186\n",
            "Epoch 73 Batch 6 Loss 1.9084\n",
            "Epoch 73 Batch 7 Loss 1.9121\n",
            "Epoch 73 Batch 8 Loss 1.9142\n",
            "Epoch 73 Batch 9 Loss 1.9160\n",
            "Epoch 73 Batch 10 Loss 1.9152\n",
            "Epoch 73 Batch 11 Loss 1.9155\n",
            "Epoch 73 Batch 12 Loss 1.9091\n",
            "Epoch 73 Batch 13 Loss 1.9034\n",
            "Epoch 73 Batch 14 Loss 1.9044\n",
            "Epoch 73 Batch 15 Loss 1.8931\n",
            "Epoch 73 Loss 1.8931\n",
            "Time taken for 1 epoch: 3.6563100814819336 secs\n",
            "\n",
            "Epoch 74 Batch 0 Loss 1.8831\n",
            "Epoch 74 Batch 1 Loss 1.8473\n",
            "Epoch 74 Batch 2 Loss 1.8220\n",
            "Epoch 74 Batch 3 Loss 1.8212\n",
            "Epoch 74 Batch 4 Loss 1.8121\n",
            "Epoch 74 Batch 5 Loss 1.8110\n",
            "Epoch 74 Batch 6 Loss 1.8081\n",
            "Epoch 74 Batch 7 Loss 1.8249\n",
            "Epoch 74 Batch 8 Loss 1.8077\n",
            "Epoch 74 Batch 9 Loss 1.7940\n",
            "Epoch 74 Batch 10 Loss 1.7912\n",
            "Epoch 74 Batch 11 Loss 1.7863\n",
            "Epoch 74 Batch 12 Loss 1.7859\n",
            "Epoch 74 Batch 13 Loss 1.7916\n",
            "Epoch 74 Batch 14 Loss 1.7899\n",
            "Epoch 74 Batch 15 Loss 1.7947\n",
            "Epoch 74 Loss 1.7947\n",
            "Time taken for 1 epoch: 3.6270511150360107 secs\n",
            "\n",
            "Epoch 75 Batch 0 Loss 1.7007\n",
            "Epoch 75 Batch 1 Loss 1.6516\n",
            "Epoch 75 Batch 2 Loss 1.6476\n",
            "Epoch 75 Batch 3 Loss 1.6648\n",
            "Epoch 75 Batch 4 Loss 1.6808\n",
            "Epoch 75 Batch 5 Loss 1.6864\n",
            "Epoch 75 Batch 6 Loss 1.6876\n",
            "Epoch 75 Batch 7 Loss 1.6869\n",
            "Epoch 75 Batch 8 Loss 1.6878\n",
            "Epoch 75 Batch 9 Loss 1.6838\n",
            "Epoch 75 Batch 10 Loss 1.6927\n",
            "Epoch 75 Batch 11 Loss 1.6938\n",
            "Epoch 75 Batch 12 Loss 1.6874\n",
            "Epoch 75 Batch 13 Loss 1.6949\n",
            "Epoch 75 Batch 14 Loss 1.6927\n",
            "Epoch 75 Batch 15 Loss 1.6906\n",
            "Epoch 75 Loss 1.6906\n",
            "Time taken for 1 epoch: 3.612818956375122 secs\n",
            "\n",
            "Epoch 76 Batch 0 Loss 1.6399\n",
            "Epoch 76 Batch 1 Loss 1.6350\n",
            "Epoch 76 Batch 2 Loss 1.5972\n",
            "Epoch 76 Batch 3 Loss 1.6128\n",
            "Epoch 76 Batch 4 Loss 1.6434\n",
            "Epoch 76 Batch 5 Loss 1.6168\n",
            "Epoch 76 Batch 6 Loss 1.6218\n",
            "Epoch 76 Batch 7 Loss 1.6216\n",
            "Epoch 76 Batch 8 Loss 1.6274\n",
            "Epoch 76 Batch 9 Loss 1.6198\n",
            "Epoch 76 Batch 10 Loss 1.6122\n",
            "Epoch 76 Batch 11 Loss 1.6038\n",
            "Epoch 76 Batch 12 Loss 1.5989\n",
            "Epoch 76 Batch 13 Loss 1.5876\n",
            "Epoch 76 Batch 14 Loss 1.5923\n",
            "Epoch 76 Batch 15 Loss 1.6018\n",
            "Epoch 76 Loss 1.6018\n",
            "Time taken for 1 epoch: 3.6208770275115967 secs\n",
            "\n",
            "Epoch 77 Batch 0 Loss 1.5402\n",
            "Epoch 77 Batch 1 Loss 1.5891\n",
            "Epoch 77 Batch 2 Loss 1.5394\n",
            "Epoch 77 Batch 3 Loss 1.5237\n",
            "Epoch 77 Batch 4 Loss 1.5279\n",
            "Epoch 77 Batch 5 Loss 1.5156\n",
            "Epoch 77 Batch 6 Loss 1.5088\n",
            "Epoch 77 Batch 7 Loss 1.4981\n",
            "Epoch 77 Batch 8 Loss 1.4947\n",
            "Epoch 77 Batch 9 Loss 1.5007\n",
            "Epoch 77 Batch 10 Loss 1.5059\n",
            "Epoch 77 Batch 11 Loss 1.5084\n",
            "Epoch 77 Batch 12 Loss 1.5115\n",
            "Epoch 77 Batch 13 Loss 1.5061\n",
            "Epoch 77 Batch 14 Loss 1.5033\n",
            "Epoch 77 Batch 15 Loss 1.5002\n",
            "Epoch 77 Loss 1.5002\n",
            "Time taken for 1 epoch: 3.6372156143188477 secs\n",
            "\n",
            "Epoch 78 Batch 0 Loss 1.4474\n",
            "Epoch 78 Batch 1 Loss 1.4570\n",
            "Epoch 78 Batch 2 Loss 1.4562\n",
            "Epoch 78 Batch 3 Loss 1.4251\n",
            "Epoch 78 Batch 4 Loss 1.4283\n",
            "Epoch 78 Batch 5 Loss 1.4234\n",
            "Epoch 78 Batch 6 Loss 1.4282\n",
            "Epoch 78 Batch 7 Loss 1.4191\n",
            "Epoch 78 Batch 8 Loss 1.4167\n",
            "Epoch 78 Batch 9 Loss 1.4114\n",
            "Epoch 78 Batch 10 Loss 1.4068\n",
            "Epoch 78 Batch 11 Loss 1.4108\n",
            "Epoch 78 Batch 12 Loss 1.4081\n",
            "Epoch 78 Batch 13 Loss 1.4093\n",
            "Epoch 78 Batch 14 Loss 1.4122\n",
            "Epoch 78 Batch 15 Loss 1.4119\n",
            "Epoch 78 Loss 1.4119\n",
            "Time taken for 1 epoch: 3.629312038421631 secs\n",
            "\n",
            "Epoch 79 Batch 0 Loss 1.3558\n",
            "Epoch 79 Batch 1 Loss 1.3237\n",
            "Epoch 79 Batch 2 Loss 1.3138\n",
            "Epoch 79 Batch 3 Loss 1.3389\n",
            "Epoch 79 Batch 4 Loss 1.3481\n",
            "Epoch 79 Batch 5 Loss 1.3425\n",
            "Epoch 79 Batch 6 Loss 1.3519\n",
            "Epoch 79 Batch 7 Loss 1.3483\n",
            "Epoch 79 Batch 8 Loss 1.3395\n",
            "Epoch 79 Batch 9 Loss 1.3332\n",
            "Epoch 79 Batch 10 Loss 1.3359\n",
            "Epoch 79 Batch 11 Loss 1.3378\n",
            "Epoch 79 Batch 12 Loss 1.3218\n",
            "Epoch 79 Batch 13 Loss 1.3204\n",
            "Epoch 79 Batch 14 Loss 1.3184\n",
            "Epoch 79 Batch 15 Loss 1.3112\n",
            "Epoch 79 Loss 1.3112\n",
            "Time taken for 1 epoch: 3.6058096885681152 secs\n",
            "\n",
            "Epoch 80 Batch 0 Loss 1.2255\n",
            "Epoch 80 Batch 1 Loss 1.2309\n",
            "Epoch 80 Batch 2 Loss 1.2398\n",
            "Epoch 80 Batch 3 Loss 1.2266\n",
            "Epoch 80 Batch 4 Loss 1.2315\n",
            "Epoch 80 Batch 5 Loss 1.2300\n",
            "Epoch 80 Batch 6 Loss 1.2294\n",
            "Epoch 80 Batch 7 Loss 1.2285\n",
            "Epoch 80 Batch 8 Loss 1.2206\n",
            "Epoch 80 Batch 9 Loss 1.2194\n",
            "Epoch 80 Batch 10 Loss 1.2269\n",
            "Epoch 80 Batch 11 Loss 1.2254\n",
            "Epoch 80 Batch 12 Loss 1.2225\n",
            "Epoch 80 Batch 13 Loss 1.2218\n",
            "Epoch 80 Batch 14 Loss 1.2229\n",
            "Epoch 80 Batch 15 Loss 1.2225\n",
            "Epoch 80 Loss 1.2225\n",
            "Time taken for 1 epoch: 3.6299030780792236 secs\n",
            "\n",
            "Epoch 81 Batch 0 Loss 1.1679\n",
            "Epoch 81 Batch 1 Loss 1.1692\n",
            "Epoch 81 Batch 2 Loss 1.1851\n",
            "Epoch 81 Batch 3 Loss 1.1999\n",
            "Epoch 81 Batch 4 Loss 1.1743\n",
            "Epoch 81 Batch 5 Loss 1.1673\n",
            "Epoch 81 Batch 6 Loss 1.1590\n",
            "Epoch 81 Batch 7 Loss 1.1668\n",
            "Epoch 81 Batch 8 Loss 1.1703\n",
            "Epoch 81 Batch 9 Loss 1.1576\n",
            "Epoch 81 Batch 10 Loss 1.1550\n",
            "Epoch 81 Batch 11 Loss 1.1503\n",
            "Epoch 81 Batch 12 Loss 1.1447\n",
            "Epoch 81 Batch 13 Loss 1.1403\n",
            "Epoch 81 Batch 14 Loss 1.1414\n",
            "Epoch 81 Batch 15 Loss 1.1406\n",
            "Epoch 81 Loss 1.1406\n",
            "Time taken for 1 epoch: 3.608872890472412 secs\n",
            "\n",
            "Epoch 82 Batch 0 Loss 1.0079\n",
            "Epoch 82 Batch 1 Loss 1.0455\n",
            "Epoch 82 Batch 2 Loss 1.0742\n",
            "Epoch 82 Batch 3 Loss 1.0849\n",
            "Epoch 82 Batch 4 Loss 1.0850\n",
            "Epoch 82 Batch 5 Loss 1.0829\n",
            "Epoch 82 Batch 6 Loss 1.0752\n",
            "Epoch 82 Batch 7 Loss 1.0676\n",
            "Epoch 82 Batch 8 Loss 1.0632\n",
            "Epoch 82 Batch 9 Loss 1.0562\n",
            "Epoch 82 Batch 10 Loss 1.0561\n",
            "Epoch 82 Batch 11 Loss 1.0569\n",
            "Epoch 82 Batch 12 Loss 1.0593\n",
            "Epoch 82 Batch 13 Loss 1.0575\n",
            "Epoch 82 Batch 14 Loss 1.0579\n",
            "Epoch 82 Batch 15 Loss 1.0568\n",
            "Epoch 82 Loss 1.0568\n",
            "Time taken for 1 epoch: 3.6400821208953857 secs\n",
            "\n",
            "Epoch 83 Batch 0 Loss 0.9376\n",
            "Epoch 83 Batch 1 Loss 0.9289\n",
            "Epoch 83 Batch 2 Loss 0.9410\n",
            "Epoch 83 Batch 3 Loss 0.9683\n",
            "Epoch 83 Batch 4 Loss 0.9500\n",
            "Epoch 83 Batch 5 Loss 0.9694\n",
            "Epoch 83 Batch 6 Loss 0.9703\n",
            "Epoch 83 Batch 7 Loss 0.9779\n",
            "Epoch 83 Batch 8 Loss 0.9751\n",
            "Epoch 83 Batch 9 Loss 0.9777\n",
            "Epoch 83 Batch 10 Loss 0.9820\n",
            "Epoch 83 Batch 11 Loss 0.9834\n",
            "Epoch 83 Batch 12 Loss 0.9794\n",
            "Epoch 83 Batch 13 Loss 0.9799\n",
            "Epoch 83 Batch 14 Loss 0.9775\n",
            "Epoch 83 Batch 15 Loss 0.9762\n",
            "Epoch 83 Loss 0.9762\n",
            "Time taken for 1 epoch: 3.6233065128326416 secs\n",
            "\n",
            "Epoch 84 Batch 0 Loss 0.9124\n",
            "Epoch 84 Batch 1 Loss 0.9102\n",
            "Epoch 84 Batch 2 Loss 0.9030\n",
            "Epoch 84 Batch 3 Loss 0.8969\n",
            "Epoch 84 Batch 4 Loss 0.9054\n",
            "Epoch 84 Batch 5 Loss 0.9019\n",
            "Epoch 84 Batch 6 Loss 0.9060\n",
            "Epoch 84 Batch 7 Loss 0.9170\n",
            "Epoch 84 Batch 8 Loss 0.9187\n",
            "Epoch 84 Batch 9 Loss 0.9151\n",
            "Epoch 84 Batch 10 Loss 0.9119\n",
            "Epoch 84 Batch 11 Loss 0.9066\n",
            "Epoch 84 Batch 12 Loss 0.9069\n",
            "Epoch 84 Batch 13 Loss 0.9004\n",
            "Epoch 84 Batch 14 Loss 0.8975\n",
            "Epoch 84 Batch 15 Loss 0.8975\n",
            "Epoch 84 Loss 0.8975\n",
            "Time taken for 1 epoch: 3.604285478591919 secs\n",
            "\n",
            "Epoch 85 Batch 0 Loss 0.8843\n",
            "Epoch 85 Batch 1 Loss 0.8663\n",
            "Epoch 85 Batch 2 Loss 0.8399\n",
            "Epoch 85 Batch 3 Loss 0.8206\n",
            "Epoch 85 Batch 4 Loss 0.8173\n",
            "Epoch 85 Batch 5 Loss 0.8182\n",
            "Epoch 85 Batch 6 Loss 0.8152\n",
            "Epoch 85 Batch 7 Loss 0.8146\n",
            "Epoch 85 Batch 8 Loss 0.8184\n",
            "Epoch 85 Batch 9 Loss 0.8119\n",
            "Epoch 85 Batch 10 Loss 0.8085\n",
            "Epoch 85 Batch 11 Loss 0.8145\n",
            "Epoch 85 Batch 12 Loss 0.8113\n",
            "Epoch 85 Batch 13 Loss 0.8161\n",
            "Epoch 85 Batch 14 Loss 0.8145\n",
            "Epoch 85 Batch 15 Loss 0.8155\n",
            "Epoch 85 Loss 0.8155\n",
            "Time taken for 1 epoch: 3.620495557785034 secs\n",
            "\n",
            "Epoch 86 Batch 0 Loss 0.8086\n",
            "Epoch 86 Batch 1 Loss 0.7830\n",
            "Epoch 86 Batch 2 Loss 0.7731\n",
            "Epoch 86 Batch 3 Loss 0.7736\n",
            "Epoch 86 Batch 4 Loss 0.7693\n",
            "Epoch 86 Batch 5 Loss 0.7703\n",
            "Epoch 86 Batch 6 Loss 0.7600\n",
            "Epoch 86 Batch 7 Loss 0.7579\n",
            "Epoch 86 Batch 8 Loss 0.7572\n",
            "Epoch 86 Batch 9 Loss 0.7595\n",
            "Epoch 86 Batch 10 Loss 0.7624\n",
            "Epoch 86 Batch 11 Loss 0.7596\n",
            "Epoch 86 Batch 12 Loss 0.7572\n",
            "Epoch 86 Batch 13 Loss 0.7530\n",
            "Epoch 86 Batch 14 Loss 0.7483\n",
            "Epoch 86 Batch 15 Loss 0.7494\n",
            "Epoch 86 Loss 0.7494\n",
            "Time taken for 1 epoch: 3.656405210494995 secs\n",
            "\n",
            "Epoch 87 Batch 0 Loss 0.7148\n",
            "Epoch 87 Batch 1 Loss 0.7127\n",
            "Epoch 87 Batch 2 Loss 0.7110\n",
            "Epoch 87 Batch 3 Loss 0.6983\n",
            "Epoch 87 Batch 4 Loss 0.7000\n",
            "Epoch 87 Batch 5 Loss 0.6988\n",
            "Epoch 87 Batch 6 Loss 0.7027\n",
            "Epoch 87 Batch 7 Loss 0.6992\n",
            "Epoch 87 Batch 8 Loss 0.7037\n",
            "Epoch 87 Batch 9 Loss 0.6949\n",
            "Epoch 87 Batch 10 Loss 0.6912\n",
            "Epoch 87 Batch 11 Loss 0.6916\n",
            "Epoch 87 Batch 12 Loss 0.6936\n",
            "Epoch 87 Batch 13 Loss 0.6929\n",
            "Epoch 87 Batch 14 Loss 0.6922\n",
            "Epoch 87 Batch 15 Loss 0.6904\n",
            "Epoch 87 Loss 0.6904\n",
            "Time taken for 1 epoch: 3.6450295448303223 secs\n",
            "\n",
            "Epoch 88 Batch 0 Loss 0.6553\n",
            "Epoch 88 Batch 1 Loss 0.6311\n",
            "Epoch 88 Batch 2 Loss 0.6331\n",
            "Epoch 88 Batch 3 Loss 0.6466\n",
            "Epoch 88 Batch 4 Loss 0.6382\n",
            "Epoch 88 Batch 5 Loss 0.6384\n",
            "Epoch 88 Batch 6 Loss 0.6277\n",
            "Epoch 88 Batch 7 Loss 0.6334\n",
            "Epoch 88 Batch 8 Loss 0.6307\n",
            "Epoch 88 Batch 9 Loss 0.6297\n",
            "Epoch 88 Batch 10 Loss 0.6282\n",
            "Epoch 88 Batch 11 Loss 0.6226\n",
            "Epoch 88 Batch 12 Loss 0.6224\n",
            "Epoch 88 Batch 13 Loss 0.6239\n",
            "Epoch 88 Batch 14 Loss 0.6223\n",
            "Epoch 88 Batch 15 Loss 0.6224\n",
            "Epoch 88 Loss 0.6224\n",
            "Time taken for 1 epoch: 3.6690404415130615 secs\n",
            "\n",
            "Epoch 89 Batch 0 Loss 0.6235\n",
            "Epoch 89 Batch 1 Loss 0.5677\n",
            "Epoch 89 Batch 2 Loss 0.5581\n",
            "Epoch 89 Batch 3 Loss 0.5659\n",
            "Epoch 89 Batch 4 Loss 0.5616\n",
            "Epoch 89 Batch 5 Loss 0.5585\n",
            "Epoch 89 Batch 6 Loss 0.5602\n",
            "Epoch 89 Batch 7 Loss 0.5622\n",
            "Epoch 89 Batch 8 Loss 0.5626\n",
            "Epoch 89 Batch 9 Loss 0.5630\n",
            "Epoch 89 Batch 10 Loss 0.5655\n",
            "Epoch 89 Batch 11 Loss 0.5693\n",
            "Epoch 89 Batch 12 Loss 0.5672\n",
            "Epoch 89 Batch 13 Loss 0.5696\n",
            "Epoch 89 Batch 14 Loss 0.5702\n",
            "Epoch 89 Batch 15 Loss 0.5678\n",
            "Epoch 89 Loss 0.5678\n",
            "Time taken for 1 epoch: 3.6326730251312256 secs\n",
            "\n",
            "Epoch 90 Batch 0 Loss 0.5441\n",
            "Epoch 90 Batch 1 Loss 0.5174\n",
            "Epoch 90 Batch 2 Loss 0.5187\n",
            "Epoch 90 Batch 3 Loss 0.5032\n",
            "Epoch 90 Batch 4 Loss 0.5108\n",
            "Epoch 90 Batch 5 Loss 0.5129\n",
            "Epoch 90 Batch 6 Loss 0.5078\n",
            "Epoch 90 Batch 7 Loss 0.5107\n",
            "Epoch 90 Batch 8 Loss 0.5057\n",
            "Epoch 90 Batch 9 Loss 0.5101\n",
            "Epoch 90 Batch 10 Loss 0.5057\n",
            "Epoch 90 Batch 11 Loss 0.5079\n",
            "Epoch 90 Batch 12 Loss 0.5099\n",
            "Epoch 90 Batch 13 Loss 0.5117\n",
            "Epoch 90 Batch 14 Loss 0.5125\n",
            "Epoch 90 Batch 15 Loss 0.5141\n",
            "Epoch 90 Loss 0.5141\n",
            "Time taken for 1 epoch: 3.6346492767333984 secs\n",
            "\n",
            "Epoch 91 Batch 0 Loss 0.4811\n",
            "Epoch 91 Batch 1 Loss 0.4648\n",
            "Epoch 91 Batch 2 Loss 0.4662\n",
            "Epoch 91 Batch 3 Loss 0.4676\n",
            "Epoch 91 Batch 4 Loss 0.4620\n",
            "Epoch 91 Batch 5 Loss 0.4678\n",
            "Epoch 91 Batch 6 Loss 0.4711\n",
            "Epoch 91 Batch 7 Loss 0.4749\n",
            "Epoch 91 Batch 8 Loss 0.4709\n",
            "Epoch 91 Batch 9 Loss 0.4695\n",
            "Epoch 91 Batch 10 Loss 0.4666\n",
            "Epoch 91 Batch 11 Loss 0.4627\n",
            "Epoch 91 Batch 12 Loss 0.4626\n",
            "Epoch 91 Batch 13 Loss 0.4631\n",
            "Epoch 91 Batch 14 Loss 0.4638\n",
            "Epoch 91 Batch 15 Loss 0.4609\n",
            "Epoch 91 Loss 0.4609\n",
            "Time taken for 1 epoch: 3.610853910446167 secs\n",
            "\n",
            "Epoch 92 Batch 0 Loss 0.4048\n",
            "Epoch 92 Batch 1 Loss 0.4221\n",
            "Epoch 92 Batch 2 Loss 0.4122\n",
            "Epoch 92 Batch 3 Loss 0.4143\n",
            "Epoch 92 Batch 4 Loss 0.4150\n",
            "Epoch 92 Batch 5 Loss 0.4123\n",
            "Epoch 92 Batch 6 Loss 0.4159\n",
            "Epoch 92 Batch 7 Loss 0.4137\n",
            "Epoch 92 Batch 8 Loss 0.4109\n",
            "Epoch 92 Batch 9 Loss 0.4132\n",
            "Epoch 92 Batch 10 Loss 0.4142\n",
            "Epoch 92 Batch 11 Loss 0.4139\n",
            "Epoch 92 Batch 12 Loss 0.4125\n",
            "Epoch 92 Batch 13 Loss 0.4116\n",
            "Epoch 92 Batch 14 Loss 0.4083\n",
            "Epoch 92 Batch 15 Loss 0.4076\n",
            "Epoch 92 Loss 0.4076\n",
            "Time taken for 1 epoch: 3.6184256076812744 secs\n",
            "\n",
            "Epoch 93 Batch 0 Loss 0.3765\n",
            "Epoch 93 Batch 1 Loss 0.3862\n",
            "Epoch 93 Batch 2 Loss 0.3807\n",
            "Epoch 93 Batch 3 Loss 0.3752\n",
            "Epoch 93 Batch 4 Loss 0.3698\n",
            "Epoch 93 Batch 5 Loss 0.3685\n",
            "Epoch 93 Batch 6 Loss 0.3670\n",
            "Epoch 93 Batch 7 Loss 0.3638\n",
            "Epoch 93 Batch 8 Loss 0.3619\n",
            "Epoch 93 Batch 9 Loss 0.3635\n",
            "Epoch 93 Batch 10 Loss 0.3610\n",
            "Epoch 93 Batch 11 Loss 0.3605\n",
            "Epoch 93 Batch 12 Loss 0.3603\n",
            "Epoch 93 Batch 13 Loss 0.3607\n",
            "Epoch 93 Batch 14 Loss 0.3624\n",
            "Epoch 93 Batch 15 Loss 0.3644\n",
            "Epoch 93 Loss 0.3644\n",
            "Time taken for 1 epoch: 3.6242752075195312 secs\n",
            "\n",
            "Epoch 94 Batch 0 Loss 0.3235\n",
            "Epoch 94 Batch 1 Loss 0.3289\n",
            "Epoch 94 Batch 2 Loss 0.3430\n",
            "Epoch 94 Batch 3 Loss 0.3397\n",
            "Epoch 94 Batch 4 Loss 0.3341\n",
            "Epoch 94 Batch 5 Loss 0.3312\n",
            "Epoch 94 Batch 6 Loss 0.3311\n",
            "Epoch 94 Batch 7 Loss 0.3324\n",
            "Epoch 94 Batch 8 Loss 0.3323\n",
            "Epoch 94 Batch 9 Loss 0.3314\n",
            "Epoch 94 Batch 10 Loss 0.3317\n",
            "Epoch 94 Batch 11 Loss 0.3306\n",
            "Epoch 94 Batch 12 Loss 0.3308\n",
            "Epoch 94 Batch 13 Loss 0.3290\n",
            "Epoch 94 Batch 14 Loss 0.3287\n",
            "Epoch 94 Batch 15 Loss 0.3300\n",
            "Epoch 94 Loss 0.3300\n",
            "Time taken for 1 epoch: 3.6144721508026123 secs\n",
            "\n",
            "Epoch 95 Batch 0 Loss 0.2933\n",
            "Epoch 95 Batch 1 Loss 0.3042\n",
            "Epoch 95 Batch 2 Loss 0.3018\n",
            "Epoch 95 Batch 3 Loss 0.2999\n",
            "Epoch 95 Batch 4 Loss 0.2944\n",
            "Epoch 95 Batch 5 Loss 0.2970\n",
            "Epoch 95 Batch 6 Loss 0.2969\n",
            "Epoch 95 Batch 7 Loss 0.2982\n",
            "Epoch 95 Batch 8 Loss 0.2969\n",
            "Epoch 95 Batch 9 Loss 0.2958\n",
            "Epoch 95 Batch 10 Loss 0.2972\n",
            "Epoch 95 Batch 11 Loss 0.2975\n",
            "Epoch 95 Batch 12 Loss 0.2983\n",
            "Epoch 95 Batch 13 Loss 0.2984\n",
            "Epoch 95 Batch 14 Loss 0.2966\n",
            "Epoch 95 Batch 15 Loss 0.2968\n",
            "Epoch 95 Loss 0.2968\n",
            "Time taken for 1 epoch: 3.6267192363739014 secs\n",
            "\n",
            "Epoch 96 Batch 0 Loss 0.2917\n",
            "Epoch 96 Batch 1 Loss 0.2889\n",
            "Epoch 96 Batch 2 Loss 0.2734\n",
            "Epoch 96 Batch 3 Loss 0.2710\n",
            "Epoch 96 Batch 4 Loss 0.2706\n",
            "Epoch 96 Batch 5 Loss 0.2711\n",
            "Epoch 96 Batch 6 Loss 0.2694\n",
            "Epoch 96 Batch 7 Loss 0.2696\n",
            "Epoch 96 Batch 8 Loss 0.2694\n",
            "Epoch 96 Batch 9 Loss 0.2696\n",
            "Epoch 96 Batch 10 Loss 0.2682\n",
            "Epoch 96 Batch 11 Loss 0.2667\n",
            "Epoch 96 Batch 12 Loss 0.2657\n",
            "Epoch 96 Batch 13 Loss 0.2648\n",
            "Epoch 96 Batch 14 Loss 0.2629\n",
            "Epoch 96 Batch 15 Loss 0.2640\n",
            "Epoch 96 Loss 0.2640\n",
            "Time taken for 1 epoch: 3.61763596534729 secs\n",
            "\n",
            "Epoch 97 Batch 0 Loss 0.2194\n",
            "Epoch 97 Batch 1 Loss 0.2262\n",
            "Epoch 97 Batch 2 Loss 0.2269\n",
            "Epoch 97 Batch 3 Loss 0.2312\n",
            "Epoch 97 Batch 4 Loss 0.2342\n",
            "Epoch 97 Batch 5 Loss 0.2345\n",
            "Epoch 97 Batch 6 Loss 0.2336\n",
            "Epoch 97 Batch 7 Loss 0.2307\n",
            "Epoch 97 Batch 8 Loss 0.2280\n",
            "Epoch 97 Batch 9 Loss 0.2276\n",
            "Epoch 97 Batch 10 Loss 0.2272\n",
            "Epoch 97 Batch 11 Loss 0.2269\n",
            "Epoch 97 Batch 12 Loss 0.2269\n",
            "Epoch 97 Batch 13 Loss 0.2287\n",
            "Epoch 97 Batch 14 Loss 0.2267\n",
            "Epoch 97 Batch 15 Loss 0.2255\n",
            "Epoch 97 Loss 0.2255\n",
            "Time taken for 1 epoch: 3.6143033504486084 secs\n",
            "\n",
            "Epoch 98 Batch 0 Loss 0.2229\n",
            "Epoch 98 Batch 1 Loss 0.2152\n",
            "Epoch 98 Batch 2 Loss 0.2057\n",
            "Epoch 98 Batch 3 Loss 0.2005\n",
            "Epoch 98 Batch 4 Loss 0.2004\n",
            "Epoch 98 Batch 5 Loss 0.2005\n",
            "Epoch 98 Batch 6 Loss 0.2001\n",
            "Epoch 98 Batch 7 Loss 0.2014\n",
            "Epoch 98 Batch 8 Loss 0.2038\n",
            "Epoch 98 Batch 9 Loss 0.2020\n",
            "Epoch 98 Batch 10 Loss 0.2024\n",
            "Epoch 98 Batch 11 Loss 0.2013\n",
            "Epoch 98 Batch 12 Loss 0.2022\n",
            "Epoch 98 Batch 13 Loss 0.2009\n",
            "Epoch 98 Batch 14 Loss 0.1992\n",
            "Epoch 98 Batch 15 Loss 0.1991\n",
            "Epoch 98 Loss 0.1991\n",
            "Time taken for 1 epoch: 3.638366460800171 secs\n",
            "\n",
            "Epoch 99 Batch 0 Loss 0.2042\n",
            "Epoch 99 Batch 1 Loss 0.1873\n",
            "Epoch 99 Batch 2 Loss 0.1808\n",
            "Epoch 99 Batch 3 Loss 0.1742\n",
            "Epoch 99 Batch 4 Loss 0.1755\n",
            "Epoch 99 Batch 5 Loss 0.1739\n",
            "Epoch 99 Batch 6 Loss 0.1745\n",
            "Epoch 99 Batch 7 Loss 0.1756\n",
            "Epoch 99 Batch 8 Loss 0.1741\n",
            "Epoch 99 Batch 9 Loss 0.1739\n",
            "Epoch 99 Batch 10 Loss 0.1726\n",
            "Epoch 99 Batch 11 Loss 0.1716\n",
            "Epoch 99 Batch 12 Loss 0.1706\n",
            "Epoch 99 Batch 13 Loss 0.1698\n",
            "Epoch 99 Batch 14 Loss 0.1697\n",
            "Epoch 99 Batch 15 Loss 0.1708\n",
            "Epoch 99 Loss 0.1708\n",
            "Time taken for 1 epoch: 3.598783254623413 secs\n",
            "\n",
            "Epoch 100 Batch 0 Loss 0.1471\n",
            "Epoch 100 Batch 1 Loss 0.1452\n",
            "Epoch 100 Batch 2 Loss 0.1468\n",
            "Epoch 100 Batch 3 Loss 0.1457\n",
            "Epoch 100 Batch 4 Loss 0.1441\n",
            "Epoch 100 Batch 5 Loss 0.1436\n",
            "Epoch 100 Batch 6 Loss 0.1465\n",
            "Epoch 100 Batch 7 Loss 0.1467\n",
            "Epoch 100 Batch 8 Loss 0.1469\n",
            "Epoch 100 Batch 9 Loss 0.1473\n",
            "Epoch 100 Batch 10 Loss 0.1469\n",
            "Epoch 100 Batch 11 Loss 0.1470\n",
            "Epoch 100 Batch 12 Loss 0.1470\n",
            "Epoch 100 Batch 13 Loss 0.1472\n",
            "Epoch 100 Batch 14 Loss 0.1472\n",
            "Epoch 100 Batch 15 Loss 0.1477\n",
            "Epoch 100 Loss 0.1477\n",
            "Time taken for 1 epoch: 3.6015138626098633 secs\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-VP6qAOek6a"
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm1hsVDxZPuj"
      },
      "source": [
        "epochs = list(range(1,101))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbBoOpETaG4m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "d2516502-d6fb-4f7a-cdab-23e9f19fb760"
      },
      "source": [
        "plt.plot(epochs, los, 'g', label='Training-loss')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f3b4eaa02b0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVbEUCZagJ0G"
      },
      "source": [
        "### Inference"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMbqGTixu1cl"
      },
      "source": [
        "#### Predicting one word at a time at the decoder and appending it to the output; then taking the complete sequence as an input to the decoder and repeating until maxlen or stop keyword appears"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5D5cv2Jd8-6"
      },
      "source": [
        "def evaluate(input_document):\n",
        "    input_document = document_tokenizer.texts_to_sequences([input_document])\n",
        "    input_document = tf.keras.preprocessing.sequence.pad_sequences(input_document, maxlen=encoder_maxlen, padding='post', truncating='post')\n",
        "\n",
        "    encoder_input = tf.expand_dims(input_document[0], 0)\n",
        "\n",
        "    decoder_input = [summary_tokenizer.word_index[\"<go>\"]]\n",
        "    output = tf.expand_dims(decoder_input, 0)\n",
        "    \n",
        "    for i in range(decoder_maxlen):\n",
        "        enc_padding_mask, combined_mask, dec_padding_mask = create_masks(encoder_input, output)\n",
        "\n",
        "        predictions, attention_weights = transformer(\n",
        "            encoder_input, \n",
        "            output,\n",
        "            False,\n",
        "            enc_padding_mask,\n",
        "            combined_mask,\n",
        "            dec_padding_mask\n",
        "        )\n",
        "\n",
        "        predictions = predictions[: ,-1:, :]\n",
        "        predicted_id = tf.cast(tf.argmax(predictions, axis=-1), tf.int32)\n",
        "\n",
        "        if predicted_id == summary_tokenizer.word_index[\"<stop>\"]:\n",
        "            return tf.squeeze(output, axis=0), attention_weights\n",
        "\n",
        "        output = tf.concat([output, predicted_id], axis=-1)\n",
        "\n",
        "    return tf.squeeze(output, axis=0), attention_weights\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkpdiW6wnmiS"
      },
      "source": [
        "def summarize(input_document):\n",
        "    # not considering attention weights for now, can be used to plot attention heatmaps in the future\n",
        "    summarized = evaluate(input_document=input_document)[0].numpy()\n",
        "    summarized = np.expand_dims(summarized[1:], 0)  # not printing <go> token\n",
        "    return summary_tokenizer.sequences_to_texts(summarized)[0]  # since there is just one translated document"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GXWnF1cvoQzn"
      },
      "source": [
        "from nltk.translate.bleu_score import sentence_bleu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsro2umMqH5a"
      },
      "source": [
        "so = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z23sZmcboReS"
      },
      "source": [
        "for i in news['text']:\n",
        "  out = summarize(i)\n",
        "  so.append(out)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lOx6q-WtOdz"
      },
      "source": [
        "docs = news['text']\n",
        "sums = news['summary']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfdAJZ-fwk4x"
      },
      "source": [
        "bl = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6BaUamPltO7w",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "outputId": "9c4acfe5-a608-4289-ac8b-c1cef85a8b85"
      },
      "source": [
        "for i,j in zip(sums,so):\n",
        "  reference = [i.split()]\n",
        "  candidate = j.split()\n",
        "  score = sentence_bleu(reference, candidate,smoothing_function=None)\n",
        "  bl.append(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 4-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 3-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iFoT98-jM_Uv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5f039c2-54a5-423e-ac95-dfb100ef417c"
      },
      "source": [
        "len(bl)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1007"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FCD32T0JNpBC"
      },
      "source": [
        "av_bl = sum(bl) / len(bl)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs62s7kRNwdv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "178ee2b9-23d5-40ee-f086-33e363b8b4f2"
      },
      "source": [
        "av_bl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8795734662674392"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Ta6lcJtStEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "adcc387f-29d6-414b-816f-533f899a852a"
      },
      "source": [
        "so"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['ఆర్మీ జవాన్\\u200cకు కరోనా పాజిటివ్\\u200c',\n",
              " 'యస్\\u200c’ పునర్నిర్మాణ పథకం త్వరలోనే ఆంక్షలు ఎత్తివేత',\n",
              " 'చంద్రబాబు క్షమాపణ చెప్పాలి',\n",
              " '‘ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు’',\n",
              " 'తల్లి గిరిజను కలిసిన అమృతా ప్రణయ్\\u200c',\n",
              " 'ఆ తర్వాత టీడీపీని ఓఎల్\\u200cఎక్స్\\u200cలో పెట్టుకోవాలి',\n",
              " 'షెడ్యూల్\\u200c ప్రకారమే ఒలింపిక్స్\\u200c జపాన్\\u200c ప్రధాని',\n",
              " 'కోల్\\u200cకతాకే ఐఎస్\\u200cఎల్\\u200c కిరీటం',\n",
              " '31 వరకు దేశంలో ‘నో’ ఫుట్\\u200cబాల్\\u200c',\n",
              " 'తల్లి భర్త మోసం నవవధువు ఆత్మహత్య',\n",
              " '24 గంటల్లో వంద మరణాలు 2వేల కరోనా కేసులు కరోనా',\n",
              " 'నా ప్రతి చరణం ఒక ఆత్మ విమర్శ',\n",
              " 'ప్రేమ కల చెదిరింది డాక్టర్\\u200c గుండె ఆగింది',\n",
              " 'బీటెక్\\u200c కొత్త కోర్సుల్లో 21 వేల సీట్లు',\n",
              " 'మన వ్యవసాయ కేటాయింపులు జాతీయసగటు కంటే ఎక్కువ',\n",
              " 'బడ్జెట్\\u200c సమావేశాలు కుదింపు',\n",
              " 'చెక్\\u200cడ్యామ్\\u200cలతో 15 టీఎంసీల నిల్వ',\n",
              " 'ఎండలతో కరోనా తగ్గుముఖం',\n",
              " 'రూ 24 577 కోట్లు 2 253 పరిశ్రమలు',\n",
              " 'కరోనా ఎఫెక్ట్\\u200c విద్యా సంస్థలు మాల్స్\\u200c మూసివేత',\n",
              " 'స్వల్పంగా దిగివచ్చిన పెట్రో ధరలు',\n",
              " 'సెల్\\u200cఫోన్లపై జీఎస్టీ ఇకపై 18',\n",
              " 'వోడాఫోన్\\u200c ఐడియా కొత్త ప్లాన్లు అన్\\u200cలిమిటెడ్\\u200c కాల్స్\\u200c',\n",
              " 'స్మార్ట్\\u200c ఫోన్లకు జీఎస్\\u200cటీ షాక్',\n",
              " 'యస్\\u200c బ్యాంకు మరో రూ 600 కోట్లు',\n",
              " 'యస్\\u200c బ్యాంకు సత\\u200d్వర చర్యలు కస\\u200d్టమర్లకు ఊరట',\n",
              " 'పెట్రోల్\\u200c డీజిల్\\u200cపై ఎక్సైజ్\\u200c సుంకం పెంపు',\n",
              " 'మైక్రోసాఫ్ట్\\u200cకు బిల్\\u200cగేట్స్\\u200c రాజీనామా',\n",
              " 'స్టాక్\\u200c మార్కెట్లో ట్రేడింగ్\\u200cను 45 నిమిషాల పాటు నిలిపేశారు నిలిపేశారు',\n",
              " '‘యస్\\u200c’ ప్రణాళికకు కేంద్రం ఓకే త్వరలో మారటోరియం ఎత్తివేత',\n",
              " '‘కోవిడ్\\u200c’ కోస్టర్\\u200c 45 నిమిషాల పాటు ట్రేడింగ్\\u200c నిలిపివేత',\n",
              " 'తగ్గిన బంగారం ధరలు',\n",
              " 'యస్\\u200c సంక్షోభం పెట్టుబడుల వెల్లువ',\n",
              " 'ఆ దేశాలకు ఎయిరిండియా సర్వీసులు రద్దు',\n",
              " '‘యస్\\u200c’ పునర్నిర్మాణ పథకం త్వరలోనే ఆంక్షలు ఎత్తివేత నోటిఫికేషన్\\u200c ఎత్తివేత',\n",
              " 'కరోనా ‘ఈ మధ్యకాలంలో ఇదే గొప్ప బహుమతి’',\n",
              " 'విలయం నుంచి భారీ రికవరీ',\n",
              " 'ఉద్యోగులకు తీపి కబురు కేంద్ర ప్రభుత్వ ఉద్యోగులకు దీపావళి దీపావళి',\n",
              " 'స్టాక్\\u200cమార్కెట్\\u200cలో భారీ రికవరీ',\n",
              " '‘యస్\\u200c’బీఐ ప్రణాళికకు ఓకే',\n",
              " 'మార్కెట్ల మహాపతనం ట్రేడింగ్\\u200c నిలిపివేత',\n",
              " 'సెన్సెక్స్ 3100 పాయింట్లు క్రాష్ 10వేల కిందికి నిఫ్టీ',\n",
              " 'క్యాన్సర్\\u200cకు వ్యతిరేకంగా యువరాజ్ సింగ్\\u200cపోరాటం ‘యూవీకాన్’తో ‘పేబ్యాక్’ భాగస్వామ్యం భాగస్వామ్యం',\n",
              " 'భారత్\\u200cలో తొలి ఎలక్ట్రిక్\\u200c ట్రాక్టర్\\u200c',\n",
              " 'మల్కాపూర్\\u200cలో ఐఓసీ భారీ టెర్మినల్\\u200c',\n",
              " 'అస్థిరతల్లోనూ చెదరని విశ్వాసం',\n",
              " 'చమురు ధరల పతనం భారత్\\u200cకు వరం క్యాడ్ ద్రవ్యోల్బణం ద్రవ్యోల్బణం',\n",
              " '125 కొత్త శాఖలను ఆరంభించిన బంధన్\\u200c బ్యాంకు',\n",
              " 'రూ 3 000 కోట్లు సమీకరించిన కెనరా బ్యాంక్\\u200c',\n",
              " 'ఫుడ్\\u200c ప్రాసెసింగ్\\u200c యూనిట్లకు రుణాలు',\n",
              " 'మొబైల్\\u200c ఫోన్ల ధరలకు రెక్కలు',\n",
              " 'ఆసియా మార్కెట్ల పతనం',\n",
              " '56 పైసలు ఎగిసిన రూపాయి',\n",
              " 'మినిమం బ్యాలెన్స్ \\u200bనిబంధన తొలగింపు',\n",
              " 'ఆస్తుల అమ్మకానికి రాణా స్కెచ్\\u200c\\u200c',\n",
              " 'వాహన రంగానికి బీఎస్\\u200c–4 గుదిబండ మార్చి 31తో ముగియనున్న',\n",
              " 'పాగల్\\u200c ప్రారంభం',\n",
              " 'నమస్కారం చేద్దాం చిరంజీవి',\n",
              " 'ఆర్\\u200cఆర్\\u200cఆర్\\u200c నుంచి తప్పుకున్న అలియా భట్\\u200c',\n",
              " \"ఇప్పుడు 'జెంటిల్\\u200cమెన్' వస్తే 'శక్తి'లా ఉంటాడు\",\n",
              " 'మీరు నిజంగా వన్\\u200c మ్యాన్\\u200c ఆర్మీ',\n",
              " 'తారలు ఇంటికే పరిమితం',\n",
              " 'సామాజిక బాధ్యతతో శక్తి',\n",
              " 'డార్లింగ్\\u200c ఈజ్\\u200c బ్యాక్\\u200c',\n",
              " 'నారప్ప వచ్చాడప్ప',\n",
              " 'కాస్త అదనంగా ఇవ్వండి',\n",
              " 'నా పుట్టినరోజు వేడుకలు వద్దు',\n",
              " 'పని ఉంటే మస్తు లేదంటే పస్తు',\n",
              " 'కరోనా ఎఫెక్ట్\\u200c కాజల్\\u200c భావోద్వేగ పోస్టు',\n",
              " 'వరుసగా రెండోసారి రౌడీనే',\n",
              " 'ఆ ఇద్దరితో నటించాలని ఉంది విజయ్\\u200c',\n",
              " 'కరోనా భయం స్వీయ నిర్బంధంలో ప్రియదర్శి',\n",
              " 'నా భార్య కళ ఇదేనా కల',\n",
              " 'గయ్యాళి కాదు ఉత్త బోళా మనిషి',\n",
              " 'అందరూ బాగుండాలని',\n",
              " 'ఆ రోజు ఎవరూ నా దగ్గరకి రావొద్దు మోహన్\\u200cబాబు',\n",
              " 'తెలుగు రాష్ట్రాల్లో సినిమా షూటింగ్\\u200cలు బంద్\\u200c',\n",
              " 'రామ్\\u200c కొ ణి దె ల స్పెషల్\\u200c సాంగ్\\u200c సాంగ్\\u200c',\n",
              " 'నితిన్\\u200c పెళ్లి వాయిదా',\n",
              " 'ప్రభుత్వానికి ప్రజల సహకారం అవసరం',\n",
              " 'కొత్త జీవితం నటి షీలా వివాహం చేసుకున్నారు',\n",
              " 'తోట బావిలో',\n",
              " 'మనసు మాట వినండి',\n",
              " 'విట్టల్\\u200c వాడిలో ఏం జరిగింది',\n",
              " 'ఆరువందల ఏళ్ల కథ',\n",
              " 'ప్రేమికుల అడ్డా',\n",
              " 'మళ్లీ జోడీ',\n",
              " 'విడుదల వాయిదా',\n",
              " 'ఫారెస్ట్\\u200cకు పయనం',\n",
              " 'నాకు మూడు నాలుగు సార్లు పెళ్లి చేశారు',\n",
              " 'ఈ క్రేజ్\\u200c ఇప్పట్లో తగ్గేలా లేదు',\n",
              " 'నీతోని కష్టమే కృష్ణవేణి',\n",
              " \"యాంకర్\\u200c రవి 'తోటబావి' టీజర్\\u200c విడుదల\",\n",
              " 'భారీ గ్రాఫిక్స్\\u200cతో వస్తున్న ‘అంగుళీక’',\n",
              " 'కరోనా ఎఫెక్ట్\\u200c ‘వి’ సినిమా వాయిదా',\n",
              " 'పెళ్లి చేసుకున్న ‘పరుగు’ హీరోయిన్\\u200c',\n",
              " 'కాంబినేషన్\\u200c షురూ',\n",
              " 'దేవుడే సమాధానం చెప్పాలి',\n",
              " 'ఆచార్య నుంచి త్రిష అవుట్\\u200c',\n",
              " 'మహిళల్ని గౌరవించండి',\n",
              " 'బిగ్\\u200cబాస్\\u200c రియాలిటీ షో వ్యాఖ్యాతగా మహేశ్\\u200c బాబు',\n",
              " 'అవి నా కుటుంబాన్ని బాధిస్తున్నాయి అనుష్క',\n",
              " 'సిటీలో క్రేజీగా సోషల్\\u200c ‘పెట్\\u200c’ వర్కింగ్\\u200c',\n",
              " 'అల్లరి నరేష్\\u200cకు జోడీగా కాజల్\\u200c',\n",
              " 'మదిలో గదిలో ‘అల్లు’కున్న అభిమానం',\n",
              " 'కోహ్లిని తలపించే మొనగాడు వచ్చాడు',\n",
              " 'ఐపీఎల్\\u200cపై బీసీసీఐ ప్లాన్\\u200c బి ఇదేనా',\n",
              " 'ధోని భవితవ్యంపై గావస్కర్\\u200c స్పందన',\n",
              " '‘నేను పిచ్చి పనిచేస్తే మళ్లీ క్రికెట్\\u200c ఆడలేను’',\n",
              " '‘టీమిండియా పేస్\\u200c దెబ్బకు బెంబేలెత్తిపోయా’',\n",
              " 'ఆర్థికంగా నష్టపోతాం',\n",
              " 'అన్నా నమస్తే అంత మంచిగనే ఉంది',\n",
              " 'మరో రెండు కరోనా కేసులు మొత్తం 18',\n",
              " 'తెలంగాణలో పదో తరగతి పరీక్షలు వాయిదా',\n",
              " \"లేఖలు లీకులు అందులో భాగమే'\",\n",
              " 'కరోనా పట్ల అప్రమత్తంగా ఉండాలి మోదీ',\n",
              " 'ఏప్రిల్ 19న యుగాంతం ఏంటి కథ',\n",
              " 'ఒలింపిక్స్\\u200c వాయిదా వేస్తే మంచిది',\n",
              " 'మధ్యప్రదేశ్\\u200cలో ప్రభుత్వ ఏర్పాటు దిశగా బీజేపీ',\n",
              " 'మధ్యప్రదేశ్\\u200c సీఎం కమల్\\u200cనాథ్\\u200c రాజీనామా',\n",
              " 'సింగపూర్\\u200cలో చిక్కుకున్న జడ్చర్ల విద్యార్థులు',\n",
              " 'కామసూత్ర నటికి కరోనా కష్టాలు',\n",
              " 'ప్రముఖ బాలీవుడ్\\u200c సింగర్\\u200cకు కరోనా పాజిటివ్\\u200c',\n",
              " 'ఇల్లుకని కొల్లగొట్టాడు',\n",
              " 'జనతా కర్ఫ్యూ మెట్రో సేవలు బంద్\\u200c',\n",
              " 'రెండో రోజు కొనసాగుతున్న ఏసీబీ దాడులు',\n",
              " 'మాజీ మంత్రి ఆది సోదరులపై కేసు నమోదు',\n",
              " 'వెలగపూడి యాక్షన్\\u200c ఎక్సైజ్\\u200c శాఖ రియాక్షన్\\u200c',\n",
              " 'రూ 70 వేల శాంసంగ్\\u200c ఫోన్\\u200c రూ 25',\n",
              " 'వారాంతంలో లాభాల కళ కానీ',\n",
              " 'లాభనష్టాల సయ్యాట ఐటీ జూమ్\\u200c',\n",
              " 'మళ్లీ రూ 40 000 దాటిన బంగారం',\n",
              " 'యస్\\u200c బ్యాంక్\\u200cకు ఆర్\\u200cబీఐ 60 వేల కోట్లు',\n",
              " 'బోర్డ్\\u200c మీటింగ్స్\\u200c వీడియోలో',\n",
              " 'డిజిటల్\\u200c ప్రకటనల్లోకి ‘డిజిటల్\\u200c కైట్స్\\u200c’',\n",
              " 'బాకీ మొత్తం కట్టాల్సిందే',\n",
              " 'కుప్పకూలిన స్టాక్\\u200cమార్కెట్లు',\n",
              " '‘ఇన్నోవా క్రిస్టా’ లిమిటెడ్\\u200c',\n",
              " 'ఎకానమీకి కరోనా షాక్\\u200c',\n",
              " 'అదే వారికి చివరి రాత్రి',\n",
              " 'ఆమె రుణం ఎలా తీర్చుకోవాలో',\n",
              " 'అతన్ని చూస్తే శత్రువుని చూసిన ఫీలింగ్\\u200c',\n",
              " 'సైకోలాగా టార్చర్\\u200c చేసేది',\n",
              " 'మీ భాగస్వామి నిజంగా ప్రత్యేకమే',\n",
              " 'నేను పిచ్చివాడిలా ఆమెకోసం',\n",
              " 'తను ఎక్కడ ఉన్నా హ్యాపీగా ఉండాలి',\n",
              " 'తొక్కతోనూ లాభాలు',\n",
              " 'అబ్బురం సన్యాసి గుహల అందాలు',\n",
              " 'రౌడీ టీమ్\\u200cలో మోడల్స్\\u200cగా చేరడానికి సిటీ యూత్\\u200c ఆసక్తి ఆసక్తి',\n",
              " 'లాక్మే సంపూర్ణ స్టయిల్\\u200c',\n",
              " 'అరకును తలపించే ప్రకృతి సౌందర్యం పశ్చిమ ఏజెన్సీ సొంతం',\n",
              " 'శవపేటికలో ఉన్నపుడు ఆశ్చర్యం వేసింది',\n",
              " 'అండమాన్\\u200cలో విహరించిన నగర అమ్మాయిలు',\n",
              " 'నేడు ప్రపంచ పర్యాటక దినం',\n",
              " 'ఇంత లేటు వయసులో ఎంతటి మాతృత్వ అనుభూతులో',\n",
              " 'వేల సంఖ్యలో పెళ్లిళ్లు',\n",
              " 'సిటీ థ్రిల్స్\\u200c పార్టీ స్టైల్స్\\u200c',\n",
              " 'వరల్డ్\\u200c ఫేమస్\\u200c క్రైస్తవ ప్రార్థనా మందిరాలు',\n",
              " 'సోదర బంధమే కాదు సాదర బంధం కూడా',\n",
              " 'ప్రతిధ్వనించే పుస్తకం',\n",
              " 'బాధ్యతలూ కోరికలకూ మధ్య',\n",
              " 'రారండోయ్\\u200c',\n",
              " '22న కాకినాడలో ప్రకృతి వ్యవసాయ శిక్షణ',\n",
              " 'ఆశావహ సేద్యం',\n",
              " 'పశువుల్లో బాక్టీరియా వ్యాధులు',\n",
              " 'ఇంటిపంటలే ఆరోగ్యదాయకం',\n",
              " 'ప్రదర్శన క్షేత్రంగా రైతు శిక్షణా కేంద్రంగా మారిన కృష్ణ',\n",
              " 'శీతాకాలంలో పశువులకు నిల్వ నీళ్లివ్వవద్దు',\n",
              " 'ట్రంప్\\u200cకు అమెరికా వంటలు నచ్చట్లేదిప్పుడు',\n",
              " 'స్నేహమేరా జీవితం స్నేహమేరా శాశ్వతం',\n",
              " 'బంగారయ్యను చంపేశారు',\n",
              " 'నేనైతే ఫాంహౌజ్\\u200cకు తీసుకువెళ్లి దోషుల లాయర్\\u200c',\n",
              " 'కోవిడ్\\u200c 19 చైనా కంపెనీ సరికొత్త రికార్డు',\n",
              " 'మరో రెండు కరోనా కేసులు మొత్తం 18',\n",
              " 'ఆ బ్లడ్\\u200c గ్రూపు వాళ్లు తస్మాత్\\u200c జాగ్రత్త',\n",
              " 'పారాసిటమాల్\\u200c మింగి దర్జాగా ఇంటికి',\n",
              " 'స్మార్ట్\\u200cగా కాలేజీ యువతులు ఒంటరి మహిళలతో వ్యభిచారం',\n",
              " 'నిర్భయ ‘బతకాలని లేదు నేను చచ్చిపోతా’',\n",
              " 'ఉరితీయొద్దు దోషుల లాయర్\\u200c',\n",
              " 'నిర్భయ వ్యక్తిత్వంపై లాయర్\\u200c వివాదాస్పద వ్యాఖ్యలు',\n",
              " 'దిక్కు తోచని స్థితిలో టీడీపీ నేతలు',\n",
              " 'కాన్స్\\u200c ఫెస్టివల్\\u200c క్యాన్సిల్\\u200c',\n",
              " 'నా బిడ్డకు తండ్రి ఎలన్\\u200c మస్క్\\u200c సింగర్\\u200c',\n",
              " 'ఐదేళ్ల కంటే ఎక్కువ శిక్ష వేస్తే అక్కడే చచ్చిపోతాడు',\n",
              " 'నవంబర్\\u200cకు ‘నో టైమ్\\u200c టు డై’',\n",
              " 'పోర్న్\\u200c స్టార్\\u200cగా మారిన మికేలాపై గృహహింస కేసు',\n",
              " 'జైలుకి హార్వీ వెయిన్\\u200cస్టీన్\\u200c',\n",
              " '‘హీరో’లు మాత్రమే ఐఫోన్లు వాడాలి',\n",
              " 'సంచలన గాయనికి చెప్పుకోలేని చేదు అనుభవం',\n",
              " 'షూటింగ్\\u200c ‘ఇంపాజిబుల్\\u200c’',\n",
              " 'నాకు హార్వే వెయిన్\\u200cస్టీన్\\u200c అస్సలు నచ్చడు ట్రంప్\\u200c',\n",
              " 'జురాసిక్\\u200c ఫుల్\\u200c కిక్\\u200c',\n",
              " 'అఫ్గాన్\\u200cలో భద్రతా దళాల స్థావరంపై దాడిలో 24 మంది 24',\n",
              " 'వరల్డ్\\u200c హ్యాపియెస్ట్\\u200c కంట్రీ ఫిన్\\u200cలాండ్\\u200c',\n",
              " 'స్వీయ నిర్బంధం ఉల్లంఘన భారీ జరిమానా',\n",
              " \"కరోనా 'నిర్లక్ష్యం వహిస్తే లక్షల్లో ప్రాణాలు పోతాయి'\",\n",
              " 'ఏప్రిల్ 19న యుగాంతం',\n",
              " 'కోవిడ్\\u200c 19 చైనా కంపెనీ సరికొత్త రికార్డు',\n",
              " 'కరోనా విజృంభణ ఇటలీ వీధులు వెలవెల',\n",
              " 'ఇది చైనా పాపమే ట్రంప్\\u200c',\n",
              " 'వైరల్ ఈ డ్యాన్సింగ్\\u200c జోడీ అదిరింది',\n",
              " 'కరోనా మరణాల్లో చైనాను మించిన ఇటలీ',\n",
              " 'ప్రపంచ దేశాల్లో ప్రజా దిగ్భందనం',\n",
              " 'కరోనా ఎఫెక్ట్\\u200c కన్నీటి పర్యంతమైన ఓ తల్లి',\n",
              " 'స్వీయ నిర్బంధంలో ‘ముద్దు’ ముచ్చట',\n",
              " '‘హృదయ విదారకం కన్నీళ్లు ఆగడం లేదు’',\n",
              " 'కరోనా అలర్ట్\\u200c మాస్క్\\u200cలు గ్లోవ్స్\\u200c కంటే ఇదే ముఖ్యం',\n",
              " 'కరోనా వ్యాప్తి ఏంజెలా మెర్కెల్ సంచలన వ్యాఖ్యలు',\n",
              " 'యూరప్\\u200c ఆసియాలో అత్యధిక మరణాలు',\n",
              " 'ఇటలీలో ఒక్కరోజే 475 మంది మృతి',\n",
              " 'కృత్రిమంగా తయారు చేసింది కాదు',\n",
              " 'కేసులు 2లక్షలు మరణాలు 8వేలు',\n",
              " 'చైనీస్\\u200c వైరస్\\u200c వ్యాఖ్యలకు ట్రంప్\\u200c సమర్ధన',\n",
              " '‘ఇలాగైతే అమెరికాలో 22 లక్షల మరణాలు’',\n",
              " 'క్షమాపణ నా పిల్లలకు చెప్పక్కర్లేదు',\n",
              " 'జాగ్రత్త పడకపోతే వినాశనమే',\n",
              " 'భారత్\\u200c కృషి ప్రశంసనీయం డబ్ల్యూహెచ్\\u200cఓ',\n",
              " '‘గ్రాండ్\\u200c ప్రిన్సెస్\\u200c’లో చిక్కుకుపోయిన 100 మంది భారతీయులు',\n",
              " 'పాకిస్తాన్\\u200cలో తొలి కరోనా మరణం',\n",
              " 'కరోనా ట్రీట్\\u200cమెంట్\\u200c తర్వాత డాక్టర్లు ఏం చేస్తారో తెలుసా',\n",
              " 'కరోనా సోకి యువ కోచ్\\u200c మృతి',\n",
              " 'ఐసీజేను ఆశ్రయించిన నిర్భయ దోషులు',\n",
              " 'ప్రియురాలిని హత్య చేసి శవంతో ప్రయాణం',\n",
              " 'జేమ్స్\\u200cబాండ్\\u200c నటికి కరోనా',\n",
              " 'ఉగ్రవాదులూ యూరప్\\u200c వెళ్లొద్దు ఐసిస్\\u200c',\n",
              " 'త్వరలో వాట్సాప్\\u200cలో కొత్త ఫీచర్\\u200c',\n",
              " 'యూరప్\\u200c అతలాకుతలం',\n",
              " '‘సిద్దంగా ఉండండి కానీ భయపడకండి’',\n",
              " 'సెలబ్రిటీల ఫేక్\\u200c వీడియోలతో పోర్న్\\u200c క్లిప్\\u200cల తయారీ',\n",
              " '40 ఏళ్లు చీకటి గుహలో 60 ఏళ్లు కప్\\u200cబోర్డులో',\n",
              " 'ధ్యానం డైరీ రాయడమే కాపాడుతోంది',\n",
              " 'అరవై ఏళ్ల టీనేజర్\\u200c',\n",
              " 'అప్పుడే పుట్టిన శిశువుకి కరోనా లక్షణాలు',\n",
              " 'ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు',\n",
              " 'అందుకు ఇమ్రాన్\\u200c ఖాన్\\u200c సిద్ధం పాకిస్తాన్\\u200c',\n",
              " 'వాయు కాలుష్యంతో ఒబెసిటీ',\n",
              " 'కరోనాను కలసి ఎదుర్కొందాం మోదీ',\n",
              " 'కరోనా భయం నా సోదరి శవాన్ని తీసుకువెళ్లండి',\n",
              " 'తిరుపతిలో ఏసీబీ దాడులు',\n",
              " 'ఆత్మహత్య కాదు హత్యే',\n",
              " 'మాజీ మంత్రి ఆది సోదరులపై కేసు నమోదు',\n",
              " 'విధులకు ఆటంకం కలిగించారని ఎమ్మెల్యేపై ఫిర్యాదు',\n",
              " 'సొంత తమ్ముడినే హత్య చేయించిన అన్న',\n",
              " 'ఘోర రోడ్డు ప్రమాదం నలుగురు మృతి',\n",
              " 'దేవుడా ఎంత పనిచేశావయ్యా',\n",
              " 'వైఎస్సార్\\u200cసీపీ ఎమ్మెల్యే మూలె సుధీర్\\u200cరెడ్డి అనుచరుడిపై దాడి',\n",
              " 'వైఎస్సార్\\u200cసీపీ కార్యకర్తపై హత్యాయత్నం',\n",
              " 'ఏసీబీ వలలో ట్రాన్స్\\u200cకో అవినీతి చేప',\n",
              " 'బరితెగించిన జనసేన కార్యకర్తలు',\n",
              " 'హిందూపురం నియోజకవర్గంలో వైఎస్సార్\\u200cసీపీ నేతపై టీడీపీ దౌర్జన్యం',\n",
              " 'అర్ధరాత్రి ప్రేమ జంట కిడ్నాప్\\u200cయత్నం',\n",
              " 'బాబు మరో డ్రామాకు తెరలేపారు',\n",
              " \"లేఖలు లీకులు అందులో భాగమే'\",\n",
              " 'రమేష్\\u200c కుమార్\\u200c లేఖ వెనుక ఉద్దేశం ఏంటి',\n",
              " '‘బాపిరాజు నోటికొచ్చినట్టు మాట్లాడుతున్నారు’',\n",
              " 'ఎన్ని కుట్రలు చేసినా వైఎస్సార్\\u200c సీపీదే విజయం',\n",
              " 'మద్యం రేట్లను ‘అమ్మ ఒడి’తో పోల్చడం సిగ్గుచేటు',\n",
              " 'రమేష్\\u200c కుమార్\\u200cను ఎస్\\u200cఈసీ నుంచి తప్పించాలి',\n",
              " 'ఈసీ లేఖపై ఏపీ ప్రభుత్వం సీరియస్\\u200c',\n",
              " 'వైఎస్సార్\\u200cసీపీలో చేరిన ఎమ్మెల్సీ శమంతకమణి',\n",
              " 'చంద్రబాబు ఎల్లో మీడియాపై మంత్రి పెద్దిరెడ్డి ధ్వజం',\n",
              " 'ఆ లేఖ పెద్ద కుట్ర',\n",
              " 'తీర్పు తర్వాత ఆకాశ రామన్న లేఖ',\n",
              " 'ఆ విషయాన్ని బీజేపీ నేతలు గుర్తుపెట్టుకోవాలి వెల్లంపల్లి',\n",
              " \"సీట్ల కేటాయింపులో వారికి పెద్దపీట వేశాం'\",\n",
              " 'అందుకే టీడీపీని వీడాను శమంతకమణి',\n",
              " 'ఉనికి కోల్పోతామనే చంద్రబాబు కుట్రలు',\n",
              " 'ఏపీలో ఎన్నికల కోడ్\\u200cను ఎత్తివేయండి సుప్రీంకోర్టు',\n",
              " 'ఎన్నికలంటే విపక్షాలకు భయమెందుకు',\n",
              " \"కరోనాను ఆయనే కనుగొన్నట్లు మాట్లాడుతున్నారు'\",\n",
              " 'టీడీపీకి మరోసారి షాక్\\u200c',\n",
              " \"చంద్రబాబును రాష్ట్ర ప్రజలు క్షమించరు'\",\n",
              " 'ఎన్నికల వాయిదాకే గెలిచినట్టు ఫీలవుతున్నారు',\n",
              " 'రాజ్యాంగ విలువలు కాల రాశారు',\n",
              " 'బాబు రుణం తీర్చుకున్నారు',\n",
              " 'చంద్రబాబు నమ్మించి మోసం చేశారు',\n",
              " 'కే వైరస్\\u200c బాధితులే చంద్రబాబుకు సహకరిస్తున్నారు',\n",
              " 'వైఎస్సార్\\u200cసీపీలో చేరిన మాజీ మంత్రి వెంకటరెడ్డి',\n",
              " 'ఎన్నికల కమిషనర్\\u200c దారుణంగా వ్యవహరిస్తున్నారు',\n",
              " 'ఎవరిని సంప్రదించి ఎన్నికలు వాయిదా వేశారు',\n",
              " '‘ఇది టెర్రర్ గ్రూపుల కంటే ఘోరం కాదా ’ ’',\n",
              " 'సామాజిక వర్గాలను అడ్డు పెట్టుకొని పెత్తనం ఏంటి',\n",
              " 'ధర్మశ్రీ చతురత',\n",
              " 'గ్రహం అనుగ్రహం 19 03 2020',\n",
              " 'పబ్లిక్\\u200c అండర్\\u200c టేకింగ్స్\\u200c కమిటీకి ఎంపీ సంతోష్\\u200cకుమార్\\u200c',\n",
              " 'నల్లగొండలో కరోనా కలకలం',\n",
              " 'అంగన్\\u200cవాడీ కేంద్రాల్లో పౌష్టికాహారం ఆపొద్దు',\n",
              " 'నల్లగుట్టలో టెన్షన్\\u200c',\n",
              " 'ఇండోనేసియా బృందంలో అందరికీ పాజిటివ్\\u200c',\n",
              " 'సీసీఎంబీలో పరీక్షలకు అనుమతివ్వండి',\n",
              " 'క్వారంటైన్\\u200cలో ఉండలేం',\n",
              " 'తిరుమలలో మహాయాగం',\n",
              " 'దేశ సరిహద్దుల్లో కట్టుదిట్టమైన నిఘా',\n",
              " 'రూ 50కి రెండు కోళ్లు',\n",
              " 'రుణమాఫీ’కి సమాయత్తం',\n",
              " 'త్వరపడండి రూపాయికే గుడ్డు',\n",
              " 'ట్రైన్\\u200c క్యాంటీన్\\u200cలో కాల్పులు తీవ్ర గాయాలు',\n",
              " 'పట్టాలు తప్పిన ఎంఎంటీఎస్\\u200c ట్రైన్\\u200c',\n",
              " 'బాసర రేపటి నుంచిఅర్జిత సేవలు బంద్\\u200c',\n",
              " 'ఈదురుగాలులతో కూడిన భారీ వర్షం',\n",
              " 'అన్నా నమస్తే అంత మంచిగనే ఉంది',\n",
              " 'స్మార్ట్\\u200c పరిశుభ్రతా ప్రధానమే',\n",
              " 'రోడ్లపై తగ్గిన వాహనాల సంఖ్య',\n",
              " 'కరోనా బారిన పడింది వీరే',\n",
              " 'అడ్డా కూలీలకు గడ్డు కాలం',\n",
              " 'స్వయంగా పరీక్ష రాసిన వీణావాణీలు',\n",
              " 'కోవిడ్\\u200c నేపథ్యంలో పలు రైళ్లు రద్దు',\n",
              " 'కరీంనగర్\\u200c లాంటి ఘటనలపై నిఘా పెట్టాం',\n",
              " 'విదేశాంగ మంత్రి జైశంకర్\\u200cకు విజయసాయి రెడ్డి విజ్ఞప్తి',\n",
              " 'యూత్\\u200c కాంగ్రెస్\\u200c ఇంటర్వ్యూల్లో ఆసక్తికర ప్రశ్నలు',\n",
              " 'కరోనా నివారణకు ట్రాఫిక్\\u200c పోలీసుల సూచనలు',\n",
              " 'వేల కోళ్లు ఉచిత పంపిణీ',\n",
              " 'జార్జియాలో చిక్కుకున్న భువనగిరి యువతి శివాణి',\n",
              " 'కక్కుకుంటూ ఒకరు కెన్యాపై మరొకరు',\n",
              " 'భారత ఫుట్\\u200cబాల్\\u200c దిగ్గజం పీకే బెనర్జీ అస్తమయం',\n",
              " 'కోహ్లిని తలపించే మొనగాడు వచ్చాడు',\n",
              " 'ఐపీఎల్\\u200cపై బీసీసీఐ ప్లాన్\\u200c బి ఇదేనా',\n",
              " 'ఫుట్\\u200cబాల్\\u200c దిగ్గజం కన్నుమూత సచిన్\\u200c సంతాపం',\n",
              " 'ధోని భవితవ్యంపై గావస్కర్\\u200c స్పందన',\n",
              " 'జపాన్\\u200cకు ఒలింపిక్\\u200c జ్యోతి',\n",
              " 'ప్రధాని మోదీని ఫాలో అవుదాం కోహ్లి',\n",
              " 'ఏప్రిల్\\u200c 15 వరకు ఆటల్లేవ్\\u200c',\n",
              " 'భారత జట్టు దృక్పథం మారింది',\n",
              " 'నా శైలి అందరికీ తెలుసు',\n",
              " 'త్వరలో ఆర్థిక ప్యాకేజీ ప్రకటిస్తాం',\n",
              " 'కరోనా బీఎస్\\u200cఎన్\\u200cఎల్\\u200c నెల రోజులు ఫ్రీ',\n",
              " 'మరో రికార్డు కనిష్టానికి రూపాయి',\n",
              " 'రూ 70 వేల శాంసంగ్\\u200c ఫోన్\\u200c రూ 25',\n",
              " 'వారాంతంలో లాభాల కళ కానీ',\n",
              " 'లాభనష్టాల సయ్యాట ఐటీ జూమ్\\u200c',\n",
              " 'మళ్లీ రూ 40 000 దాటిన బంగారం',\n",
              " 'మరోసారి ఈడీ ముందుకు',\n",
              " 'యస్\\u200c బ్యాంక్\\u200cకు ఆర్\\u200cబీఐ 60 వేల కోట్లు',\n",
              " 'ఉద్యోగులకు 6 నెలల జీతం బోనస్\\u200c',\n",
              " 'డిజిటల్\\u200c ప్రకటనల్లోకి ‘డిజిటల్\\u200c కైట్స్\\u200c’',\n",
              " 'తీవ్ర ఒడిదుడుకులు చివరికి నష్టాలు',\n",
              " 'మరో 5 ఐఐఐటీలకు జాతీయ ప్రాధాన్య హోదా',\n",
              " 'పీటర్\\u200c ముఖర్జియా విడుదల',\n",
              " 'జనతా కర్ఫ్యూని పాటించండి',\n",
              " 'కమల్\\u200cనాథ్\\u200c రాజీనామా',\n",
              " '\\u200dకరోనా కేరళ బామ్మ భావోద్వేగ లేఖ',\n",
              " 'ఉద్యోగ కల్పనలో ఏపీని ఆదర్శంగా తీసుకోండి',\n",
              " 'జనతా కర్ఫ్యూ మెట్రో సేవలు బంద్\\u200c',\n",
              " 'మధ్యప్రదేశ్\\u200cలో ప్రభుత్వ ఏర్పాటు దిశగా బీజేపీ',\n",
              " 'నిర్భయ దోషులకు ఉరి అమలుపై మోదీ',\n",
              " 'వైరల్\\u200c కరోనా భయంతో చితకబాదారు',\n",
              " 'ఈరోజు విజయం సాధించాం',\n",
              " 'నా కుమార్తెకు న్యాయం జరిగింది',\n",
              " 'రాజ్యసభలో గొగోయ్\\u200c ప్రమాణం',\n",
              " 'నేడు మధ్యప్రదేశ్\\u200cలో బలపరీక్ష',\n",
              " 'భారత్\\u200cలో నాలుగో మరణం',\n",
              " '22న జనతా కర్ఫ్యూ',\n",
              " 'తమిళనాడు ప్రభుత్వంపై రజనీ ప్రశంసలు',\n",
              " 'ప్రేమ పేరుతో వేధింపులు బాలిక ఆత్మహత్య',\n",
              " 'తనివితీరా స్వామి దర్శనం',\n",
              " 'రెండో రోజు పరీక్షకు 22 మంది గైర్హాజరు',\n",
              " 'ఆ దర్శకుడితో విజయ్\\u200c నాలుగో సినిమా',\n",
              " 'దర్శకుడి ఇంట్లోకి వారసుడు',\n",
              " 'ఘోర రోడ్డు ప్రమాదం ఆరుగురు మృతి',\n",
              " 'కరోనాను లెక్కచేయకుండా సీఏఏ వ్యతిరేక నిరసనలు',\n",
              " 'హీరోయిన్\\u200c ఓరియెంటెడ్\\u200c మూవీలో నయన',\n",
              " 'హైకోర్టుకు ఆశ్రయించిన కమల్\\u200cహాసన్\\u200c',\n",
              " 'సంతానంతో బాలీవుడ్\\u200c బ్యూటీ',\n",
              " 'అందుకు మీడియాకు ప్రత్యేక ధన్యవాదాలు రజనీ',\n",
              " 'నా పార్టీ జెండా ఇంద్రధనుస్సు గుర్తు జామకాయ',\n",
              " 'ఫిలిప్పీన్స్\\u200c యువతితో వివాహం',\n",
              " 'తమిళిసై పై అనుచిత పోస్టులు',\n",
              " 'టీషర్ట్స్\\u200c దాచి అడ్డంగా దొరికిపోయాడు',\n",
              " 'విజయ్\\u200cని కావాలనే టార్గెట్\\u200c చేశారా',\n",
              " 'నిత్యానందను ఒకసారి కలవాలనుంది',\n",
              " 'అవకాశం కావాలంటే పడకగదికి రావాలన్నారు',\n",
              " 'విషం ఇచ్చి చంపేయమంటున్నారు',\n",
              " 'స్వచ్ఛ రాజకీయాలు కావాలన్నప్పుడు వస్తా',\n",
              " 'ఇక్కడైతే బతికిపోయేవాడు',\n",
              " 'హీరో విజయ్\\u200c ఇంట్లో మళ్లీ ఐటీ సోదాలు',\n",
              " 'రాజకీయాలు సీఎం పదవి కోసం కాదు రజనీ',\n",
              " 'నటి సహాయకురాలు ఆత్మహత్యాయత్నం',\n",
              " 'ప్రియుడి కోసం శ్రీలంకనుంచి వచ్చిన ప్రియురాలు',\n",
              " 'నువ్వు లేకుండా జీవితాన్ని ఊహించలేను',\n",
              " 'నాకు రాజకీయాలొద్దు సినిమాలే చాలు',\n",
              " 'కమెడియన్\\u200c కునాల్\\u200cపై ప్రయాణ నిషేధం',\n",
              " 'అవును శివసేనను మోసం చేశాం\\u200b',\n",
              " 'బీజేపీ పగటికలలు నెరవేరవు',\n",
              " 'ప్రముఖ గాయకుడికి సెబీ షాక్\\u200c',\n",
              " '60 ఏళ్ల వయసులో మాజీ కేంద్రమంత్రి పెళ్లి',\n",
              " 'ప్రియుడితో ఇంట్లో ఏకాంతంగా తల్లి రావడంతో',\n",
              " 'రామ మందిర నిర్మాణానికి రూ 1కోటి విరాళం',\n",
              " 'పులి ప్రేమ ప్రయాణం',\n",
              " 'కలెక్టర్\\u200cగా నియమితులైన పాఠశాల విద్యార్థిని',\n",
              " 'సామ్నా ఎడిటర్\\u200cగా రశ్మీ ఠాక్రే',\n",
              " 'రశ్మికు అమృత ఫడ్నవిస్\\u200c అభినందనలు',\n",
              " 'సామ్నా ఎడిటర్\\u200cగా రశ్మి ఠాక్రే',\n",
              " 'కోర్టు ముందుకు ‘ఎల్గార్\\u200c’ కేసు నిందితులు',\n",
              " 'మహారాష్ట్ర ప్రభుత్వం కీలక నిర్ణయం',\n",
              " 'వారి సమాచారం అందిస్తే రూ 5 555 బహుమానం',\n",
              " 'డబ్బులు ఇవ్వకుంటే పదేళ్లు జైల్లో పెట్టిస్తా',\n",
              " 'అసదుద్దీన్\\u200c ఒవైసీ సభ వాయిదా',\n",
              " 'కూటమి ప్రభుత్వం నుంచి పాఠాలు నేర్చుకో',\n",
              " 'మన్\\u200c కీ బాత్\\u200cపై ఉద్ధవ్\\u200c సెటైర్లు',\n",
              " 'సీఏఏపై ఉద్ధవ్\\u200c ఠాక్రేకి ఎస్పీ నేత హెచ్చరిక',\n",
              " 'కేంద్ర ప్రభుత్వం హామీ ఇచ్చింది ఉద్ధవ్\\u200c ఠాక్రే',\n",
              " 'విమానం ఇంజిన్లో మంటలు',\n",
              " 'గుండెపోటుతో తల్లి మృతి చైనాలో శవం',\n",
              " 'కూతురితో గొడవ తల్లి ఆత్మహత్య',\n",
              " 'సోనియాకు అశోక్\\u200c చవాన్\\u200c లేఖాస్త్రం',\n",
              " 'జన సంద్రమైన ‘ఆజాద్\\u200c’ మైదాన్\\u200c',\n",
              " 'ఠాక్రేను విమర్శించిన పవార్\\u200c',\n",
              " 'హెచ్\\u200cసీయూ విద్యార్థినికి రికార్డు ప్యాకేజీ',\n",
              " 'కుక్క మొరిగిందని దాడి',\n",
              " 'సీఏఏ ఎన్నార్సీలపై నిరసనలెందుకు',\n",
              " 'మాది స్వచ్ఛమైన హిందుత్వ',\n",
              " 'బ్యాంకుల్లో పెళ్లికి రుణాలు తీసుకుంటున\\u200d్న ప్రజలు',\n",
              " 'మహారాష్ట్రలో దిశ చట్టం',\n",
              " 'లెక్చరర్\\u200cకు నిప్పంటించాడు',\n",
              " 'కొద్ది నిమిషాల్లో పెళ్లి మేకప్\\u200cతో ఊరేగింపులో ఉండగా',\n",
              " 'ప్రైవేట్\\u200c బస్సుల ద్వారానే నగరానికి అక్రమ రవాణా',\n",
              " 'వజ్రాల బండి అంతా మహిళలేనండి',\n",
              " 'చేతిరాత భవిష్యత్\\u200cకు బాట',\n",
              " 'విద్యార్థిని ఆత్మహత్య',\n",
              " 'ఇంట్లో తండ్రి మృతదేహం',\n",
              " 'రూ 500 జరిమానా తప్పదు',\n",
              " 'పిలవని పేరంటానికి వచ్చి',\n",
              " 'పిలవని పేరంటానికి వచ్చి',\n",
              " 'పెళ్లయ్యాక అదృశ్యం ఏడేళ్ల తర్వాత లవర్\\u200cతో',\n",
              " 'ప్రేమ జంట ఆత్మహత్య',\n",
              " 'ఎన్\\u200cఆర్\\u200cసీపై నవీన్\\u200c పట్నాయక్\\u200c కీలక వ్యాఖ్యలు',\n",
              " 'టానిక్\\u200c సీసా మూత మింగిన బాలుడు',\n",
              " 'కాబోయే భార్యపై దాడి',\n",
              " 'ఇంకా వీడని మూఢనమ్మకం',\n",
              " 'జగన్నాథుని ఆలయంలో ‘ఎలుగు’ హల్\\u200cచల్\\u200c',\n",
              " 'పెళ్లి నిశ్చయించడంతో విద్యార్థిని ఆత్మహత్య',\n",
              " 'ఒడిస్సా అధికారులపై ప్రజాప్రతినిధుల ఆగ్రహం',\n",
              " 'జేఎస్\\u200cడబ్ల్యూ ఎనర్జీ చేతికి జీఎంఆర్\\u200c కమళంగ ఎనర్జీ',\n",
              " 'ఇద్దరమ్మాయిల పెళ్లి',\n",
              " 'మారని ఆదివాసీల బతుకులు',\n",
              " 'ట్రాఫిక్\\u200cజామ్\\u200c అంబులెన్స్\\u200cలోనే బాలుడి మృతి',\n",
              " 'తుపాకుల వ్యాపారం గుట్టురట్టు',\n",
              " 'మానవత్వాన్ని చాటుకున్న ఒడిశా ప్రజాప్రతినిధి',\n",
              " 'వెంటాడిన మృత్యువు',\n",
              " 'ఇద్దరు బాలికల మృతదేహాలను పోలీసులు శుక్రవారం కనుగొన్నారు',\n",
              " 'ఒడిశా అభ్యర్థనపై కేంద్రం తిరస్కరణ',\n",
              " 'చావు బతుకుల్లో కోడలు',\n",
              " 'రూ 2 లక్షలు చెల్లించాలంటూ కూలీకి నోటీసులు',\n",
              " 'విద్యార్థినిలో కరోనా లక్షణాలు',\n",
              " 'రాష్ట్రంలో కరోనా రోగి',\n",
              " 'బిచ్చగాళ్లకు వృత్తి శిక్షణ',\n",
              " 'జంతురాయి ఘటనపై మావోయిస్టుల స్పందన',\n",
              " 'ఒడిశాలో ఘోర రోడ్డు ప్రమాదం',\n",
              " 'పదేళ్ల క్రితం ఒడిశాలో తప్పిపోయిన చిన్నారి',\n",
              " 'కొండపై ప్రేమజంట ఆత్మహత్య',\n",
              " 'రేపటి నుంచి అకాల వర్షాలు',\n",
              " 'మావోయిస్టులపై రాళ్లదాడి చేసిన గ్రామస్తులు',\n",
              " 'గర్భం దాల్చిన గిరిజన విద్యార్థిని',\n",
              " 'చిత్రకొండ పరిసరాల్లో ఆర్కే',\n",
              " 'మృత్యువాత పడుతున్న రైతులు',\n",
              " 'బాల్యవివాహం అడ్డగింత',\n",
              " 'పట్టాభిషేకం',\n",
              " 'ప్రేమించి పెళ్లి చేసుకున్న భార్యపై సామూహిక లైంగికదాడికి ఉసిగొల్పిన ఉసిగొల్పిన',\n",
              " 'అతను బిచ్చగాడు కాదు ఇంజనీర్\\u200c',\n",
              " 'మా మంచి ఎమ్మెల్యే',\n",
              " 'ఉన్నత పరీక్షల కోసం మృతదేహాల తరలింపు',\n",
              " 'క్షతగాత్రుడికి ఆర్థిక సాయం',\n",
              " 'ఫలించిన రెండు రాష్ట్రాల ఎక్సైజ్\\u200c పోలీసుల వ్యూహం',\n",
              " 'పేగుబంధం అమ్మేశారు',\n",
              " 'డబ్బులు విత్\\u200cడ్రా చేసుకునేందుకు ఇక్కట్లు పడుతున్న ప్రజలు',\n",
              " 'ఒడిశా సివిల్\\u200c సర్వీసెస్\\u200c టాపర్\\u200cకు అభినందనలు',\n",
              " 'భయభ్రాంతులకు గురవుతున్న ప్రజలు',\n",
              " 'జైలుకు లంచగొండి ఐఏఎస్\\u200c అధికారి',\n",
              " 'కొశాగుమడ బాలిక హత్య కేసులో నిందితుల అరెస్ట్\\u200c',\n",
              " 'భర్త హత్య',\n",
              " 'ఆ బాలికపై లైంగికదాడి జరగలేదు',\n",
              " 'రాష్ట్రానికి భారీ వర్ష సూచన',\n",
              " 'డప్పు కొట్టిన మంత్రి చిందేసిన కలెక్టర్\\u200c',\n",
              " 'దుమారం దిశగా మాజీ మంత్రి వ్యాఖ్యలు',\n",
              " 'పెట్రోల్\\u200c డీజిల్\\u200cతో రెడీగా ఉండండి',\n",
              " 'ఇద్దరు బాలికల సజీవ దహనం',\n",
              " 'తలుపుల్లేని గ్రామంగా ప్రసిద్ధి చెందిన సయాలియా',\n",
              " 'శభాష్\\u200c కలెక్టర్\\u200c',\n",
              " 'బాలికపై లైంగికదాడి హత్య కేసులో విచారణ పూర్తి',\n",
              " 'మావోయిస్టు అగ్రనేత రామన్న మృతి',\n",
              " '31 వరకు షూటింగ్స్\\u200c బంద్\\u200c',\n",
              " 'కన్నడంలో నిన్ను కోరి',\n",
              " 'పర్\\u200cఫెక్ట్\\u200c హజ్బెండ్\\u200c',\n",
              " '30 రోజులు ఉచితం',\n",
              " 'రజనీతో లారెన్స్\\u200c సినిమా',\n",
              " 'బియ్యం నిల్వకు కొత్త గోదాములు',\n",
              " '108 ఎంపీ కెమెరా స్మార్ట్\\u200cఫోన్\\u200c వచ్చేస్తోంది',\n",
              " 'స్మార్ట్\\u200c ఫోన్లకు జీఎస్\\u200cటీ షాక్',\n",
              " 'వెరైటీ ఫీచర్లతో వీయు ప్రీమియం 4కె టీవీ',\n",
              " 'షావోమి మొబైల్స్\\u200c స్మార్ట్\\u200c ఫీచర్లు బడ్జెట్\\u200c ధర',\n",
              " 'రియల్\\u200c మి 6 ఫస్ట్\\u200c సేల్\\u200c',\n",
              " 'త్వరలో రిలయన్స్\\u200c జియో 5జీ టెక్నాలజీ',\n",
              " 'ఊరిస్తున్న వాట్సాప్\\u200c ఫీచర్\\u200c వచ్చేసింది',\n",
              " 'త్వరలో వాయు వేగంతో ప్రయాణించే కారు',\n",
              " 'బడ్జెట్\\u200c ధరలో హువావే స్మార్ట్\\u200cపోన్\\u200c',\n",
              " 'పెరిగిన ఐఫోన్\\u200c ధరలు',\n",
              " 'గెలాక్సీ ఎస్\\u200c10 లైట్\\u200c కొత్త వేరియంట్\\u200c',\n",
              " 'ఐఫోన్\\u200c ప్రేమికులకు శుభవార్త',\n",
              " 'స్టార్\\u200c అంబాసిడర్\\u200c స్మార్ట్\\u200cఫోన్\\u200c గెల్చుకునే చాన్స్\\u200c',\n",
              " 'యాప్\\u200cతో దగ్గర్లోని ఆసుపత్రి వైద్యుల అపాయింట్\\u200cమెంట్\\u200c',\n",
              " 'రెండు సెల్ఫీ కెమెరాలు రియల్\\u200cమి 5జీ స్మార్ట్\\u200cఫోన్\\u200c',\n",
              " 'టెక్నాలజీ పెరిగినా ఫీచర్\\u200c ఫోన్లపైనే మక్కువ',\n",
              " 'రియల్\\u200cమి 5జీ ‘ఎక్స్\\u200c50 ప్రొ’ వచ్చేస్తోంది',\n",
              " 'వాట్సాప్\\u200cలో ఈ రహస్య ఫీచర్\\u200c తెలుసా',\n",
              " 'ఈక్యూ మోడ్\\u200cతో లెనోవా వైర్\\u200cలెస్\\u200c హెడ్\\u200cఫోన్లు',\n",
              " 'అద్భుత ఫీచర్లతో శాంసంగ్\\u200c గెలాక్సీ ఏ 71',\n",
              " 'యాపిల్\\u200cకూ ‘వైరస్\\u200c’',\n",
              " 'ఐటెల్\\u200c నుంచి బడ్జెట్\\u200c ఫోన్\\u200c విజన్\\u200c 1',\n",
              " 'భాష ఏదైనా నో ప్రాబ్లం',\n",
              " 'అదిరిపోయే ఫీచర్లతో ఒప్పో నుంచి మరో స్మార్ట్\\u200cఫోన్\\u200c',\n",
              " 'ఫేస్\\u200cబుక్\\u200cలో కొత్త యాప్\\u200c',\n",
              " 'ఈ యాప్స్\\u200c గురించి ఎందరికి తెలుసు',\n",
              " 'లేటెస్ట్\\u200c ఐఫోన్\\u200cపై డిస్కౌంట్\\u200c ఆఫర్\\u200c',\n",
              " 'ఆ స్మార్ట్\\u200cఫోన్లకు డిమాండ్\\u200c పడిపోయిందట',\n",
              " 'గెలాక్సీ ఎస్\\u200c20 వచ్చింది',\n",
              " '200 కోట్లకు వాట్సాప్\\u200c యూజర్ల సంఖ్య',\n",
              " 'శాంసంగ్\\u200c జెడ్\\u200c ప్లిప్\\u200c ఫోల్డబుల్\\u200c స్మార్ట్\\u200cఫోన్\\u200c',\n",
              " 'శాంసంగ్\\u200c ప్రభంజనం అద్భుత ఫీచర్లు ఫోటోలు',\n",
              " 'బడ్జెట్\\u200c ధరలో రెడ్\\u200cమి 8ఏ డ్యుయల్\\u200c లాంచ్\\u200c',\n",
              " 'అద్భుత ఫీచర్లతో శాంసంగ్\\u200c గెలాక్సీ ఎం 31 త్వరలో 31',\n",
              " 'గోరంత యంత్రం కొండంత సాయం',\n",
              " 'మధ్యప్రదేశ్\\u200c ఎమ్మెల్యే కుమార్తె ఆత్మహత్య',\n",
              " 'ఫుల్లుగా తాగేసి అంబులెన్స్\\u200cను ఢీకొట్టారు',\n",
              " 'దిగ్గజ క్రికెటర్\\u200cను అవమానపరుస్తారా',\n",
              " 'కనికాకు కరోనా కేసు నమోదు',\n",
              " '‘జనతా కర్ఫ్యూ’కు సంఘీభావం',\n",
              " \"ఆన్\\u200cలైన్\\u200c 'కరోనా'\",\n",
              " 'కైసా కరోనా కిస్సా',\n",
              " 'మీడియాకు ఎలా లీకైంది',\n",
              " 'బియ్యం నిల్వకు కొత్త గోదాములు',\n",
              " 'డాక్టర్\\u200c ది గ్రేట్\\u200c',\n",
              " 'జనతా కర్ఫ్యూకు మెగాస్టార్\\u200c మద్దతు',\n",
              " 'వీసా పేరిట టోకరా',\n",
              " '‘కాల్\\u200cసెంటర్\\u200c’తో కాజేశారు',\n",
              " 'టార్గెట్\\u200c ఓఎల్\\u200cఎక్స్\\u200c యూజర్స్\\u200c',\n",
              " 'కైసా కరోనా కిస్సా',\n",
              " 'టీవీ9 మాజీ సీఈవో రవిప్రకాశ్\\u200c ఇంట్లో సోదాలు',\n",
              " \"స్టైల్\\u200c డెనిమ్\\u200c 'జీన్\\u200c'దాబాద్\\u200c\",\n",
              " 'వెలవెలబోయిన ‘జ్యోతి’ స్వాగత వేడుకలు',\n",
              " 'ఫుట్\\u200cబాల్\\u200c దిగ్గజం కన్నుమూత సచిన్\\u200c సంతాపం',\n",
              " 'ఐఓసీ జోక్\\u200c చేస్తున్నారా',\n",
              " 'విదేశీ కోచ్\\u200cలకు జవాబుదారీతనం ఉండాలి',\n",
              " 'భారత బాక్సర్ల ‘తీన్\\u200cమార్\\u200c’',\n",
              " 'రెండు సింగిల్స్\\u200cలోనూ భారత్\\u200cకు నిరాశ',\n",
              " 'క్వార్టర్\\u200c ఫైనల్లో మనీశ్ ఆశిష్ సచిన్\\u200c',\n",
              " 'వరంగల్\\u200c వారియర్స్\\u200cకు తొలి ఓటమి',\n",
              " 'ఓయూ మహిళల టెన్నిస్\\u200c జట్టుకు స్వర్ణం',\n",
              " 'ఇన్\\u200cస్టాలో కొత్త ఫీచర్\\u200c',\n",
              " 'ఎంటర్\\u200cటైన్\\u200cమెంట్\\u200c కా సూపర్\\u200cస్టార్\\u200c బడ్జెట్\\u200c ధరలో',\n",
              " 'తప్పుడు వార్తలకు ట్విటర్\\u200c చెక్\\u200c',\n",
              " 'అద్భుతమైన డిస్\\u200cప్లేతో పోకో ఎక్స్ 2 వచ్చేసింది',\n",
              " 'ఫేక్\\u200c ట్రాఫిక్\\u200cజామ్\\u200c సృష్టించి గూగుల్\\u200cనే బురిడీ కొట్టించాడు',\n",
              " 'తప్పుడు సమాచారాన్ని నిషేధించనున్న యూట్యూబ్\\u200c',\n",
              " 'భారతీయులు టిక్\\u200cటాక్\\u200cలో తెగ గడిపేశారు',\n",
              " 'రోబో 4 o',\n",
              " 'ముందెన్నడూ చూడని సూర్యుడి అద్భుత ఫొటోలు',\n",
              " 'సింగిల్స్\\u200c కోచ్\\u200cగా సొంటోసో',\n",
              " 'మోసపూరిత యాప్\\u200cలకు పేటీఎం చెక్\\u200c',\n",
              " 'ట్రిపుల్\\u200cప్లే సేవలు బీఎస్\\u200cఎన్\\u200cఎల్\\u200cతో యప్\\u200c టీవీ జోడీ',\n",
              " 'అదిరిపోయే ‘స్మార్ట్\\u200c షూస్\\u200c’',\n",
              " 'అత్యుత్తమ ర్యాంక్\\u200cలో భారత హాకీ జట్టు',\n",
              " 'టెన్నిస్\\u200cకు గుడ్\\u200cబై చెప్పిన మారియా షరపోవా',\n",
              " 'నైనా జైస్వాల్\\u200c ఫేస్\\u200cబుక్\\u200c హ్యాక్\\u200c',\n",
              " '‘చాంపియన్\\u200c’ రాకెట్\\u200c',\n",
              " 'సంచలన గాయనికి చెప్పుకోలేని చేదు అనుభవం',\n",
              " 'ఫిట్\\u200cనెస్\\u200c సీక్రెట్\\u200c వెల్లడించిన మడోనా',\n",
              " 'శిక్షణ ముగిసింది',\n",
              " 'ఫస్ట్\\u200c లేడీ',\n",
              " 'ఫోర్డ్\\u200c ఇండియా ఉద్యోగులకు వర్క్\\u200c ఫ్రమ్\\u200c హోమ్\\u200c సౌలభ్యం',\n",
              " 'రాణా ఆయన భార్యకు సీబీఐ మరో షాక్\\u200c',\n",
              " 'భారత్\\u200cలో తొలి ఎలక్ట్రిక్\\u200c ట్రాక్టర్\\u200c',\n",
              " 'రూ 3 000 కోట్లు సమీకరించిన కెనరా బ్యాంక్\\u200c',\n",
              " 'డబ్బా బిల్డింగ్స్\\u200c కట్టొద్దు',\n",
              " 'రియల్టీ రంగానికి 2019లో నిరాశే',\n",
              " 'గృహ ప్రవేశానికి సిద్ధంగా ఉన్న వాటిల్లోనే కొంటాం',\n",
              " 'దివాలా చర్యల్లో రూ 4 6 లక్షల కోట్ల లక్షల',\n",
              " 'వచ్చే నెల 9 10 తేదీల్లో సాక్షి ప్రాపర్టీ షో',\n",
              " 'హైదరాబాద్\\u200cలో నోబ్రోకర్\\u200c కామ్\\u200c సేవలు',\n",
              " 'అపర్ణా వెన్\\u200cస్టర్\\u200c నుంచి కొత్త ఉత్పత్తులు',\n",
              " 'పులకింతల అరకు',\n",
              " 'క్యాబ్\\u200c చార్జీ ఇక మీ చేతుల్లో',\n",
              " 'భారత్\\u200cలోకి చైనా పెట్టుబడుల వెల్లువ',\n",
              " 'ప్రకృతి ఒడిలో ‘దక్కన్\\u200c ట్రేల్స్\\u200c’',\n",
              " 'జపాన్\\u200c ప్రజలకు ఆ ‘గుణం’ ఏలా',\n",
              " 'నాటా ఆధ్వర్యంలో ఘనంగా బ్యాడ్మింటన్\\u200c పోటీలు',\n",
              " 'సౌదీ అరేబియాలో తెలంగాణ కార్మికుల నిరసన',\n",
              " '108 ఎంపీ కెమెరా స్మార్ట్\\u200cఫోన్\\u200c వచ్చేస్తోంది',\n",
              " 'మార్కెట్లోకి ‘కొడాక్\\u200c సీఏ సిరీస్\\u200c’ టీవీలు',\n",
              " 'స్మార్ట్\\u200c ఫోన్లకు జీఎస్\\u200cటీ షాక్',\n",
              " 'రియల్\\u200c మి 6 ఫస్ట్\\u200c సేల్\\u200c',\n",
              " 'ఊరిస్తున్న వాట్సాప్\\u200c ఫీచర్\\u200c వచ్చేసింది',\n",
              " 'బడ్జెట్\\u200c ధరలో హువావే స్మార్ట్\\u200cపోన్\\u200c',\n",
              " 'ఐఫోన్\\u200c ప్రేమికులకు శుభవార్త',\n",
              " 'రెండు సెల్ఫీ కెమెరాలు రియల్\\u200cమి 5జీ స్మార్ట్\\u200cఫోన్\\u200c',\n",
              " 'అద్భుత ఫీచర్లతో శాంసంగ్\\u200c గెలాక్సీ ఏ 71',\n",
              " 'భాష ఏదైనా నో ప్రాబ్లం',\n",
              " 'లేటెస్ట్\\u200c ఐఫోన్\\u200cపై డిస్కౌంట్\\u200c ఆఫర్\\u200c',\n",
              " 'శాంసంగ్\\u200c జెడ్\\u200c ప్లిప్\\u200c ఫోల్డబుల్\\u200c స్మార్ట్\\u200cఫోన్\\u200c',\n",
              " '90 నిముషాల్లో ఫోన్\\u200c డెలివరీ',\n",
              " 'అప్పుడు మరిచాం ఈసారి ఉండాల్సిందే',\n",
              " 'ట్రైన్\\u200c క్యాంటీన్\\u200cలో కాల్పులు తీవ్ర గాయాలు',\n",
              " 'మహిళకు కుడి వైపున గుండె',\n",
              " 'ఏ ఉద్యోగం రాదనే మనస్తాపంతో',\n",
              " 'తల్లిదండ్రులు మందలించారని యువకుడు',\n",
              " 'అటకెక్కిన మూడెకరాలు',\n",
              " 'గద్వాలలో అదృశ్యం ఆగ్రాలో ప్రత్యక్షం',\n",
              " \"అమ్మకు కడుపు'కోత '\",\n",
              " 'యువత పెడదోవ',\n",
              " 'మహిళా కండక్టర్\\u200cపై దాడి కానిస్టేబుళ్లపై వేటు',\n",
              " 'జిల్లేడు పాలు పోసి ఆడ శిశువు హత్య',\n",
              " 'నేనూ నీ వెంటే',\n",
              " 'పెళ్లి పడవ',\n",
              " 'మైసూరు అమ్మాయి నెదర్లాండ్స్\\u200c అబ్బాయి',\n",
              " 'హైలైఫ్\\u200c అందం',\n",
              " 'మద్యం ప్రియులకు షాక్\\u200c',\n",
              " 'పండంటి అందం',\n",
              " 'పిక్టో‘రియల్\\u200c’లో దిట్ట సోమరాజు',\n",
              " 'ఆ లక్షణమే వారిని అధ్యక్షులుగా నిలబెట్టిందా',\n",
              " 'చేపతో క్యాన్సర్\\u200cకు చెక్\\u200c',\n",
              " 'ఫ్రెంచ్\\u200c కిస్\\u200cతో గనేరియా',\n",
              " 'భూగోళాన్ని చుట్టేస్తానంటున్న సెక్యూరిటీ గార్డ్\\u200c',\n",
              " 'మెరిసేందుకు మెరుగులు',\n",
              " 'మీకూ ఉందా ఓ సుతిమెత్తని ప్రియనేస్తం',\n",
              " 'కనుమరుగవుతున్నాయి కాపాడుకుంటే మేలు',\n",
              " 'డయాబెటిస్\\u200c పేషెంట్లకు మేలు చేసే‘టీ’',\n",
              " 'ఫైబర్\\u200c రైస్\\u200cతో షుగర్\\u200c వ్యాధికి చెక్\\u200c',\n",
              " 'థైరాయిడ్\\u200c టెర్రర్\\u200c',\n",
              " 'డాక్టర్\\u200c స్రవంతి మదర్ ఆఫ్ చందన్',\n",
              " 'ఇప్పటికింకా నా వయసు',\n",
              " 'ప్రకృతి కాంత అక్షతలేయగ',\n",
              " \"ఆధునిక కాలంతో పోటీ పడ'లేఖ'\",\n",
              " 'బాత్\\u200cరూం సింక్స్\\u200c రూ 18 లక్షలట',\n",
              " 'వైరల్\\u200c మహిళ కంట్లో గండు తేనెటీగలు',\n",
              " 'టీడీపీ అభ్యర్థికి వింత పరిస్థితి',\n",
              " 'మరో రికార్డు కనిష్టానికి రూపాయి',\n",
              " 'ఆర్టీసీ బస్సు ఢీ ఏడుగురు దుర్మరణం',\n",
              " 'దొంగల హల్\\u200cచల్\\u200c',\n",
              " 'మంటలార్పే సత్తా ఉందా',\n",
              " 'వేడినీళ్లలో పడి చిన్నారి మృతి',\n",
              " 'బూటుకాలితో తన్నిన కానిస్టేబుల్\\u200c సస్పెన్షన్\\u200c',\n",
              " 'టవర్\\u200c ఎక్కి యువకుడి హల్\\u200cచల్\\u200c',\n",
              " 'కుటుంబ కలహాలతో వివాహిత ఆత్మహత్య',\n",
              " 'రెండు రాష్ట్రాల ప్రేమకథ',\n",
              " 'కాల్పుల్లో కొత్తకోణం సినిమాలో చూసి ఫైరింగ్\\u200c',\n",
              " 'ఎవరు లేరని స్నేహితుడి ఇంట్లోనే',\n",
              " 'పూడ్చిపెట్టిన మృతదేహానికి గుండుగీసిన దుండగులు',\n",
              " 'ప్రమాదాల నివారణకు చర్యలు',\n",
              " 'మున్సిపల్\\u200c పీఠంపై తొలి మహిళామణి',\n",
              " 'కల్తీ కేక్\\u200c తినడం వల్లే తండ్రీకొడుకులు మృతి',\n",
              " 'వ్యక్తి అనుమానాస్పద మృతి',\n",
              " 'టీఆర్\\u200cఎస్\\u200c సెక్యులర్\\u200c పార్టీ',\n",
              " 'టీడీపీ ప్లాన్\\u200c పోలీసులపై యాక్షన్\\u200c',\n",
              " 'టీడీపీ నాయకుడి ఇంటిలో పట్టుబడ్డ మద్యం',\n",
              " 'దివ్యాంగుడిని కార్లతో గుద్ది వెళ్లిపోయారు',\n",
              " 'డీజీపీ కార్యాలయం వద్ద చంద్రబాబు హైడ్రామా',\n",
              " 'మాచర్ల ఘటనపై స్పందించిన డీజీపీ',\n",
              " 'మూడు రాజధానులకే మా మద్దతు',\n",
              " 'మానవత్వం చాటుకున్న ఎమ్మెల్యే ఆర్కే',\n",
              " 'వైఎస్సార్\\u200cసీపీలో చేరిన మాజీమంత్రి',\n",
              " 'స్థానిక ఎన్నికల్లో నీ సత్తా చూపించు',\n",
              " 'నిప్పంటుకుని ఇద్దరు చిన్నారుల మృతి',\n",
              " 'బెదిరించి పొలాల్లోకి తీసుకెళ్లి లైంగికదాడి',\n",
              " 'మృతుల కుటుంబాలకు ఎమ్మెల్యే పిన్నెల్లి పరామర్శ',\n",
              " 'గుంటూరులో ఘోరప్రమాదం ఆరుగురు మృతి',\n",
              " 'వినోద్\\u200c ఖలాల్\\u200cపై పీడీ యాక్ట్\\u200c',\n",
              " 'తల్లిని చంపిన కుమారుడి అరెస్ట్\\u200c',\n",
              " 'దా‘రుణం’',\n",
              " 'చెవుడే శాపమైంది',\n",
              " 'చంద్రబాబు వల్ల అన్ని రకాలుగా నష్టపోయా',\n",
              " 'ఆర్డీఓ కార్యాలయాన్ని ఆశ్రయించిన వృద్ధ దంపతులు',\n",
              " 'తల్లి గిరిజను కలిసిన అమృతా ప్రణయ్\\u200c',\n",
              " 'ప్రియురాలిపై హత్యాయత్నానికి పాల్పడి',\n",
              " 'డ్రైవర్\\u200cని ఆ షాప్\\u200c వద్ద కారు ఆపమన్న మారుతీరావు',\n",
              " 'వృద్ధురాలిపై లైంగిక దాడి ఆపై హత్య',\n",
              " 'ప్రభుత్వ భూమికి ఎసరు',\n",
              " 'బైక్\\u200cను ఢీకొన్న లారీ',\n",
              " 'టీఆర్\\u200cఎస్\\u200c నాయకుడి దారుణ హత్య',\n",
              " 'మాజీ సర్పంచ్\\u200c దారుణ హత్య',\n",
              " 'అభ్యర్థులకు పెళ్లిళ్ల తిప్పలు',\n",
              " 'కాంగ్రెస్\\u200c నాయకుడిపై దాడి',\n",
              " 'భయాందోళనలో ప్రజలు',\n",
              " '9999 రూ 8 66 116',\n",
              " 'కారులో మంటలు',\n",
              " 'కేజీబీవీ విద్యార్థులకు అస్వస్థత',\n",
              " 'అభిరుచులకు రిటైర్మెంట్\\u200c ఉండదు',\n",
              " 'సైబర్\\u200c వేధింపులు కొత్త పుంతలు',\n",
              " 'భూ ఆక్రమణ వాల్టా ఉల్లంఘన',\n",
              " 'నగ్నంగా డ్యాన్స్\\u200c చేయాలంటూ మహిళపై',\n",
              " 'అక్రమ బంగారు బిస్కెట్ల పట్టివేత',\n",
              " 'నాచావుకు నేనే కారణం',\n",
              " 'ఒక్కటి చేసిన టిక్\\u200cటాక్\\u200c',\n",
              " 'ఆ ఘనత సీఎం కేసీఆర్\\u200cదే',\n",
              " '‘పరీక్షా’కాలం',\n",
              " 'నకిలీ వీసా స్టాంపింగ్\\u200c రాకెట్\\u200c గుట్టురట్టు',\n",
              " 'సర్కారు కళాశాలలో దుస్థితి',\n",
              " 'జీవన భారం మోయలేక వెళ్లిపోతున్నాం',\n",
              " 'స్మగ్లర్స్\\u200cకు క్యారియర్లుగా మహిళలు',\n",
              " 'తీరొక్క ద్రాక్ష రుచి చూద్దామా',\n",
              " 'సైబర్\\u200c నేరగాళ్లకు ముకుతాడు',\n",
              " 'మహబూబ్\\u200cనగర్\\u200cలో లారీ భీభత్సం',\n",
              " 'ఏ2 మద్దిలేటిని కస్టడీకి ఇవ్వండి',\n",
              " 'కీచకుడిని ఉరితీయాలి',\n",
              " 'మరోసారి తెరపైకి ‘దిశ’ నిందితుల ఎన్\\u200cకౌంటర్\\u200c కేసు',\n",
              " 'వరుడికి భారీ షాకిచ్చిన పెళ్లి కూతురు',\n",
              " 'చిచ్చురేపిన ఫేస్\\u200cబుక్\\u200c చాటింగ్\\u200c',\n",
              " 'రైలు కింద పడి విద్యార్థిని ఆత్మహత్య',\n",
              " 'ఆ ప్రభావం బేబీపై పడుతోందా',\n",
              " 'టెక్నాలజీతోనే నిర్మాణ వ్యయం తగ్గుతుంది',\n",
              " 'రోహిత్\\u200c శర్మ కోచ్\\u200cతో షాహిద్\\u200c కపూర్\\u200c',\n",
              " 'నా ముక్కు బాలేదన్నారు',\n",
              " 'అందుకే కోర్టును ఆశ్రయించా నటి',\n",
              " '‘అలా చేస్తేనే ఇండస్ట్రీలో రాణిస్తావు అన్నాడు’',\n",
              " 'చిన్నప్పుడే అమ్మకు ఫ్యాషన్\\u200cలో సలహాలు ఇచ్చేవాడిని’',\n",
              " 'నా భార్య కోసం జీవించాలనుకుంటున్నాను నటుడు',\n",
              " '‘దేవీ’ షార్ట్\\u200cఫిల్మ్\\u200c ట్రైలర్\\u200c రిలీజ్\\u200c',\n",
              " 'ఆ నమ్మకం భయపెడుతోంది',\n",
              " '‘డెమీ మోర్\\u200c’ రహస్యాలు బట్టబయలు',\n",
              " '9 మంది మహిళలతో సింగర్\\u200c బాగోతం',\n",
              " 'శుభకార్యానికి వెళ్లి మృత్యు ఒడిలోకి',\n",
              " 'ఉద్దానం వీరుడికి ఘన స్వాగతం',\n",
              " 'పల్లె ప్రగతికి విఘాతం',\n",
              " 'ఎవరిని సంప్రదించి ఎన్నికలు వాయిదా వేశారు',\n",
              " 'వలసలతో టీడీపీ కుదేలు',\n",
              " '‘కళా’కు పరాభవం',\n",
              " 'ఇది బీసీలకు దక్కిన అరుదైన గౌరవం',\n",
              " 'మెడిసిన్\\u200cలో మెరిసెన్\\u200c',\n",
              " 'సీఎం చిత్రపటం ఇంట్లో పెట్టుకుంటాం',\n",
              " 'టీడీపీ నేత కూన రవికుమార్\\u200c అరెస్ట్\\u200c',\n",
              " 'బతుకు దయనీయం కావాలి సాయం',\n",
              " 'ఎన్నాళ్లీ హత్యా రాజకీయాలు',\n",
              " 'కార్మికుల సొమ్ము కట్టలపాము పాలు',\n",
              " 'ఇలా ఉంటే చదువు సాగేదెలా',\n",
              " 'ఆర్భాటం చేశారు ఆదిలోనే వదిలేశారు',\n",
              " 'కలెక్టర్\\u200c గారి ప్రేమకథ',\n",
              " 'అబ్బే అంత భారం ఏం కాదు',\n",
              " 'అందుకే చంద్రబాబు కారణాలు వెతుకుతున్నారు',\n",
              " 'జెడ్పీ మాజీ అధ్యక్షురాలు తనయుడు ఆత్మహత్యా యత్నం',\n",
              " '9 10 తేదీల్లో కిరణ స్పర్శ',\n",
              " 'చంద్రబాబువి స్వార్థపూరిత రాజకీయాలు',\n",
              " 'అచ్చెన్న లీలలు ఇన్నన్ని కావయా',\n",
              " 'పేదోళ్ల ‘ఇంగ్లిష్\\u200c’ చదువుకు అడ్డు చెప్పొద్దు',\n",
              " 'అమ్మానాన్న బాగున్నారా',\n",
              " 'ఎర్రబెల్లి నంబర్\\u200c వన్\\u200c',\n",
              " '‘దయ’లేకుండా హత్య',\n",
              " 'భాగ్యనగర్\\u200c ఎక్స్\\u200cప్రెస్\\u200cలో నకిలీ టీసీ హల్\\u200cచల్\\u200c',\n",
              " 'యువతిపై సాముహిక అత్యాచారం అరెస్ట్\\u200c',\n",
              " 'బడికి పోయినా బతికెటోళ్లు',\n",
              " 'మేడారం జాతరకు హెలికాప్టర్\\u200c సర్వీసులు',\n",
              " 'కేజీతండా వాసికి అరుదైన అవకాశం',\n",
              " 'స్కూలు సేవలన్నిటికీ క్రెడో',\n",
              " 'ఉద్యోగుల రవాణాకు ఈ–వాహనాలు',\n",
              " 'ప్రకటనలు చూస్తే పైసలొస్తాయ్\\u200c',\n",
              " 'వాట్సాప్\\u200c చాలెంజ్\\u200cలో 5 స్టార్టప్\\u200cల ఎంపిక',\n",
              " 'వాట్సాప్\\u200c చాలెంజ్\\u200cలో 5 స్టార్టప్\\u200cల ఎంపిక',\n",
              " 'మీ భూమి చరిత్ర',\n",
              " '‘సోలార్\\u200c’ కేరాఫ్\\u200c ప్రాకృతిక్\\u200c పవర్\\u200c',\n",
              " 'కంపెనీల రవాణా సేవలకు ‘విజిల్\\u200c’',\n",
              " 'హోమ్\\u200c ట్యూషన్స్\\u200c ఆచార్య నెట్\\u200c',\n",
              " 'అయిదు నిమిషాల్లోనే బ్యాటరీ చార్జింగ్\\u200c',\n",
              " 'స్టాక్\\u200c మార్కెట్లు ఫండ్స్\\u200cపై విస్తృత సమాచారం',\n",
              " 'ఐపీఓ రూట్లో స్టార్టప్\\u200cలు',\n",
              " 'చేతక్\\u200c మళ్లీ వచ్చేసింది',\n",
              " 'స్టార్టప్\\u200cలపై రతన్\\u200c టాటా',\n",
              " 'అకస్మాత్తుగా బైక్\\u200c చెడిపోయిందా',\n",
              " 'అమెజాన్ ఫ్లిప్\\u200cకార్ట్\\u200cలు ఆర్థిక ఉగ్రవాద సంస్థలు',\n",
              " 'బైజూస్\\u200c మరో రికార్డు',\n",
              " 'మీ ఇంటికే మెకానిక్\\u200c',\n",
              " 'రెరాతో ఇన్వెంటరీ తగ్గింది',\n",
              " 'నేడు రేపు సాక్షి ప్రాపర్టీ షో',\n",
              " 'రియల్టీ రివ్వు రివ్వు రివ్వు',\n",
              " 'ప్రవాసులు దిగొస్తున్నారు',\n",
              " 'రెరా నమోదిత ప్రాజెక్ట్స్\\u200cలో నో ఫైర్\\u200c సేఫ్టీ',\n",
              " 'క్రెడాయ్\\u200c న్యాట్\\u200cకాన్\\u200cకు 1300 మంది హాజరు',\n",
              " 'ఆదిభట్లలో ఆర్క్\\u200c ప్రాజెక్ట్\\u200c',\n",
              " 'మరింత అద్దె కావాలా',\n",
              " '5 నగరాల్లో క్రెడాయ్\\u200c హరిత భవనాలు',\n",
              " 'అపర్ణా వెన్\\u200cస్టర్\\u200c నుంచి కొత్త ఉత్పత్తులు',\n",
              " 'నిర్మాణ కార్మికులు దొరకట్లేదు',\n",
              " 'తెలుగు రాష్ట్రాల స్థిరాస్తి సమాచారం తెలుగులో',\n",
              " 'అందరికీ అందుబాటు ఇల్లు',\n",
              " 'నివాస గృహ మార్కెట్\\u200cకు పూర్వవైభవం',\n",
              " 'హైదరాబాద్\\u200c రియల్టీలో వృద్ధి',\n",
              " 'రియల్టీలోకి పెట్టుబడుల ప్రవాహం',\n",
              " 'అత్యంత చౌక నగరం ఢిల్లీ',\n",
              " 'రుణం తీసుకుని ఇంటిని కొంటే ప్రయోజనాలు',\n",
              " 'హైదరాబాద్\\u200cలో నోబ్రోకర్\\u200c కామ్\\u200c సేవలు',\n",
              " '9 పట్టణాల్లో అందుబాటు ధరల గృహాల పరిస్థితి',\n",
              " 'ఎగుమతుల ప్రోత్సాహానికి చర్యలు',\n",
              " 'హైదరాబాద్\\u200cలో 32 శాతం తగ్గిన గృహ విక్రయాలు',\n",
              " 'ఎన్\\u200cసీఎల్\\u200c బిల్డ్\\u200cటెక్\\u200c విస్తరణ',\n",
              " 'వచ్చే నెల 9 10 తేదీల్లో సాక్షి ప్రాపర్టీ షో',\n",
              " 'గృహాల సేల్స్ లాంచింగ్స్\\u200c రెండింట్లోనూ క్షీణత',\n",
              " 'హైదరాబాద్\\u200cలో గృహ నిర్మాణాలు ఆలస్యం',\n",
              " 'నిలిచిన ఇళ్ల ప్రాజెక్టుల కోసం ప్రత్యేక నిధి',\n",
              " 'సాక్షి ప్రాపర్టీ షో నేడే',\n",
              " 'తక్కువ వడ్డీకే రుణం పొందే అవకాశం',\n",
              " 'దివాలా చర్యల్లో రూ 4 6 లక్షల కోట్ల లక్షల',\n",
              " 'దివాలా చర్యల్లో రూ 4 6 లక్షల కోట్ల లక్షల',\n",
              " 'ఇతర మెట్రోలతో పోలిస్తే హైదరాబాద్\\u200c బెస్ట్\\u200c',\n",
              " 'రియల్టీ లావాదేవీల్లో బ్లాక్\\u200c మనీదే హవా',\n",
              " 'గృహ ప్రవేశానికి సిద్ధంగా ఉన్న వాటిల్లోనే కొంటాం',\n",
              " 'గృహ విక్రయాల్లో 36 శాతం వృద్ధి',\n",
              " 'రియల్టీ కుబేరులు',\n",
              " 'రియల్టీ రంగానికి 2019లో నిరాశే',\n",
              " 'టెక్నాలజీతోనే నిర్మాణ వ్యయం తగ్గుతుంది',\n",
              " 'పూర్తిగా జూపల్లి చేతికి ‘మై హోమ్\\u200c’',\n",
              " 'ధర వాస్తు నీళ్లకే ప్రాధాన్యం',\n",
              " 'ఉత్తర పశ్చిమ ప్రాంతాల్లోనే వృద్ధి',\n",
              " 'ఆఫర్లతో కస్టమర్లకు వల',\n",
              " 'డబ్బా బిల్డింగ్స్\\u200c కట్టొద్దు',\n",
              " 'ఏడుకొండల వాడికి ఏకాంత సేవలు',\n",
              " 'నవ్వుకున్న వారే ఇప్పుడు ఆలోచిస్తున్నారు',\n",
              " 'లెక్చరర్\\u200cపై ప్రిన్సిపాల్\\u200c దాడి',\n",
              " 'సెమీఫైనల్స్\\u200cకు రిజర్వ్\\u200c డే కావాలి',\n",
              " 'మహిళా క్రికెటర్లతో అసభ్య ప్రవర్తన',\n",
              " 'ఫలరారాజు విలవిల',\n",
              " 'చంద్రబాబు నాటకాల్ని నమ్మొద్దు',\n",
              " 'దూసుకొస్తున్న బీఎస్\\u200c 6',\n",
              " '‘అందుకే బాబును ప్రజలు ఇంటికి పంపారు’',\n",
              " '‘ప్రపంచాన్ని జయించే ఒకే ఆయుధం విద్య’',\n",
              " 'విజయనగరం చేరుకున్న సీఎం వైఎస్\\u200c జగన్\\u200c',\n",
              " 'తప్పుడు ఆరోపణలు ప్రజలు హర్షించరు',\n",
              " 'సీఐఎస్\\u200cఎఫ్\\u200c కానిస్టేబుల్\\u200c ఆత్మహత్య',\n",
              " \"స్టైల్\\u200c డెనిమ్\\u200c 'జీన్\\u200c'దాబాద్\\u200c\",\n",
              " 'ఆకాశ పెళ్లికొడుకు',\n",
              " 'బాబు గారి ఇంట్లో బుట్ట భోజనం',\n",
              " 'త్వరలో మా ఏపీ ఎన్నికలు',\n",
              " 'జగదంబాదేవి భక్తుడు ప్రవీణ్\\u200c బాబా',\n",
              " 'సాధికారతకు నిలువుటద్దం',\n",
              " 'అదరగొట్టిన అక్కాచెల్లెళ్లు',\n",
              " 'తన ఓటమికి కారణమాయ్యడని కత్తితో దాడి',\n",
              " 'బాసర ట్రిపుల్\\u200c ఐటీలో విద్యార్థి ఆత్మహత్యాయత్నం',\n",
              " 'ఆ లేఖ వెనుక రాజకీయ కుట్ర',\n",
              " 'పోలవరం పరుగులు పెడుతోంది',\n",
              " 'యాత్రికుడిగా కొత్త అనుభవం',\n",
              " 'తాత్త్విక పరీమళాల కథల మల్లె',\n",
              " 'కలిగిన పీడ పోయినది',\n",
              " 'వడ్డిస్తూ తినలేము',\n",
              " 'వాతావరణ సూచన హర్షాభావం',\n",
              " 'ఇక ఇంటికే ఇసుక',\n",
              " 'థామస్\\u200c–ఉబెర్\\u200c కప్\\u200c టోర్నీ వాయిదా',\n",
              " 'మన మహిళలు మరెన్నో పతకాలు సాధిస్తారు',\n",
              " 'సైనా సింధులకు క్లిష్టమైన ‘డ్రా’',\n",
              " 'భారత్\\u200c చేతిలో ఆసీస్\\u200c షూటౌట్\\u200c',\n",
              " 'ప్రపంచ నంబర్\\u200c వన్\\u200c బాక్సర్\\u200cగా అమిత్\\u200c పంఘాల్\\u200c',\n",
              " 'మరో ఛాన్స్\\u200c కొట్టేసిన బుట్ట బొమ్మ',\n",
              " 'కండక్టర్\\u200c నుంచి సూపర్\\u200c స్టార్\\u200c వరకు ప్రతిదీ ఆశ్చర్యమే',\n",
              " 'అతడే ఒక సైన్యం',\n",
              " 'లెక్చరర్\\u200cపై ప్రిన్సిపాల్\\u200c దాడి',\n",
              " 'సీఎం వైఎస్\\u200c జగన్\\u200cతో ముకేష్\\u200c అంబానీ భేటీ',\n",
              " 'ఇంటి వద్దకే పింఛన్ల పంపిణీలో ఏపీ సర్కార్\\u200c రికార్డ్\\u200c',\n",
              " 'గుంటూరులో ఘోరప్రమాదం ఆరుగురు మృతి',\n",
              " 'మేరీకోమ్\\u200c బాధ్యతారాహిత్యం',\n",
              " 'రిజర్వేషన్లు 50 మించొద్దు',\n",
              " 'స్టాలిన్\\u200cకు సీఎం జగన్ జన్మదిన శుభాకాంక్షలు',\n",
              " 'ఎస్సై వాహనంలో ఆసుపత్రికి వెళ్లిన గర్భిణీ',\n",
              " 'ఇద్దరు జబర్దస్త్\\u200c ఆర్టిస్టుల అరెస్టు',\n",
              " 'ఆలిండియా కోటా పీజీ వైద్య సీట్ల భర్తీకి షెడ్యూల్\\u200c షెడ్యూల్\\u200c',\n",
              " 'శ్రీనివాస్\\u200c ఇంట్లో కొనసాగుతున్న ఐటీ సోదాలు',\n",
              " 'ప్రాణాలతో తిరిగి వస్తామనుకోలేదు',\n",
              " 'సబ్\\u200c రిజిస్ట్రార్\\u200c కార్యాలయాలపై ఏసీబీ కొరడా',\n",
              " 'ప్రజాసేవే వైఎస్సార్\\u200cసీపీ సిద్ధాంత బలం',\n",
              " 'ఖైదీలే కర్షకులు',\n",
              " 'ఫుడ్\\u200c ప్రాసెసింగ్\\u200c యూనిట్లకు రుణాలు',\n",
              " 'మీ ఇంటికే మెకానిక్\\u200c',\n",
              " 'బైజూస్\\u200c మరో రికార్డు',\n",
              " '90 నిముషాల్లో ఫోన్\\u200c డెలివరీ',\n",
              " 'అమెజాన్ ఫ్లిప్\\u200cకార్ట్\\u200cలు ఆర్థిక ఉగ్రవాద సంస్థలు',\n",
              " 'చేతక్\\u200c మళ్లీ వచ్చేసింది',\n",
              " 'ఐపీఓ రూట్లో స్టార్టప్\\u200cలు',\n",
              " 'కంపెనీల రవాణా సేవలకు ‘విజిల్\\u200c’',\n",
              " 'స్కూలు సేవలన్నిటికీ ‘క్రెడో’',\n",
              " 'లోన్\\u200c కావాలా నాయనా',\n",
              " 'భారీ విస్తరణ ప్రణాళికలో షావోమీ',\n",
              " 'లైవ్\\u200c క్లాస్\\u200cలతో కాసుల వర్షం',\n",
              " 'మరో భారీ ప్రభుత్వ బ్యాంకు',\n",
              " 'మీ భూమి చరిత్ర',\n",
              " 'డైలమాలో అక్మల్\\u200c కెరీర్\\u200c',\n",
              " 'నమో నారసింహాయా',\n",
              " 'వేల్యూ ఫండ్స్\\u200cను కొనసాగించవచ్చా',\n",
              " 'పాప కోసం ఏ ఫండ్\\u200c బెటర్\\u200c',\n",
              " 'రిటైర్మెంట్\\u200cకు ఎంత కావాలి',\n",
              " 'మిడ్\\u200c క్యాప్ స్మాల్\\u200c క్యాప్\\u200cలో మంచి అవకాశాలు',\n",
              " 'రిలయన్స్\\u200c ఔట్\\u200c ఫండ్స్\\u200cపై ప్రభావం ఉంటుందా',\n",
              " 'హెల్త్\\u200c ఇన్సూరెన్స్ చాలా అవసరం',\n",
              " 'నన్నడగొద్దు ప్లీజ్\\u200c',\n",
              " 'ఆర్థికంగా వెలిగిపోదాం',\n",
              " 'పెట్టుబడికి పుత్తడి పనికిరాదా',\n",
              " 'డెట్\\u200c ఫండ్స్\\u200cలో ఇన్వెస్ట్\\u200c చేయవచ్చా',\n",
              " 'మార్చి 31 వరకు తెలంగాణలో జనతా కర్ఫ్యూ',\n",
              " 'కరోనా ఎఫెక్ట్\\u200c 75 జిల్లాల్లో లాక్\\u200cడౌన్\\u200c',\n",
              " 'ఆసక్తి కలిగిస్తున్న ఆద్య సితారల ‘టెలిపతి ఛాలెంజ్\\u200c’',\n",
              " '‘శివ’రాత్రి స్పెషల్\\u200c స్టోరీ',\n",
              " 'అపార క్షమాగుణ సంపన్నుడు',\n",
              " 'పేతురును వరించిన ఆత్మీయ ఐశ్వర్యం',\n",
              " 'మనిషి స్వార్థంతో మసకబారిన దేవుని ప్రేమ',\n",
              " 'కథాసంక్రాంతి',\n",
              " 'వైకుంఠ ఏకాదశికి ముస్తాబు',\n",
              " 'అర్ధమైంది గురువర్యా',\n",
              " 'కరస్పర్శ కరువైన వేళ',\n",
              " 'ఇరుగు వైరస్\\u200c పొరుగు వైరస్\\u200c',\n",
              " 'పరిశుభ్రతే పరమధర్మం',\n",
              " 'సైన్స్\\u200cను విశ్వసిస్తేనే విజయం',\n",
              " 'ఏ న్యాయానికి ఈ మూల్యం',\n",
              " 'జనం దృష్టిలో తనే దోషి',\n",
              " 'న్యాయవ్యవస్థ స్వతంత్రత పై నీలినీడలు',\n",
              " 'సార్క్\\u200c పునరుద్ధరణ సాధ్యమేనా',\n",
              " 'పౌరసత్వ నిరూపణకు మతం ఆధారమా',\n",
              " 'మానవ స్పర్శకు కరోనాతో గండి',\n",
              " 'పౌరసత్వ సవరణ చట్టం దళితులకే వరం',\n",
              " 'ముసుగు కరోనాది లొసుగు బాబుది',\n",
              " 'మహమ్మారి కరోనా ప్రపంచానికే పెనుసవాల్\\u200c',\n",
              " 'భయానకం కాదు మనోహరం',\n",
              " 'ఏది హాస్యం ఏది అపహాస్యం',\n",
              " 'సమాజానికి ‘అమృత’ సందేశం',\n",
              " 'ఈ సంఘర్షణ ఇంకెంతకాలం',\n",
              " 'మైనార్టీల రక్షణ ముసుగులో దాడులు',\n",
              " 'మైత్రీపురి పొత్తూరి',\n",
              " 'బెస్ట్\\u200c సీఎం వైఎస్\\u200c జగన్\\u200c',\n",
              " 'సింధియా నిష్క్రమణతో చేతికి చిక్కులు',\n",
              " 'పదవ వసంతంలోకి అడుగిడిన వైఎస్సార్\\u200cసీపీ',\n",
              " 'ఇళ్లలోనే ఇటాలియన్లు',\n",
              " 'రాజ్యాంగబద్ధతే రిజర్వేషన్లకు రక్షణ',\n",
              " 'బీజేపీకి బిహార్\\u200c ఎంత ముఖ్యం',\n",
              " 'అంబేడ్కర్\\u200c సవరణకే ‘ఎసరా’',\n",
              " 'సమానత్వం ఎక్కడ',\n",
              " 'త్వరపడండి రూపాయికే గుడ్డు',\n",
              " 'నిజమైన వారసులు',\n",
              " 'ఒక ఆకాంక్ష ఒక విలువ',\n",
              " 'తీరు మార్చిన పోరు',\n",
              " 'దోపిడీదారులు',\n",
              " 'మరో వ్యవసాయ విప్లవానికి బీజాలు',\n",
              " 'పెద్దదిక్కు ‘పొత్తూరి’',\n",
              " 'నేరస్తుల చెరలో ‘న్యాయ’ శాస్త్రం',\n",
              " 'నమస్కార్\\u200c కరోనా',\n",
              " 'మహమ్మారిని మించిన అమానుషత్వం',\n",
              " 'మహిళా నాయకత్వం చెల్లని చోటు',\n",
              " 'విశాఖ రైల్వే జోన్\\u200cపై ఊగిసలాట',\n",
              " 'బడుగు వర్గాలకు బాబు ద్రోహం',\n",
              " 'ట్రంపూ విశాఖపట్టణం మనమూ',\n",
              " '‘సుప్రీం’ చైతన్యం కోల్పోతోందా',\n",
              " 'మార్కెట్లో ‘సంక్షేమ’ డబ్బు',\n",
              " 'బహుజనుల బాగుకే మూడు రాజధానులు',\n",
              " 'మెదళ్లలో తుఫాను',\n",
              " 'దత్తుడు గార్లెండ్స్\\u200c బాబ్జీ',\n",
              " 'భావజాలం రగిలించిన ఘర్షణలు',\n",
              " 'ట్రంప్\\u200c రాకతో ఒరిగిందేంటి',\n",
              " 'రాజధాని మౌన సిక్తం',\n",
              " 'పిల్లల్ని చెరబట్టందే చదువు చెప్పలేమా',\n",
              " 'మందుల వాడకంలో మనమే టాప్\\u200c',\n",
              " 'ఈ దీవెనలు బడుగుల వెలుగుదివ్వెలు',\n",
              " 'ఎమ్మెల్సీ బరిలో సుభాష్\\u200cరెడ్డి',\n",
              " 'సమాజంలో సగం అధికారంలో అధమం',\n",
              " 'భారత్\\u200c పర్యటనలో భారీ ప్రయోజనం',\n",
              " 'కోటా రక్షణకు పటిష్ట చట్టం',\n",
              " 'ట్రంప్\\u200cతో తేల్చుకోవాల్సినవి',\n",
              " 'నిద్రలోనే తనువు చాలించాడు',\n",
              " 'మానవ ప్రగతికి మేనిఫెస్టో',\n",
              " 'బానిసత్వం నేటికీ నేరం కాదా',\n",
              " 'లెగ్\\u200c పీస్\\u200c డిప్లొమసీ',\n",
              " 'తూర్పు కనుమల్లోకి రాజ్యం ప్రవేశం',\n",
              " 'పిట్ట కథలు',\n",
              " 'గుజరాత్\\u200c మోడల్\\u200cపై గోడలెందుకు',\n",
              " 'కమ్యూనిస్టు ప్రణాళిక ఘనత',\n",
              " 'తల్లిభాష నిలవాలి ఇంగ్లిష్\\u200cతో గెలవాలి',\n",
              " 'అక్షరాలా నడిచే విజ్ఞాన సర్వస్వం రాంభట్ల',\n",
              " 'పదోన్నతుల కోటాలోనూ అన్యాయమే',\n",
              " 'హోలీ వేడుకల్లో వింత ఆచారం',\n",
              " '‘ఎమ్మెల్సీగా అవకాశం ఇవ్వండి’',\n",
              " 'బాన్సువాడలో నకిలీ డాక్టర్\\u200c కలకలం',\n",
              " 'విభజన రాజకీయాలపై అభివృద్ధి గెలుపు',\n",
              " 'ఏసీబీకి చిక్కిన ఆర్\\u200cఐ',\n",
              " 'స్వీయ తప్పిదాలతోనే ఈ దుస్థితి',\n",
              " 'మూడు రాజధానులు ముమ్మాటికీ అవసరమే',\n",
              " 'తుపాకీ పేల్చిన మాజీ నక్సలైట్\\u200c',\n",
              " 'అభివృద్ధికే ఢిల్లీ ఓటరు పట్టం',\n",
              " 'ఉపాధికి వెళ్తే అప్పులే మిగిలాయి',\n",
              " 'దీన్\\u200cదయాళ్\\u200c అడుగుజాడలు అనుసరణీయం',\n",
              " 'బాబు ‘వలస’ బంధం ‘రాయిటర్స్\\u200c’',\n",
              " 'ఎన్నారై పాలసీ రావాలి',\n",
              " 'అంతర్జాతీయ విద్యకు అతిపెద్ద దెబ్బ కరోనా',\n",
              " 'గ్రేటాంధ్ర చౌరస్తా',\n",
              " 'లవ్\\u200c ఫెయిల్యూర్\\u200c అని స్టేటస్\\u200c అంతలోనే',\n",
              " 'దానవీరులు',\n",
              " 'పతన ఆర్థిక వ్యవస్థ పట్టదా',\n",
              " 'వినరా నాజర్\\u200c గాథను నేడూ',\n",
              " 'రుజువులు చూపకపోతే పౌరులు కారా',\n",
              " \"హీబా'సారం'\",\n",
              " 'ప్రాణం నిలిపే పోషణ ఏది',\n",
              " 'పెళ్లి చేయడం లేదన్న మనస్తాపంతో',\n",
              " 'బడుగులకు ఈ బడ్జెట్\\u200cతో ఒరిగిందేమిటి',\n",
              " 'జాతీయ రహదారిపై పెద్దపులి కలకలం',\n",
              " 'ఎగువ సభ ఎవరికోసం',\n",
              " 'సమస్యల పరిష్కారంలో భారతీయులు భేష్\\u200c',\n",
              " '‘వైరస్\\u200c’ల ఆటబొమ్మ మన శరీరం',\n",
              " 'చిన్నపరిశ్రమ ఆశలకు గండి',\n",
              " 'సంపన్నుల సేవ ఇంకెంతకాలం',\n",
              " 'పసుపు ధరలపై ‘కరోనా’ కాటు',\n",
              " 'అంబేడ్కర్\\u200c పత్రికకు వందేళ్లు',\n",
              " 'కొనుగోలు శక్తి పెంపే బడ్జెట్\\u200c లక్ష్యం',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Q_vRqOTlYEu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5a63070a-fd7d-4828-b9d3-bbea133bc301"
      },
      "source": [
        "bl"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0,\n",
              " 0.5946035575013605,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6223329772884784,\n",
              " 0.6147881529512643,\n",
              " 1.0,\n",
              " 0.5946035575013605,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0,\n",
              " 0.6431870218238024,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.5946035575013605,\n",
              " 1.0,\n",
              " 0.6431870218238024,\n",
              " 0.6431870218238024,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.6803749333171202,\n",
              " 0.05979002145444452,\n",
              " 0.06897167579387467,\n",
              " 1.0,\n",
              " 0.7037259479962376,\n",
              " 1.0,\n",
              " 0.1554427880977443,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.45966135761245924,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7037259479962376,\n",
              " 0.5169731539571706,\n",
              " 0.45966135761245924,\n",
              " 0.5506953149031838,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.2846946938149361,\n",
              " 1.0,\n",
              " 0.41113361690051975,\n",
              " 0.15777684932819508,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.481571310902054,\n",
              " 1.0,\n",
              " 0.9036020036098448,\n",
              " 0.8187307530779819,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 0.6042750794713536,\n",
              " 0.7598356856515925,\n",
              " 0.6042750794713536,\n",
              " 0.6223329772884784,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 0.8091067115702212,\n",
              " 1.0,\n",
              " 0.48109772909788073,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.5623413251903491,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.6042750794713536,\n",
              " 0.8187307530779819,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865476,\n",
              " 0.7788007830714049,\n",
              " 0.5623413251903491,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 0.6042750794713536,\n",
              " 0.5946035575013605,\n",
              " 0.8187307530779819,\n",
              " 0.7071067811865476,\n",
              " 0.5789300674674098,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.4417918226831577,\n",
              " 0.7071067811865475,\n",
              " 0.7071067811865475,\n",
              " 0.7186082239261684,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.8408964152537145,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.5946035575013605,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.668740304976422,\n",
              " 0.7186082239261684,\n",
              " 0.8408964152537145,\n",
              " 0.7598356856515925,\n",
              " 0,\n",
              " 0.668740304976422,\n",
              " 0.8408964152537145,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.32668286409255015,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865476,\n",
              " 0.8408964152537145,\n",
              " 0.8408964152537145,\n",
              " 0.6223329772884784,\n",
              " 0.4728708045015879,\n",
              " 0.5946035575013605,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.7186082239261684,\n",
              " 0.7952707287670506,\n",
              " 0.7598356856515925,\n",
              " 0.668740304976422,\n",
              " 0.8187307530779819,\n",
              " 0.7165313105737893,\n",
              " 0.537284965911771,\n",
              " 0.4347208719449914,\n",
              " 0.8187307530779819,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.537284965911771,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.7071067811865476,\n",
              " 0.6223329772884784,\n",
              " 0.7598356856515925,\n",
              " 0.7598356856515925,\n",
              " 0.4728708045015879,\n",
              " 0.6042750794713536,\n",
              " 0.5917606269910581,\n",
              " 0.5789300674674098,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.42383656282787796,\n",
              " 0.537284965911771,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9036020036098448,\n",
              " 0.7071067811865475,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.6147881529512643,\n",
              " 0.668740304976422,\n",
              " 0.7071067811865476,\n",
              " 0.6223329772884784,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 0.4417918226831577,\n",
              " 0.7071067811865476,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.7598356856515925,\n",
              " 0.5917606269910581,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 0.9036020036098448,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6223329772884784,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 0.537284965911771,\n",
              " 1.0,\n",
              " 0.5917606269910581,\n",
              " 0.7071067811865476,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.5169731539571706,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.5623413251903491,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5623413251903491,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.49473859088183875,\n",
              " 1.0,\n",
              " 0.4417918226831577,\n",
              " 0.7071067811865475,\n",
              " 0.7071067811865475,\n",
              " 0.7186082239261684,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.5789300674674098,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6731821382417487,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.4417918226831577,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5946035575013605,\n",
              " 0.7598356856515925,\n",
              " 0.7952707287670506,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7186082239261684,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6803749333171202,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.537284965911771,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0,\n",
              " 1.0,\n",
              " 0.5946035575013605,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8187307530779819,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8801117367933934,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 0.7598356856515925,\n",
              " 0.7037259479962376,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6223329772884784,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7952707287670506,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5081327481546147,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.41113361690051975,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6147881529512643,\n",
              " 0.5946035575013605,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6731821382417487,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5623413251903491,\n",
              " 0.49473859088183875,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8187307530779819,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865475,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 1.0,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7165313105737893,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5946035575013605,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6147881529512643,\n",
              " 0.6147881529512643,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6389431042462724,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9036020036098448,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.6025286104785453,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.668740304976422,\n",
              " 0.8091067115702212,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 0.9036020036098448,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5623413251903491,\n",
              " 0.7598356856515925,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.7598356856515925,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.668740304976422,\n",
              " 0.7165313105737893,\n",
              " 0.537284965911771,\n",
              " 0.6042750794713536,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5789300674674098,\n",
              " 0.5946035575013605,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.668740304976422,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7788007830714049,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.9036020036098448,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.7598356856515925,\n",
              " 0.8408964152537145,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.8408964152537145,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7165313105737893,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.5623413251903491,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865476,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 0.7071067811865476,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 0.7598356856515925,\n",
              " 1.0,\n",
              " 1.0,\n",
              " 1.0,\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kNVOWPXFIn0k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4164f4d4-347f-4976-acbf-17be38f412f1"
      },
      "source": [
        "summarize(\n",
        "    \"పాకిస్తాన్‌ మాజీ క్రికెటర్‌ షోయబ్‌ అక్తర్‌ చైనీయులపై మండిపడ్డారు. ఏది పడితే అది తిని ప్రపంచాన్ని ప్రమాదంలోకి నెట్టారని ఆగ్రహం వ్యక్తం చేశారు. అసలు గబ్బిలాలు, కుక్కలు, పాములు, పిల్లులు, ఎలుకల్ని ఎలా తింటారని విస్మయం వ్యక్తం చేశారు. వాటి రక్తం, వ్యర్థాలను సైతం ఆహారంగా తీసుకునే చైనీయులపై కోపం వస్తోందని అన్నారు. కరోనా వ్యాప్తితో ప్రపంచంలోని అన్ని దేశాలు తీవ్ర ఇబ్బందులు ఎదుర్కొంటున్నాయని పేర్కొన్నారు. పర్యాటకం దెబ్బతిందని, ఆర్థిక వ్యవస్థ క్షీణించిందని  తెలిపారు. కోవిడ్‌ ప్రభావం క్రీడలపైనా పడిందని తన యూట్యూబ్‌ చానెల్‌లో చెప్పుకొచ్చారు. \"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'‘ఏది పడితే అది తిని ఈ మహమ్మారిని తెచ్చారు’'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNhCDi_6many",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "bab5cb1a-8ad8-4557-efc6-8c56d5b33c5c"
      },
      "source": [
        "summarize(\"దేశంలో జరిగే అన్ని ఫుట్‌బాల్‌ మ్యాచ్‌లను ఈ నెల 31 వరకు రద్దు చేస్తూ అఖిల భారత ఫుట్‌బాల్‌ సమాఖ్య (ఏఐఎఫ్‌ఎఫ్‌) శనివారం నిర్ణయం తీసుకుంది. దాంతో ఐ–లీగ్, డివిజన్‌–2, యూత్‌ లీగ్, గోల్డెన్‌ లీగ్, జాతీయ టోర్నీలు రద్దయ్యాయి. ఐ–లీగ్‌లోని 28 మ్యాచ్‌లను ప్రేక్షకులు లేకుండానే నిర్వహించాలని ఏఐఎఫ్‌ఎఫ్‌ తొలుత అనుకున్నా... కేంద్ర ఆరోగ్య మంత్రిత్వ శాఖ సలహా మేరకు ఈ నెల చివరి వరకు దేశంలో ఎటువంటి ఫుట్‌బాల్‌ మ్యాచ్‌లను నిర్వహించరాదని  నిర్ణయించింది.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'31 వరకు దేశంలో ‘నో’ ఫుట్\\u200cబాల్\\u200c'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfQs9BFHnEqE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5451ac50-5948-4684-f92d-c47a4800bfd0"
      },
      "source": [
        "summarize(\"కరోనావైరస్‌ మహమ్మారి కట్టడి కోసం లాక్‌డౌన్‌ విధించిన నేపథ్యంలో దేశీ స్మార్ట్‌ఫోన్స్‌ పరిశ్రమ తీవ్రంగా నష్టపోనుంది. ఇది సుమారు 2 బిలియన్‌ డాలర్ల మేర ఉండొచ్చని కౌంటర్‌పాయింట్‌ రీసెర్చ్‌ సంస్థ అంచనా వేసింది. మార్చి, ఏప్రిల్‌లో విక్రయాలు గణనీయంగా మందగించడం ఇందుకు కారణంగా ఉంటుందని పేర్కొంది. మార్చి మధ్య దాకా కరోనా మహమ్మారి ప్రభావం ఒక మోస్తరుగానే ఉన్నప్పటికీ.. ఆ తర్వాత విజృంభిస్తుండటంతో లాక్‌డౌన్‌ అనివార్యమైందని వివరించింది.దీని ఫలితంగా 2020లో స్మార్ట్‌ఫోన్ల విక్రయం గతేడాది నమోదైన 15.8 కోట్లతో పోలిస్తే 3 శాతం తగ్గి 15.3 కోట్లకు పరిమితం కావొచ్చని అంచనా వేసింది. వార్షిక ప్రాతిపదికన చూస్తే మార్చిలో 27 శాతం తగ్గనుండగా, ఏప్రిల్‌ 14 దాకా లాక్‌డౌన్‌ కొనసాగితే ఈ నెలలో దాదాపు 60 శాతం తగ్గుదల నమోదు కావొచ్చని కౌంటర్‌పాయింట్‌ రీసెర్చ్‌ అసోసియేట్‌ డైరెక్టర్‌ తరుణ్‌ పాఠక్‌ తెలిపారు. కరోనా వైరస్‌ మహమ్మారికి మూలకేంద్రమైన చైనా నుంచి విడిభాగాల సరఫరా దెబ్బతినడం వల్ల ఈ ఏడాది తొలి త్రైమాసికంలో స్మార్ట్‌ఫోన్‌ తయారీ సంస్థలు తీవ్రంగా ఇబ్బందిపడ్డాయి.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'భారీ గ్రాఫిక్స్\\u200cతో వస్తున్న ‘అంగుళీక’'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2aDmNwonUQ0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2234baf5-af06-45ca-e7a4-7d251fcd33cd"
      },
      "source": [
        "summarize(\"కోవిడ్‌–19 కేసులపై డిపార్ట్‌మెంట్‌లో ఎవరూ మాట్లాడవద్దని ముఖ్యంగా మీడియాతో అసలు చర్చించవద్దని డీజీపీ మహేందర్‌రెడ్డి ఆదేశాలు జారీ చేశారు. గత 50 రోజులుగా లాక్‌డౌన్‌ కారణంగా.. జనసంచారం లేకపోవడం, అంతా ఇళ్లకే పరిమితమవడంతో రాష్ట్రంలో నేరాలు గణనీయంగా తగ్గుముఖం పట్టాయి. మర్కజ్‌ లింకులు, ఇక్కడి నుంచి వలస కూలీలను పంపడం, రాష్ట్రానికి వచ్చిన వలస కూలీల గుర్తింపు వరకు పోలీసులు అన్నీ తామై వ్యవహరించారు. కేంద్ర– రాష్ట్ర ప్రభుత్వాలు లాక్‌డౌన్‌కు మెజారిటీ ప్రాంతాల్లో మినహాయింపులు ఇచ్చాయి. మరోవైపు నేరాలు, దోపిడీలు, రోడ్డు ప్రమాదాలు, హత్యలు, దొంగతనాల కేసులు కూడా పెరుగుతున్నాయి. ఇకపై కరోనాతోపాటు సాధారణ నేరాల నియంత్రణకు కృషి చేయాలని డీజీపీ ఆదేశించారు.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'అమెజాన్ ఫ్లిప్\\u200cకార్ట్\\u200cలు ఆర్థిక ఉగ్రవాద సంస్థలు'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ts2g_CAlnkhJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a59fd6da-06f7-444d-8731-9800fe1cfc6c"
      },
      "source": [
        "summarize(\"అమెరికా అధ్యక్షుడు డొనాల్డ్‌ ట్రంప్‌ ఆడవారిపై అసభ్య వ్యాఖ్యలు చేసిన వీడియో అమెరికాలో కలకలం రేపింది. తరువాత అది నకిలీదని తేలింది. ఓ హాలీవుడ్‌ హీరోయిన్‌ పోర్న్‌ క్లిప్‌ ఇంటర్నెట్‌లో ప్రత్యక్షం.. అందులో ఉన్నది తాను కాదన్నా ఎవరూ నమ్మలేదు. కానీ, ఆమె చెప్పేది నిజమే. మనకు నచ్చిన సెలబ్రిటీల శరీరానికి సామాన్యుల ముఖాలను అంటించి మురిసిపోయే వీలున్న ఆర్టిఫిషియల్‌ ఇంటెలిజెన్స్‌ ఆధారంగా పనిచేసే ‘డీప్‌ఫేక్‌’సాఫ్ట్‌వేర్‌ సృష్టిస్తోన్న మాయాజాలమిది.ఈ యాప్‌ వచ్చిన కొత్తలో తమకు ఇష్టమైన హీరో, గాయకులు, రాజకీయ నాయకులను అనుకరిస్తూ.. పలు ఫొటోలు, వీడియోలు సృష్టించి, వాటిని సోషల్‌ మీడియా వేదికలపై పంచుకునేవారు. వాటికి వచ్చే లైకులు చూసి సంబరపడిపోయే వారు. అక్కడి వరకే పరిమితమైతే సరిపోయేది. కానీ, కొందరు మరో అడుగు ముందుకేసి.. సంచలనం సృష్టించాలని, తమ టీవీ చానళ్లకు రేటింగులను పెంచాలనే దురుద్దేశంతో డీప్‌ఫేక్‌ను వాడుకుని సెలబ్రిటీల ప్రతిష్టను దెబ్బతీసేలా తప్పుడు సందేశాలు, అసభ్య వీడియోలు సృష్టించి వాటిని వైరల్‌ చేస్తున్నారు. అవి నకిలీవని నిరూపించుకునేందుకు బాధితులు నానా తంటాలు పడుతున్నారు. \")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'సెలబ్రిటీల ఫేక్\\u200c వీడియోలతో పోర్న్\\u200c క్లిప్\\u200cల తయారీ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LuS7yfDXnkrd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6cc7a185-ff8d-4212-ffd8-17cf9e008ca1"
      },
      "source": [
        "summarize(\"టిక్ టాక్  యాప్ ను భారతీయులు అధికంగా వినియోగిస్తున్నారు. రోజురోజుకు టిక్ టాక్  యాప్ ను ఉపయోగిస్తున్నవారి సంఖ్య పెరుగుతోంది. యూజర్లు తమ వీడియోల ద్వారా ప్రతిభను బయటపెడుతున్నారు. అదేవిధంగా చాలా మంది ఈ టిక్ టాక్  వీడియోల్లో డాన్స్ లు, పాటలు, చాలెంజ్ లు చేస్తూ.. సోషల్ మీడియాలో పాపులర్  అయిన విషయం తెలిసిందే. సాధారణంగా ఈ టిక్ టాక్  వీడియోలను చూస్తూ.. వైరల్ గా మారిన వీడియోలను షేర్  చేస్తూ యూజర్లు గంటల కొద్ది సమయాన్ని గడిపేస్తున్నారు. కొంతమందికి తమ ప్రతిభను బయట పెట్టడానికి.. మరికొంతమందికి కాలక్షేపం, వినోదానికి అనువుగా ఉండటంలో ఈ యాప్ పై యూజర్లు బోలడంత సమయాన్ని కేటాయిస్తున్నారు.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'భారతీయులు టిక్\\u200cటాక్\\u200cలో తెగ గడిపేశారు'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WYlViKHwnk16",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "233ca61a-b78b-47b9-8f96-c2745004514a"
      },
      "source": [
        "summarize(\"సూర్యుడికి సంబంధించిన అత్యంత అరుదైన ఫొటోలను అమెరికా ఖగోళ శాస్త్రవేత్తలు విడుదల చేశారు. ప్రపంచంలోనే అత్యంత పెద్దదైన సోలార్ టెలిస్కోప్ గా ప్రసిద్ధి పొందిన డేనియల్ కే ఇనౌయే సోలార్ టెలిస్కోప్ (డీకేఐఎస్ టీ) అద్భుత ఆవిష్కారానికి కారణమైంది. దీని ద్వారా సూర్యుడి ఉపరితలానికి సంబంధించిన అరుదైన ఫొటోలను చూసే అవకాశం మానవాళికి దక్కింది. కాగా హవాయి ద్వీపంలో ఏర్పాటు చేసిన ఈ భారీ టెలిస్కోపు ద్వారా సూర్యుడిని అత్యంత సమీపంగా చూస్తూ.. అంతర్గత శక్తిని అంచనా వేసే అవకాశం ఉంటుందని ఆస్ట్రోనాట్లు పేర్కొంటున్నారు. ప్రస్తుతం ఇది విడుదల చేసిన ఫొటోల ఆధారంగా.. సూర్యడి ఉపరితలం మీది కణాల వంటి ఆకారాలను జూమ్ చేయగా.. ఒక్కోటి అమెరికా రాష్ట్రం టెక్సాస్ పరిమాణంలో ఉందని తెలిపారు.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'ముందెన్నడూ చూడని సూర్యుడి అద్భుత ఫొటోలు'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGmAMAVYFu25",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b62ae424-1c63-4e16-a125-ad25a29ac206"
      },
      "source": [
        "summarize(\"అమెరికన్  ప్రెసిడెంట్ గా వ్యవహరిస్తున్న వ్యక్తి భార్యను ఫస్ట్  లేడీ అని సంబోధిస్తారు. హాలీవుడ్ లో ప్రస్తుతం ‘ఫస్ట్  లేడీస్ ’ అనే టైటిల్ తో ప్రెసిడెంట్  సతీమణులపై ఓ సిరీస్  రూపొందబోతోంది. ఈ సిరీస్  మొదటి సీజన్ లో అమెరికాకు ప్రెసిడెంట్లుగా వ్యవహరించిన ఇలియానోర్  రూజ్ వెల్ట్  , బెట్టీ ఫోర్డ్, ఒబామా భార్యల కథలను చర్చించనున్నారు. ఇందులో ఒబామా భార్య మిచ్చెలీ ఒబామా పాత్రలో వయోలా డేవిస్  నటించనున్నారు. ‘మిచ్చెలీ లాంటి ధైర్యవంతురాలు, ఎక్స్ ట్రార్డినరీ ఉమెన్  పాత్ర చేస్తున్నందుకు చాలా గర్వంగా ఉంది’ అని డేవిస్  అన్నారు.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'అందుకే టీడీపీని వీడాను శమంతకమణి'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uue86MVeFvE1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b0be0fe-6d26-4f6f-a45a-40254d027e92"
      },
      "source": [
        "summarize(\"రియల్  ఎస్టేట్  పోర్టల్  నోబ్రోకర్ .కామ్  హైదరాబాద్ లో అడుగుపెట్టింది. కస్టమర్  నుంచి కస్టమర్ కు సేవలందిస్తున్న ఈ కంపెనీ ఇప్పటికే అయిదు నగరాల్లో కార్యకలాపాలు సాగిస్తోంది. అద్దె, కొనుగోలు, విక్రయానికి ఉన్న రెసిడెన్షియల్, కమర్షియల్  ప్రాపర్టీస్ ను ఈ పోర్టల్ లో నమోదు చేయవచ్చు. రియల్  ఎస్టేట్  లావాదేవీల్లో ఎటువంటి బ్రోకరేజ్  వసూలు చేయబోమని కంపెనీ ఫౌండర్, సీబీవో సౌరభ్  గర్గ్  తెలిపారు. ఫౌండర్, సీటీవో అఖిల్  గుప్తాతో కలిసి బుధవారమిక్కడ మీడియాతో మాట్లాడారు. ‘ఒక్క భాగ్యనగరిలో బ్రోకరేజ్  వ్యాపారం ఏటా రూ.4,100 కోట్లుంది. ఈ నగరంలో నోబ్రోకర్ .కామ్ లో 15,000పైచిలుకు లిస్టింగ్స్  జరిగాయి. 33,000లకుపైగా కస్టమర్లు సేవలను వినియోగించుకున్నారు. దేశవ్యాప్తంగా సంస్థకు 65 లక్షల వినియోగదార్లున్నారు. 5 లక్షల లావాదేవీలు పూర్తి అయ్యాయి’ అని వివరించారు.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'హైదరాబాద్\\u200cలో నోబ్రోకర్\\u200c కామ్\\u200c సేవలు'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yf7CWdiFvSI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c7cdd36a-6e74-462f-ca03-60637f26cadf"
      },
      "source": [
        "summarize(\"దక్షిణకొరియా దిగ్గజం శాంసంగ్  ఇండియాలో కొత్త స్మార్ట్ పోన్ ను లాంచ్  చేసింది. గెలాక్సీ ఏ 70కి కొనసాగింపుగా గెలాక్సీ ఏ 71ని ఆవిష్కరించింది. భారతదేశంలో శాంసంగ్ గెలాక్సీ ఏ 71. ప్రిజం క్రష్ బ్లాక్, ప్రిజం క్రష్ సిల్వర్, ప్రిజం క్రష్ బ్లూ కలర్ వేరియంట్ లలో వస్తుంది. ఫిబ్రవరి 24 నుండి శాంసంగ్ ఒపెరా హౌస్, శాంసంగ్.కామ్ తో పాటు ప్రముఖ ఆన్ లైన్ పోర్టల్ ల ద్వారా ఈ స్మార్ట్ ఫోన్ అందుబాటులో వుంటుంది.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'అద్భుత ఫీచర్లతో శాంసంగ్\\u200c గెలాక్సీ ఏ 71'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    }
  ]
}